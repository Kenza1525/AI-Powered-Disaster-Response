INFO:root:
================Training Summary=================
INFO:root:Training Summary: 
INFO:root:Learning rate 0.002
INFO:root:Batch size 32
INFO:root:DataParallel(
  (module): TextOnlyModel(
    (dropout): Dropout(p=0.5, inplace=False)
    (textEncoder): ElectraModel(
      (embeddings): ElectraEmbeddings(
        (word_embeddings): Embedding(30522, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): ElectraEncoder(
        (layer): ModuleList(
          (0-11): 12 x ElectraLayer(
            (attention): ElectraAttention(
              (self): ElectraSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): ElectraSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): ElectraIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): ElectraOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
    )
    (linear): Linear(in_features=768, out_features=2, bias=True)
  )
)
INFO:root:
=================================================
INFO:root:Training iteration 0
INFO:root:Finished 100 / 426 batches with loss: 0.020923852920532227, accuracy 0.61
INFO:root:Finished 200 / 426 batches with loss: 0.020090430974960327, accuracy 0.64375
INFO:root:Finished 300 / 426 batches with loss: 0.019187666177749634, accuracy 0.6721875
INFO:root:Finished 400 / 426 batches with loss: 0.018212104737758635, accuracy 0.7065625
INFO:root:=============Iteration 0=============
INFO:root:Training accuracy 0.6614491475602586
INFO:root:Avg Training loss 0.019543814490922125
INFO:root:Micro F1: 0.6614
INFO:root:Macro F1: 0.5978
INFO:root:Weighted F1: 0.6339
INFO:root:Saving model...
