INFO:root:
================Training Summary=================
INFO:root:Training Summary: 
INFO:root:Learning rate 0.002
INFO:root:Batch size 32
INFO:root:DataParallel(
  (module): TextOnlyModel(
    (dropout): Dropout(p=0.5, inplace=False)
    (textEncoder): ElectraModel(
      (embeddings): ElectraEmbeddings(
        (word_embeddings): Embedding(30522, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): ElectraEncoder(
        (layer): ModuleList(
          (0-11): 12 x ElectraLayer(
            (attention): ElectraAttention(
              (self): ElectraSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): ElectraSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): ElectraIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): ElectraOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
    )
    (linear): Linear(in_features=768, out_features=2, bias=True)
  )
)
INFO:root:
=================================================
INFO:root:Training iteration 0
INFO:root:Finished 100 / 426 batches with loss: 0.021135096549987794, accuracy 0.5896875
INFO:root:Finished 200 / 426 batches with loss: 0.019829678535461425, accuracy 0.6475
INFO:root:Finished 300 / 426 batches with loss: 0.019136059880256653, accuracy 0.668125
INFO:root:Finished 400 / 426 batches with loss: 0.01869566649198532, accuracy 0.6928125
INFO:root:=============Iteration 0=============
INFO:root:Training accuracy 0.6527042915931804
INFO:root:Avg Training loss 0.019657566433861143
INFO:root:Micro F1: 0.6527
INFO:root:Macro F1: 0.5916
INFO:root:Weighted F1: 0.6273
INFO:root:Saving model...
