INFO:root:
================Training Summary=================
INFO:root:Training Summary: 
INFO:root:Learning rate 0.002
INFO:root:Batch size 32
INFO:root:DataParallel(
  (module): TextOnlyModel(
    (dropout): Dropout(p=0.5, inplace=False)
    (textEncoder): ElectraModel(
      (embeddings): ElectraEmbeddings(
        (word_embeddings): Embedding(30522, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): ElectraEncoder(
        (layer): ModuleList(
          (0-11): 12 x ElectraLayer(
            (attention): ElectraAttention(
              (self): ElectraSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): ElectraSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): ElectraIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): ElectraOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
    )
    (linear): Linear(in_features=768, out_features=6, bias=True)
  )
)
INFO:root:
=================================================
INFO:root:Training iteration 0
INFO:root:Finished 100 / 426 batches with loss: 0.04922489881515503, accuracy 0.33625
INFO:root:Finished 200 / 426 batches with loss: 0.046407597064971925, accuracy 0.3784375
INFO:root:Finished 300 / 426 batches with loss: 0.045133744478225706, accuracy 0.3884375
INFO:root:Finished 400 / 426 batches with loss: 0.04410911083221435, accuracy 0.4271875
INFO:root:=============Iteration 0=============
INFO:root:Training accuracy 0.38646384479717816
INFO:root:Avg Training loss 0.046051377902515914
INFO:root:Micro F1: 0.3865
INFO:root:Macro F1: 0.1685
INFO:root:Weighted F1: 0.3080
INFO:root:Saving model...
