INFO:root:
================Training Summary=================
INFO:root:Training Summary: 
INFO:root:Learning rate 0.002
INFO:root:Batch size 32
INFO:root:DataParallel(
  (module): TextOnlyModel(
    (dropout): Dropout(p=0.5, inplace=False)
    (textEncoder): ElectraModel(
      (embeddings): ElectraEmbeddings(
        (word_embeddings): Embedding(30522, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): ElectraEncoder(
        (layer): ModuleList(
          (0-11): 12 x ElectraLayer(
            (attention): ElectraAttention(
              (self): ElectraSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): ElectraSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): ElectraIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): ElectraOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
    )
    (linear): Linear(in_features=768, out_features=6, bias=True)
  )
)
INFO:root:
=================================================
INFO:root:Training iteration 0
INFO:root:Finished 100 / 426 batches with loss: 0.04807009220123291, accuracy 0.374375
INFO:root:Finished 200 / 426 batches with loss: 0.0462105131149292, accuracy 0.3890625
INFO:root:Finished 300 / 426 batches with loss: 0.04566876530647278, accuracy 0.389375
INFO:root:Finished 400 / 426 batches with loss: 0.04354527473449707, accuracy 0.4240625
INFO:root:=============Iteration 0=============
INFO:root:Training accuracy 0.39616402116402116
INFO:root:Avg Training loss 0.04583124943441114
INFO:root:Micro F1: 0.3962
INFO:root:Macro F1: 0.1776
INFO:root:Weighted F1: 0.3231
INFO:root:Saving model...
