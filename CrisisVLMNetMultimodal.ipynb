{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kenza1525/AI-Powered-Disaster-Response/blob/main/CrisisVLMNetMultimodal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o7oryBPPoT0_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bd5546e-b600-444a-8831-9c6eafdf4468"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m108.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m73.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m336.6/336.6 kB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.7/320.7 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.6/37.6 MB\u001b[0m \u001b[31m65.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m97.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m90.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m51.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m42.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m82.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for flash_attn (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "#Install required packages for\n",
        "!pip install -qq torch==2.6.0 torchvision==0.21.0 transformers==4.48.2 \\\n",
        "accelerate==1.3.0 flash_attn==2.7.4.post1 peft==0.13.2 \\\n",
        "soundfile==0.13.1 pillow==11.1.0 scipy==1.15.2 backoff==2.2.1 \\\n",
        "wandb tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRsd4lALogUk",
        "outputId": "d70119e2-a98f-48ba-c9db-4602191e32c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5mGYCGDupRHp"
      },
      "outputs": [],
      "source": [
        "#Core imports\n",
        "import re\n",
        "import gc\n",
        "import os\n",
        "import json\n",
        "import random\n",
        "import getpass\n",
        "import wandb\n",
        "import shutil\n",
        "import zipfile\n",
        "import random\n",
        "import math\n",
        "import torch\n",
        "import time\n",
        "import logging\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Optimizer\n",
        "from torch.optim.lr_scheduler import LambdaLR\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, models\n",
        "from transformers import ElectraTokenizer\n",
        "from transformers import ElectraModel, ElectraConfig\n",
        "from transformers import AutoTokenizer, AutoProcessor, AutoModelForCausalLM, GenerationConfig\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_recall_fscore_support, classification_report"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.backends.cudnn.benchmark = True\n"
      ],
      "metadata": {
        "id": "lF40T8QRREkG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GeSVzBnovm6O",
        "outputId": "34695e35-f697-41dc-ea79-50ec8dfebae9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "Enter your W&B API key: ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlnzabamp\u001b[0m (\u001b[33mprinciple-paper\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "#Set seed for reproducibility\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "#Check device\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {DEVICE}\")\n",
        "\n",
        "#W&B Login (use getpass to hide API key)\n",
        "wandb_key = getpass.getpass(\"Enter your W&B API key: \")\n",
        "wandb.login(key=wandb_key)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4HhKveMn4VkG",
        "outputId": "54331904-da47-4177-90a5-d2d9c4f9121d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Configuration loaded.\n"
          ]
        }
      ],
      "source": [
        "#Master configuration dictionary\n",
        "config = {\n",
        "    \"task\": \"task1\",  # Options: task1, task2, task3\n",
        "    \"setting\": \"A\",   # Options: A or B\n",
        "\n",
        "    \"model_type\": \"CrisisVLMNet\",  # Model variants: CrisisVLMNet, TextOnly, etc.\n",
        "    \"use_caption\": True,\n",
        "    \"use_image\": True,\n",
        "\n",
        "    #Training hyperparameters\n",
        "    \"max_epochs\": 20,\n",
        "    \"batch_size\": 16,\n",
        "    \"learning_rate\": 1e-5,\n",
        "    \"weight_decay\": 0.05,\n",
        "    \"optimizer\": \"AdamW\",\n",
        "\n",
        "    #W&B config\n",
        "    \"log_to_wandb\": True,\n",
        "    \"wandb_project\": \"ai-disaster-response\",\n",
        "    \"wandb_entity\": \"principle-paper\",\n",
        "\n",
        "    #Paths\n",
        "    \"root_dir\": \"/content/drive/MyDrive/AI_Disaster_Management\",\n",
        "    \"dataset_dir\": \"/content/drive/MyDrive/AI_Disaster_Management/CrisisMMD/CrisisMMD_v2.0\",\n",
        "    \"caption_path\": \"/content/drive/MyDrive/AI_Disaster_Management/captions/captions_phi4.json\",\n",
        "    \"split_dir\": \"/content/drive/MyDrive/AI_Disaster_Management/CrisisMMD/CrisisMMD_v2.0/splits/crisismmd_datasplit_all\",\n",
        "    \"model_save_path\": \"/content/drive/MyDrive/AI_Disaster_Management/models\",\n",
        "    \"image_dir\": \"/content/drive/MyDrive/AI_Disaster_Management/CrisisMMD/CrisisMMD_v2.0/data_image\",\n",
        "    \"split_dir\": \"/content/drive/MyDrive/AI_Disaster_Management/CrisisMMD/CrisisMMD_v2.0/splits/crisismmd_datasplit_all\",\n",
        "    \"enriched_split_dir\": \"/content/drive/MyDrive/AI_Disaster_Management/CrisisMMD/CrisisMMD_v2.0/splits/enriched_phi4\",\n",
        "    \"device\": DEVICE\n",
        "}\n",
        "\n",
        "print(\"Configuration loaded.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bafWA3avsV88"
      },
      "outputs": [],
      "source": [
        "# #Load Phi-4 Multimodal model\n",
        "# phi_model_id = \"microsoft/Phi-4-multimodal-instruct\"\n",
        "\n",
        "# print(\"Loading Phi-4 model and processor...\")\n",
        "# phi_processor = AutoProcessor.from_pretrained(phi_model_id, trust_remote_code=True)\n",
        "# phi_model = AutoModelForCausalLM.from_pretrained(\n",
        "#     phi_model_id,\n",
        "#     device_map=\"cuda\" if config[\"device\"] == \"cuda\" else \"auto\",\n",
        "#     torch_dtype=\"auto\",\n",
        "#     trust_remote_code=True\n",
        "# ).to(config[\"device\"])\n",
        "\n",
        "# phi_generation_config = GenerationConfig.from_pretrained(phi_model_id)\n",
        "\n",
        "# #Structured disaster prompt\n",
        "# system_prompt = \"You are a helpful assistant.\"\n",
        "# user_prompt = \"\"\"Analyze this disaster image and provide a detailed description that includes:\n",
        "# 1. Main disaster type visible (flood, fire, earthquake damage, hurricane, etc.)\n",
        "# 2. Severity assessment (severe, moderate, or minor damage)\n",
        "# 3. Key infrastructure visible and its condition (buildings, roads, bridges, power lines)\n",
        "# 4. People present and their situation (trapped, injured, being rescued)\n",
        "# 5. Environmental conditions (water levels, smoke, debris)\n",
        "# 6. Any visible hazards that emergency responders should be aware of\n",
        "# 7. Geographic identifiers or landmarks if recognizable\n",
        "# 8. Temporal indicators (time of day, weather conditions)\n",
        "# Format the description as a single cohesive paragraph that would help emergency responders understand the situation. Focus on objective, factual observations rather than assumptions.\"\"\"\n",
        "\n",
        "# #Generate caption for a single image\n",
        "# def generate_caption(image_path):\n",
        "#     from PIL import Image\n",
        "\n",
        "#     image = Image.open(image_path).convert(\"RGB\")\n",
        "#     content_list = [\n",
        "#         {\"type\": \"image\", \"content\": image},\n",
        "#         {\"type\": \"text\", \"content\": user_prompt, \"role\": \"user\"}\n",
        "#     ]\n",
        "\n",
        "#     prompt = \"<|system|>\" + system_prompt + \"<|end|>\" + \"<|user|><|image_1|>\" + user_prompt + \"<|end|><|assistant|>\"\n",
        "\n",
        "#     inputs = phi_processor(\n",
        "#         text=prompt,\n",
        "#         images=[image],\n",
        "#         return_tensors='pt'\n",
        "#     ).to(config[\"device\"])\n",
        "\n",
        "#     with torch.no_grad():\n",
        "#         output_ids = phi_model.generate(\n",
        "#             **inputs,\n",
        "#             max_new_tokens=512,\n",
        "#             generation_config=phi_generation_config\n",
        "#         )\n",
        "\n",
        "#     # Only return new generated tokens\n",
        "#     output_ids = output_ids[:, inputs[\"input_ids\"].shape[1]:]\n",
        "#     caption = phi_processor.batch_decode(output_ids, skip_special_tokens=True)[0]\n",
        "#     return caption\n",
        "\n",
        "# print(\"Phi-4 model ready for captioning.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xWc9w0kwxKxG"
      },
      "outputs": [],
      "source": [
        "# #Pick a random image\n",
        "# test_image_path = \"/content/drive/MyDrive/AI_Disaster_Management/CrisisMMD/CrisisMMD_v2.0/data_image/california_wildfires/10_10_2017/917791044158185473_0.jpg\"\n",
        "# #Confirm full path\n",
        "# print(f\"Using image: {test_image_path}\")\n",
        "\n",
        "# # Display the image\n",
        "# img = Image.open(test_image_path).convert(\"RGB\")\n",
        "# plt.imshow(img)\n",
        "# plt.axis(\"off\")\n",
        "# plt.title(\"CrisisMMD Sample Image\")\n",
        "# plt.show()\n",
        "\n",
        "# #Generate caption using Phi-4\n",
        "# print(\"Generating caption with Phi-4...\")\n",
        "# caption = generate_caption(test_image_path)\n",
        "\n",
        "# #Show caption\n",
        "# print(\"\\nGenerated Caption:\\n\")\n",
        "# print(caption)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yVievl_tFxJ_"
      },
      "outputs": [],
      "source": [
        "# caption_output_path = config[\"caption_path\"]\n",
        "# image_root = config[\"image_dir\"]\n",
        "\n",
        "# #Load existing captions\n",
        "# if os.path.exists(caption_output_path):\n",
        "#     with open(caption_output_path, \"r\") as f:\n",
        "#         captions = json.load(f)\n",
        "#     print(f\"Loaded {len(captions)} existing captions.\")\n",
        "# else:\n",
        "#     captions = {}\n",
        "\n",
        "# #Caption generation loop\n",
        "# new_captions = 0\n",
        "# total_images = 0\n",
        "\n",
        "# for root, _, files in os.walk(image_root):\n",
        "#     for fname in files:\n",
        "#         if fname.endswith(\".jpg\") and not fname.startswith(\"._\"):\n",
        "#             total_images += 1\n",
        "#             #Relative path = key for captions dict\n",
        "#             rel_path = os.path.relpath(os.path.join(root, fname), image_root)\n",
        "\n",
        "#             if rel_path in captions:\n",
        "#                 continue  # already done\n",
        "\n",
        "#             abs_path = os.path.join(root, fname)\n",
        "#             try:\n",
        "#                 caption = generate_caption(abs_path)\n",
        "#                 captions[rel_path] = caption\n",
        "#                 new_captions += 1\n",
        "#             except Exception as e:\n",
        "#                 print(f\"Error on {rel_path}: {e}\")\n",
        "\n",
        "#             if new_captions % 100 == 0:\n",
        "#                 with open(caption_output_path, \"w\") as f:\n",
        "#                     json.dump(captions, f, indent=2)\n",
        "\n",
        "# #Final save\n",
        "# with open(caption_output_path, \"w\") as f:\n",
        "#     json.dump(captions, f, indent=2)\n",
        "\n",
        "# print(f\"\\n Finished captioning.\")\n",
        "# print(f\"Total images scanned: {total_images}\")\n",
        "# print(f\"New captions generated: {new_captions}\")\n",
        "# print(f\"Captions saved to: {caption_output_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XrR3wL68QjL5"
      },
      "outputs": [],
      "source": [
        "\n",
        "# # === Paths ===\n",
        "# original_split_dir = config[\"split_dir\"]\n",
        "# enriched_split_dir = \"/content/drive/MyDrive/AI_Disaster_Management/CrisisMMD/CrisisMMD_v2.0/splits/enriched_phi4\"\n",
        "# caption_path = config[\"caption_path\"]\n",
        "\n",
        "# # Make output folder if it doesn't exist\n",
        "# os.makedirs(enriched_split_dir, exist_ok=True)\n",
        "\n",
        "# # === Load captions ===\n",
        "# with open(caption_path, \"r\") as f:\n",
        "#     captions = json.load(f)\n",
        "\n",
        "# print(f\"Loaded {len(captions)} captions from Phi-4\")\n",
        "\n",
        "# # === Tweet text cleaning (same as preprocess.py) ===\n",
        "# def clean_text(text):\n",
        "#     text = re.sub(r'^RT[\\s]+', '', text)\n",
        "#     text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text)\n",
        "#     text = re.sub(r'#', '', text)\n",
        "#     text = re.sub(r'@\\w+', '', text)  # <-- NEW: remove @mentions\n",
        "#     return text.strip()\n",
        "\n",
        "# # === Process each original .tsv ===\n",
        "# tsv_files = [f for f in os.listdir(original_split_dir) if f.endswith(\".tsv\")]\n",
        "\n",
        "# for fname in tqdm(tsv_files, desc=\"Processing TSV splits\"):\n",
        "#     input_path = os.path.join(original_split_dir, fname)\n",
        "#     df = pd.read_csv(input_path, sep=\"\\t\")\n",
        "\n",
        "#     # Dynamic required column check\n",
        "#     if \"task_damage\" in fname:\n",
        "#         required_cols = ['event_name', 'tweet_id', 'image_id', 'tweet_text', 'image', 'label']\n",
        "#     else:\n",
        "#         required_cols = ['event_name', 'tweet_id', 'image_id', 'tweet_text', 'image', 'label',\n",
        "#                          'label_text', 'label_image', 'label_text_image']\n",
        "\n",
        "#     if not all(col in df.columns for col in required_cols):\n",
        "#         print(f\"Skipping {fname} — missing required columns.\")\n",
        "#         continue\n",
        "\n",
        "#     # Clean tweet and add caption if available\n",
        "#     final_texts = []\n",
        "#     keep_indices = []\n",
        "\n",
        "#     for i, row in df.iterrows():\n",
        "#         cleaned = clean_text(str(row['tweet_text']))\n",
        "#         rel_path = row['image'].replace(\"data_image/\", \"\")\n",
        "\n",
        "#         caption = captions.get(rel_path)\n",
        "#         if caption:\n",
        "#             final_texts.append(f\"{cleaned} [SEP] {caption}\")\n",
        "#             keep_indices.append(i)\n",
        "\n",
        "#     # Keep only rows with captions\n",
        "#     df_filtered = df.iloc[keep_indices].copy()\n",
        "#     df_filtered[\"tweet_text\"] = df_filtered[\"tweet_text\"].apply(clean_text)\n",
        "#     df_filtered[\"final_text\"] = final_texts\n",
        "\n",
        "#     # Save\n",
        "#     out_path = os.path.join(enriched_split_dir, fname)\n",
        "#     df_filtered.to_csv(out_path, sep=\"\\t\", index=False)\n",
        "#     print(f\"Saved enriched TSV: {out_path} ({len(df_filtered)} rows)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9KfA_LuCponU"
      },
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "\n",
        "# df = pd.read_csv(\"/content/drive/MyDrive/AI_Disaster_Management/CrisisMMD/CrisisMMD_v2.0/splits/crisismmd_datasplit_all/task_damage_text_img_dev.tsv\", sep=\"\\t\")\n",
        "# print(df.columns)\n",
        "# print(df[\"image\"].head(3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wTvRnFC6p6vG"
      },
      "outputs": [],
      "source": [
        "# import json\n",
        "\n",
        "# with open(config[\"caption_path\"]) as f:\n",
        "#     captions = json.load(f)\n",
        "\n",
        "# sample_keys = list(captions.keys())[:5]\n",
        "# print(sample_keys)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZPq0zu5O-aw9"
      },
      "outputs": [],
      "source": [
        "# Clean tweet text (previously in preprocess.py)\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'^RT[\\s]+', '', text)\n",
        "    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text)\n",
        "    text = re.sub(r'#', '', text)\n",
        "    text = re.sub(r'@\\w+', '', text)\n",
        "    return text.strip()\n",
        "\n",
        "# Expand to square (from base_dataset.py)\n",
        "def expand2square(pil_img, background_color=(0, 0, 0)):\n",
        "    width, height = pil_img.size\n",
        "    if width == height:\n",
        "        return pil_img\n",
        "    elif width > height:\n",
        "        result = Image.new(pil_img.mode, (width, width), background_color)\n",
        "        result.paste(pil_img, (0, (width - height) // 2))\n",
        "        return result\n",
        "    else:\n",
        "        result = Image.new(pil_img.mode, (height, height), background_color)\n",
        "        result.paste(pil_img, ((height - width) // 2, 0))\n",
        "        return result\n",
        "\n",
        "# Label mappings\n",
        "LABELS = {\n",
        "    'task1': {\n",
        "        'informative': 1,\n",
        "        'not_informative': 0\n",
        "    },\n",
        "    'task2': {\n",
        "        'infrastructure_and_utility_damage': 0,\n",
        "        'not_humanitarian': 1,\n",
        "        'other_relevant_information': 2,\n",
        "        'rescue_volunteering_or_donation_effort': 3,\n",
        "        'vehicle_damage': 4,\n",
        "        'affected_individuals': 5,\n",
        "        'injured_or_dead_people': 5,\n",
        "        'missing_or_found_people': 5\n",
        "    },\n",
        "    'task2_full': {\n",
        "        'infrastructure_and_utility_damage': 0,\n",
        "        'not_humanitarian': 1,\n",
        "        'other_relevant_information': 2,\n",
        "        'rescue_volunteering_or_donation_effort': 3,\n",
        "        'vehicle_damage': 4,\n",
        "        'affected_individuals': 5,\n",
        "        'injured_or_dead_people': 6,\n",
        "        'missing_or_found_people': 7\n",
        "    },\n",
        "    'task3': {\n",
        "        'little_or_no_damage': 0,\n",
        "        'mild_damage': 1,\n",
        "        'severe_damage': 2\n",
        "    }\n",
        "}\n",
        "\n",
        "# Task name to file prefix mapping\n",
        "TASK_MAP = {\n",
        "    'task1': 'informative',\n",
        "    'task2': 'humanitarian',\n",
        "    'task2_full': 'humanitarian',\n",
        "    'task3': 'damage'\n",
        "}\n",
        "\n",
        "class CrisisMMDataset(Dataset):\n",
        "    def __init__(self):\n",
        "        self.data = []\n",
        "\n",
        "    def initialize(self, opt, phase='train', cat='all', task='task1'):\n",
        "        self.task = task\n",
        "        self.label_map = LABELS[task]\n",
        "        self.tokenizer = ElectraTokenizer.from_pretrained('google/electra-base-discriminator')\n",
        "        self.max_len = opt.get('max_len', 512)\n",
        "        self.debug = opt.get('debug', False)\n",
        "\n",
        "        # Fix filename using mapping\n",
        "        task_file_prefix = TASK_MAP[task]\n",
        "        tsv_path = os.path.join(opt['enriched_split_dir'], f\"task_{task_file_prefix}_text_img_{phase}.tsv\")\n",
        "        df = pd.read_csv(tsv_path, sep='\\t')\n",
        "\n",
        "        if self.debug:\n",
        "            df = df.head(100)\n",
        "\n",
        "        self.image_root = opt['image_dir']\n",
        "\n",
        "        # Read and store\n",
        "        self.data = []\n",
        "        for _, row in df.iterrows():\n",
        "            text = clean_text(row['final_text'])\n",
        "            image_rel_path = row['image']\n",
        "            if image_rel_path.startswith(\"data_image/\"):\n",
        "              image_rel_path = image_rel_path[len(\"data_image/\"):]\n",
        "            image_path = os.path.join(self.image_root, image_rel_path)\n",
        "\n",
        "            # Tokenize\n",
        "            tokens = self.tokenizer(\n",
        "                text,\n",
        "                padding='max_length',\n",
        "                truncation=True,\n",
        "                max_length=self.max_len,\n",
        "                return_tensors='pt'\n",
        "            )\n",
        "\n",
        "            self.data.append({\n",
        "                'input_ids': tokens['input_ids'].squeeze(0),\n",
        "                'attention_mask': tokens['attention_mask'].squeeze(0),\n",
        "                'token_type_ids': tokens['token_type_ids'].squeeze(0),\n",
        "                'image_path': image_path,\n",
        "                'label': torch.tensor(self.label_map[row['label']], dtype=torch.long),\n",
        "                'text': text  # optional\n",
        "            })\n",
        "\n",
        "        # Define transforms\n",
        "        self.transforms = transforms.Compose([\n",
        "            transforms.Lambda(lambda img: expand2square(img)),\n",
        "            transforms.Resize((opt.get('load_size', 224), opt.get('load_size', 224))),\n",
        "            transforms.RandomHorizontalFlip(0.2),\n",
        "            transforms.RandomCrop((opt.get('crop_size', 224), opt.get('crop_size', 224))),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "        ])\n",
        "\n",
        "        print(f\"Loaded {len(self.data)} samples for {phase}\")\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample = self.data[idx]\n",
        "\n",
        "        if not os.path.exists(sample['image_path']):\n",
        "          print(f\"[Missing Image] {sample['image_path']}\")\n",
        "\n",
        "        with Image.open(sample['image_path']).convert('RGB') as img:\n",
        "            image_tensor = self.transforms(img)\n",
        "\n",
        "        return {\n",
        "            'input_ids': sample['input_ids'],\n",
        "            'attention_mask': sample['attention_mask'],\n",
        "            'token_type_ids': sample['token_type_ids'],\n",
        "            'image': image_tensor,\n",
        "            'label': sample['label'],\n",
        "            'text': sample['text']\n",
        "        }\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def name(self):\n",
        "        return \"CrisisMMDataset\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eZPP7nzbIL4z"
      },
      "outputs": [],
      "source": [
        "# Base class to handle saving/loading\n",
        "class BaseModel(nn.Module):\n",
        "    def __init__(self, save_dir):\n",
        "        super(BaseModel, self).__init__()\n",
        "        self.save_dir = save_dir\n",
        "\n",
        "    def save(self, filename):\n",
        "        path = os.path.join(self.save_dir, f\"{filename}.pt\")\n",
        "        torch.save(self.state_dict(), path)\n",
        "        print(f\" Model saved to: {path}\")\n",
        "\n",
        "    def load(self, filepath):\n",
        "        self.load_state_dict(torch.load(filepath, map_location='cpu'), strict=False)\n",
        "        print(f\"Loaded model from: {filepath}\")\n",
        "\n",
        "# Text-only ELECTRA model\n",
        "class TextOnlyModel(BaseModel):\n",
        "    def __init__(self, save_dir, dim_text_repr=768, num_class=2):\n",
        "        super(TextOnlyModel, self).__init__(save_dir)\n",
        "\n",
        "        self.textEncoder = ElectraModel.from_pretrained('google/electra-base-discriminator')\n",
        "\n",
        "\n",
        "        self.dropout = nn.Dropout()\n",
        "        self.linear = nn.Linear(dim_text_repr, num_class)\n",
        "\n",
        "    def forward(self, x):\n",
        "        _, text = x\n",
        "        hidden_states = self.textEncoder(**text)\n",
        "        cls_token = self.dropout(hidden_states[0][:, 0, :])\n",
        "        return self.linear(cls_token)\n",
        "\n",
        "# Image-only DenseNet model\n",
        "class ImageOnlyModel(BaseModel):\n",
        "    def __init__(self, save_dir, dim_visual_repr=1000, num_class=2):\n",
        "        super(ImageOnlyModel, self).__init__(save_dir)\n",
        "\n",
        "        self.imageEncoder = torch.hub.load('pytorch/vision:v0.8.0', 'densenet201', pretrained=True)\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.dropout = nn.Dropout()\n",
        "        self.linear = nn.Linear(dim_visual_repr, num_class)\n",
        "\n",
        "    def forward(self, x):\n",
        "        image, _ = x\n",
        "        visual_feats = self.dropout(self.flatten(self.imageEncoder(image)))\n",
        "        return self.linear(visual_feats)\n",
        "\n",
        "class MultiTaskDenseNetElectraModel(BaseModel):\n",
        "    def __init__(self, save_dir, dim_visual_repr=1000, dim_text_repr=768, dim_proj=100,\n",
        "                 num_classes_task1=2, num_classes_task2=6, num_classes_task3=3):\n",
        "        super(MultiTaskDenseNetElectraModel, self).__init__(save_dir)\n",
        "\n",
        "        self.imageEncoder = torch.hub.load('pytorch/vision:v0.8.0', 'densenet201', pretrained=True)\n",
        "        self.textEncoder = ElectraModel.from_pretrained('google/electra-base-discriminator')\n",
        "\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.dropout = nn.Dropout(p=0.6)\n",
        "\n",
        "        # Shared projection layers\n",
        "        self.proj_visual = nn.Linear(dim_visual_repr, dim_proj)\n",
        "        self.proj_text = nn.Linear(dim_text_repr, dim_proj)\n",
        "        self.bn_visual = nn.BatchNorm1d(dim_proj)\n",
        "        self.bn_text = nn.BatchNorm1d(dim_proj)\n",
        "\n",
        "        # Attention layers\n",
        "        self.attn_visual = nn.Linear(dim_visual_repr, dim_proj)\n",
        "        self.attn_text = nn.Linear(dim_text_repr, dim_proj)\n",
        "\n",
        "        # Shared feature fusion\n",
        "        self.fc_attn = nn.Linear(2 * dim_proj, 2 * dim_proj)\n",
        "        self.bn_attn = nn.BatchNorm1d(2 * dim_proj)\n",
        "\n",
        "        # Task-specific classification heads\n",
        "        self.classifier_task1 = nn.Linear(2 * dim_proj, num_classes_task1)\n",
        "        self.classifier_task2 = nn.Linear(2 * dim_proj, num_classes_task2)\n",
        "        self.classifier_task3 = nn.Linear(2 * dim_proj, num_classes_task3)\n",
        "\n",
        "    def apply_self_attention(self, x):\n",
        "        scores = torch.matmul(x, x.transpose(-1, -2))\n",
        "        weights = F.softmax(scores, dim=-1)\n",
        "        return torch.matmul(weights, x)\n",
        "\n",
        "    def forward(self, x, task=None):\n",
        "        image, text = x\n",
        "\n",
        "        visual_feats = self.dropout(self.flatten(self.imageEncoder(image)))\n",
        "        text_hidden = self.textEncoder(**text)[0][:, 0, :]\n",
        "        text_hidden = self.dropout(text_hidden)\n",
        "\n",
        "        # Self-attention and feature extraction (same for all tasks)\n",
        "        v_attn = self.apply_self_attention(visual_feats)\n",
        "        t_attn = self.apply_self_attention(text_hidden)\n",
        "\n",
        "        v_proj = F.relu(self.bn_visual(self.proj_visual(v_attn)))\n",
        "        t_proj = F.relu(self.bn_text(self.proj_text(t_attn)))\n",
        "\n",
        "        alpha_v = torch.sigmoid(self.attn_text(t_attn))\n",
        "        alpha_t = torch.sigmoid(self.attn_visual(v_attn))\n",
        "\n",
        "        masked_v = alpha_v * v_proj\n",
        "        masked_t = alpha_t * t_proj\n",
        "\n",
        "        joint = torch.cat((masked_v, masked_t), dim=1)\n",
        "        joint = self.dropout(F.relu(self.bn_attn(self.fc_attn(joint))))\n",
        "\n",
        "        # Return predictions for specific task or all tasks\n",
        "        if task == \"task1\":\n",
        "            return self.classifier_task1(joint)\n",
        "        elif task == \"task2\":\n",
        "            return self.classifier_task2(joint)\n",
        "        elif task == \"task3\":\n",
        "            return self.classifier_task3(joint)\n",
        "        else:\n",
        "            # Return all task predictions\n",
        "            return {\n",
        "                \"task1\": self.classifier_task1(joint),\n",
        "                \"task2\": self.classifier_task2(joint),\n",
        "                \"task3\": self.classifier_task3(joint)\n",
        "            }"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare datasets for all tasks\n",
        "train_set_task1 = CrisisMMDataset()\n",
        "train_set_task1.initialize(config, phase='train', task=\"task1\")\n",
        "train_set_task2 = CrisisMMDataset()\n",
        "train_set_task2.initialize(config, phase='train', task=\"task2\")\n",
        "train_set_task3 = CrisisMMDataset()\n",
        "train_set_task3.initialize(config, phase='train', task=\"task3\")\n",
        "\n",
        "dev_set_task1 = CrisisMMDataset()\n",
        "dev_set_task1.initialize(config, phase='dev', task=\"task1\")\n",
        "dev_set_task2 = CrisisMMDataset()\n",
        "dev_set_task2.initialize(config, phase='dev', task=\"task2\")\n",
        "dev_set_task3 = CrisisMMDataset()\n",
        "dev_set_task3.initialize(config, phase='dev', task=\"task3\")\n",
        "\n",
        "test_set_task1 = CrisisMMDataset()\n",
        "test_set_task1.initialize(config, phase='test', task=\"task1\")\n",
        "test_set_task2 = CrisisMMDataset()\n",
        "test_set_task2.initialize(config, phase='test', task=\"task2\")\n",
        "test_set_task3 = CrisisMMDataset()\n",
        "test_set_task3.initialize(config, phase='test', task=\"task3\")\n",
        "\n",
        "\n",
        "# Create dataloaders\n",
        "train_loader_task1 = DataLoader(train_set_task1, batch_size=config[\"batch_size\"], shuffle=True)\n",
        "train_loader_task2 = DataLoader(train_set_task2, batch_size=config[\"batch_size\"], shuffle=True)\n",
        "train_loader_task3 = DataLoader(train_set_task3, batch_size=config[\"batch_size\"], shuffle=True)\n",
        "\n",
        "dev_loader_task1 = DataLoader(dev_set_task1, batch_size=config[\"batch_size\"], shuffle=False)\n",
        "dev_loader_task2 = DataLoader(dev_set_task2, batch_size=config[\"batch_size\"], shuffle=False)\n",
        "dev_loader_task3 = DataLoader(dev_set_task3, batch_size=config[\"batch_size\"], shuffle=False)\n",
        "\n",
        "test_loader_task1 = DataLoader(test_set_task1, batch_size=config[\"batch_size\"], shuffle=False)\n",
        "test_loader_task2 = DataLoader(test_set_task2, batch_size=config[\"batch_size\"], shuffle=False)\n",
        "test_loader_task3 = DataLoader(test_set_task3, batch_size=config[\"batch_size\"], shuffle=False)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t623eT3Ur8YU",
        "outputId": "6c01a384-068d-4040-bb32-5f6b5970cd70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 8533 samples for train\n",
            "Loaded 8562 samples for train\n",
            "Loaded 1705 samples for train\n",
            "Loaded 1433 samples for dev\n",
            "Loaded 1436 samples for dev\n",
            "Loaded 383 samples for dev\n",
            "Loaded 1434 samples for test\n",
            "Loaded 1402 samples for test\n",
            "Loaded 372 samples for test\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EVZULIv1Id8a"
      },
      "outputs": [],
      "source": [
        "from torch.optim import AdamW\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "def create_optimizer_and_scheduler(config, model, total_steps=None):\n",
        "    optimizer = AdamW(\n",
        "        model.parameters(),\n",
        "        lr=config[\"learning_rate\"],\n",
        "        weight_decay=config[\"weight_decay\"]\n",
        "    )\n",
        "\n",
        "    # Scheduler — Reduce LR on plateau of val_loss\n",
        "    scheduler = ReduceLROnPlateau(\n",
        "    optimizer,\n",
        "    mode='min',\n",
        "    factor=0.7,     # More gradual reduction (0.2 instead of 0.1)\n",
        "    patience=3,     # Wait fewer epochs before reducing (3 instead of 5)\n",
        "    cooldown=1,     # Shorter cooldown (1 instead of 2)\n",
        "    min_lr=1e-7,    # Add a minimum learning rate\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "    return optimizer, scheduler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- Checkpointing Utilities ----\n",
        "def save_model(model, optimizer, scheduler, metric, epoch, path='./checkpoint.pth'):\n",
        "    torch.save(\n",
        "        {'model_state_dict'      : model.state_dict(),\n",
        "         'optimizer_state_dict'  : optimizer.state_dict(),\n",
        "         'scheduler_state_dict'  : scheduler.state_dict(),\n",
        "         metric[0]               : metric[1],\n",
        "         'epoch'                 : epoch},\n",
        "         path\n",
        "    )\n",
        "\n",
        "def load_model(path, model, metric= 'val_loss', optimizer= None, scheduler= None):\n",
        "    checkpoint = torch.load(path)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "    if optimizer is not None:\n",
        "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    if scheduler is not None:\n",
        "        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
        "\n",
        "    epoch = checkpoint['epoch']\n",
        "    metric_value = checkpoint[metric]\n",
        "\n",
        "    return model, optimizer, scheduler, epoch, metric_value\n"
      ],
      "metadata": {
        "id": "sI2q4LUnT4Bn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.utils import clip_grad_norm_\n",
        "class MultiTaskTrainer:\n",
        "    def __init__(self, train_loaders, dev_loaders, test_loaders, model, loss_fn, optimizer, scheduler, config):\n",
        "        # train_loaders, dev_loaders, test_loaders are dictionaries mapping task names to dataloaders\n",
        "        self.train_loaders = train_loaders\n",
        "        self.dev_loaders = dev_loaders\n",
        "        self.test_loaders = test_loaders\n",
        "        self.model = model\n",
        "        self.loss_fn = loss_fn\n",
        "        self.optimizer = optimizer\n",
        "        self.scheduler = scheduler\n",
        "        self.device = config[\"device\"]\n",
        "        self.save_dir = config[\"model_save_path\"]\n",
        "        self.config = config\n",
        "\n",
        "        # Add task weights to config before creating the trainer\n",
        "        config[\"task_weights\"] = {\"task1\": 1.0, \"task2\": 1.0, \"task3\": 1.0}\n",
        "\n",
        "        # Or with dataset size weighting\n",
        "        num_samples = {\n",
        "            \"task1\": len(train_set_task1),\n",
        "            \"task2\": len(train_set_task2),\n",
        "            \"task3\": len(train_set_task3)\n",
        "        }\n",
        "        total_samples = sum(num_samples.values())\n",
        "\n",
        "        self.task_weights = {\n",
        "            task: (total_samples / (3 * count))\n",
        "            for task, count in num_samples.items()\n",
        "}\n",
        "\n",
        "        # WandB setup\n",
        "        if config.get(\"log_to_wandb\", False):\n",
        "            self.run = wandb.init(\n",
        "                project=config[\"wandb_project\"],\n",
        "                entity=config[\"wandb_entity\"],\n",
        "                name=f\"multitask_{int(time.time())}\",\n",
        "                config=config,\n",
        "                reinit=True\n",
        "            )\n",
        "        else:\n",
        "            self.run = None\n",
        "\n",
        "        if self.device != 'cpu':\n",
        "            self.scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "    def train(self, max_epochs):\n",
        "        best_dev_loss = float('inf')\n",
        "        patience = 7\n",
        "        patience_counter = 0\n",
        "\n",
        "        for epoch in range(max_epochs):\n",
        "            self.model.train()\n",
        "            total_loss = 0\n",
        "            task_losses = {task: 0 for task in self.train_loaders}\n",
        "            task_corrects = {task: 0 for task in self.train_loaders}\n",
        "            task_totals = {task: 0 for task in self.train_loaders}\n",
        "\n",
        "            # Determine the length of the longest loader to set as epoch length\n",
        "            max_batches = max([len(loader) for loader in self.train_loaders.values()])\n",
        "            loaders_iter = {task: iter(loader) for task, loader in self.train_loaders.items()}\n",
        "\n",
        "            for _ in tqdm(range(max_batches), desc=f\"Epoch {epoch}\"):\n",
        "                self.optimizer.zero_grad()\n",
        "                epoch_loss = 0\n",
        "\n",
        "                # Process a batch from each task\n",
        "                for task, iterator in loaders_iter.items():\n",
        "                    try:\n",
        "                        batch = next(iterator)\n",
        "                    except StopIteration:\n",
        "                        # Reinitialize iterator if exhausted\n",
        "                        loaders_iter[task] = iter(self.train_loaders[task])\n",
        "                        batch = next(loaders_iter[task])\n",
        "\n",
        "                    x = (\n",
        "                        batch['image'].to(self.device),\n",
        "                        {\n",
        "                            \"input_ids\": batch[\"input_ids\"].to(self.device),\n",
        "                            \"attention_mask\": batch[\"attention_mask\"].to(self.device),\n",
        "                            \"token_type_ids\": batch[\"token_type_ids\"].to(self.device)\n",
        "                        }\n",
        "                    )\n",
        "                    y = batch[\"label\"].to(self.device)\n",
        "\n",
        "                    if self.device != 'cpu':\n",
        "                        with torch.amp.autocast(device_type='cuda'):\n",
        "                            logits = self.model(x, task=task)\n",
        "                            loss = self.loss_fn(logits, y) * self.task_weights[task]\n",
        "                            epoch_loss += loss\n",
        "\n",
        "                        # Track metrics\n",
        "                        task_losses[task] += loss.item()\n",
        "                        preds = torch.argmax(logits, dim=1)\n",
        "                        task_corrects[task] += (preds == y).sum().item()\n",
        "                        task_totals[task] += y.size(0)\n",
        "                    else:\n",
        "                        logits = self.model(x, task=task)\n",
        "                        loss = self.loss_fn(logits, y) * self.task_weights[task]\n",
        "                        epoch_loss += loss\n",
        "\n",
        "                        # Track metrics\n",
        "                        task_losses[task] += loss.item()\n",
        "                        preds = torch.argmax(logits, dim=1)\n",
        "                        task_corrects[task] += (preds == y).sum().item()\n",
        "                        task_totals[task] += y.size(0)\n",
        "\n",
        "                # Backward pass and optimization\n",
        "                if self.device != 'cpu':\n",
        "                    self.scaler.scale(epoch_loss).backward()\n",
        "                    clip_grad_norm_(self.model.parameters(), max_norm=1.0)  # Clip gradients\n",
        "                    self.scaler.step(self.optimizer)\n",
        "                    self.scaler.update()\n",
        "                else:\n",
        "                    epoch_loss.backward()\n",
        "                    clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n",
        "                    self.optimizer.step()\n",
        "\n",
        "                total_loss += epoch_loss.item()\n",
        "\n",
        "            # Calculate metrics\n",
        "            avg_loss = total_loss / (max_batches * len(self.train_loaders))\n",
        "            task_accs = {task: task_corrects[task] / task_totals[task] if task_totals[task] > 0 else 0\n",
        "                         for task in task_corrects}\n",
        "\n",
        "            # Log metrics\n",
        "            logging.info(f\"[Epoch {epoch}] Avg Loss: {avg_loss:.4f}\")\n",
        "            for task, acc in task_accs.items():\n",
        "                logging.info(f\"  - {task} Acc: {acc:.4f}\")\n",
        "\n",
        "            if self.run:\n",
        "                wandb.log({\n",
        "                    \"train_loss\": avg_loss,\n",
        "                    **{f\"{task}_acc\": acc for task, acc in task_accs.items()},\n",
        "                    \"epoch\": epoch\n",
        "                })\n",
        "\n",
        "            # Validation\n",
        "            dev_loss = self.validate(epoch)\n",
        "\n",
        "            # Save checkpoint\n",
        "            if dev_loss < best_dev_loss:\n",
        "                best_dev_loss = dev_loss\n",
        "                patience_counter = 0\n",
        "                model_to_save = self.model.module if hasattr(self.model, \"module\") else self.model\n",
        "\n",
        "                save_model(\n",
        "                    model=model_to_save,\n",
        "                    optimizer=self.optimizer,\n",
        "                    scheduler=self.scheduler,\n",
        "                    metric=('val_loss', dev_loss),\n",
        "                    epoch=epoch,\n",
        "                    path=os.path.join(self.save_dir, \"checkpoint_best.pth\")\n",
        "                )\n",
        "\n",
        "            else:\n",
        "              patience_counter += 1\n",
        "              if patience_counter >= patience:\n",
        "                  print(f\"Early stopping triggered after {epoch+1} epochs\")\n",
        "                  break\n",
        "\n",
        "            self.scheduler.step(dev_loss)\n",
        "\n",
        "    def validate(self, epoch=0):\n",
        "        self.model.eval()\n",
        "        total_loss = 0\n",
        "        task_losses = {task: 0 for task in self.dev_loaders}\n",
        "        task_corrects = {task: 0 for task in self.dev_loaders}\n",
        "        task_totals = {task: 0 for task in self.dev_loaders}\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for task, loader in self.dev_loaders.items():\n",
        "                for batch in loader:\n",
        "                    x = (\n",
        "                        batch['image'].to(self.device),\n",
        "                        {\n",
        "                            \"input_ids\": batch[\"input_ids\"].to(self.device),\n",
        "                            \"attention_mask\": batch[\"attention_mask\"].to(self.device),\n",
        "                            \"token_type_ids\": batch[\"token_type_ids\"].to(self.device)\n",
        "                        }\n",
        "                    )\n",
        "                    y = batch[\"label\"].to(self.device)\n",
        "\n",
        "                    logits = self.model(x, task=task)\n",
        "                    loss = self.loss_fn(logits, y)\n",
        "\n",
        "                    task_losses[task] += loss.item() * y.size(0)\n",
        "                    preds = torch.argmax(logits, dim=1)\n",
        "                    task_corrects[task] += (preds == y).sum().item()\n",
        "                    task_totals[task] += y.size(0)\n",
        "\n",
        "                    total_loss += loss.item() * y.size(0)\n",
        "\n",
        "        # Calculate metrics\n",
        "        total_examples = sum(task_totals.values())\n",
        "        avg_loss = total_loss / total_examples if total_examples > 0 else 0\n",
        "        task_accs = {task: task_corrects[task] / task_totals[task] if task_totals[task] > 0 else 0\n",
        "                     for task in task_corrects}\n",
        "\n",
        "        # Log metrics\n",
        "        logging.info(f\"[Val Epoch {epoch}] Avg Loss: {avg_loss:.4f}\")\n",
        "        for task, acc in task_accs.items():\n",
        "            logging.info(f\"  - {task} Acc: {acc:.4f}\")\n",
        "\n",
        "        if self.run:\n",
        "            wandb.log({\n",
        "                \"val_loss\": avg_loss,\n",
        "                **{f\"val_{task}_acc\": acc for task, acc in task_accs.items()},\n",
        "                \"epoch\": epoch\n",
        "            })\n",
        "\n",
        "        return avg_loss\n",
        "\n",
        "    def predict(self):\n",
        "        self.model.eval()\n",
        "        task_predictions = {task: [] for task in self.test_loaders}\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for task, loader in self.test_loaders.items():\n",
        "                for batch in loader:\n",
        "                    x = (\n",
        "                        batch['image'].to(self.device),\n",
        "                        {\n",
        "                            \"input_ids\": batch[\"input_ids\"].to(self.device),\n",
        "                            \"attention_mask\": batch[\"attention_mask\"].to(self.device),\n",
        "                            \"token_type_ids\": batch[\"token_type_ids\"].to(self.device)\n",
        "                        }\n",
        "                    )\n",
        "                    logits = self.model(x, task=task)\n",
        "                    preds = torch.argmax(logits, dim=1)\n",
        "                    task_predictions[task].extend(preds.cpu().numpy())\n",
        "\n",
        "        return task_predictions"
      ],
      "metadata": {
        "id": "cYtX8bUOt1gE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "task_output_sizes = {\n",
        "    \"task1\": 2,\n",
        "    \"task2\": 8,\n",
        "    \"task2_full\": 8,\n",
        "    \"task3\": 3\n",
        "}\n",
        "# Create model\n",
        "model = MultiTaskDenseNetElectraModel(\n",
        "    save_dir=config[\"model_save_path\"],\n",
        "    num_classes_task1=task_output_sizes[\"task1\"],\n",
        "    num_classes_task2=task_output_sizes[\"task2\"],\n",
        "    num_classes_task3=task_output_sizes[\"task3\"]\n",
        ")\n",
        "model = nn.DataParallel(model).to(config[\"device\"])\n",
        "\n",
        "# Create dataloaders dict for all tasks\n",
        "train_loaders = {\n",
        "    \"task1\": train_loader_task1,\n",
        "    \"task2\": train_loader_task2,\n",
        "    \"task3\": train_loader_task3\n",
        "}\n",
        "dev_loaders = {\n",
        "    \"task1\": dev_loader_task1,\n",
        "    \"task2\": dev_loader_task2,\n",
        "    \"task3\": dev_loader_task3\n",
        "}\n",
        "test_loaders = {\n",
        "    \"task1\": test_loader_task1,\n",
        "    \"task2\": test_loader_task2,\n",
        "    \"task3\": test_loader_task3\n",
        "}\n",
        "\n",
        "# Configure optimizer & scheduler\n",
        "optimizer, scheduler = create_optimizer_and_scheduler(config, model)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# Set task weights (optional - can help balance tasks)\n",
        "config[\"task_weights\"] = {\"task1\": 1.0, \"task2\": 1.0, \"task3\": 1.0}\n",
        "\n",
        "# Create multi-task trainer\n",
        "trainer = MultiTaskTrainer(\n",
        "    train_loaders=train_loaders,\n",
        "    dev_loaders=dev_loaders,\n",
        "    test_loaders=test_loaders,\n",
        "    model=model,\n",
        "    loss_fn=loss_fn,\n",
        "    optimizer=optimizer,\n",
        "    scheduler=scheduler,\n",
        "    config=config\n",
        ")\n",
        "\n",
        "# Train model\n",
        "trainer.train(config[\"max_epochs\"])\n",
        "\n",
        "# Get predictions for all tasks\n",
        "predictions = trainer.predict()\n",
        "preds_task1 = predictions[\"task1\"]\n",
        "preds_task2 = predictions[\"task2\"]\n",
        "preds_task3 = predictions[\"task3\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 642
        },
        "id": "flic5JSquIpm",
        "outputId": "c1947b55-377c-445e-8685-ae0c5f3d61e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.8.0\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet201_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet201_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "creating run (0.0s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250423_183458-52zhd1ja</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/principle-paper/ai-disaster-response/runs/52zhd1ja' target=\"_blank\">multitask_1745433298</a></strong> to <a href='https://wandb.ai/principle-paper/ai-disaster-response' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/principle-paper/ai-disaster-response' target=\"_blank\">https://wandb.ai/principle-paper/ai-disaster-response</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/principle-paper/ai-disaster-response/runs/52zhd1ja' target=\"_blank\">https://wandb.ai/principle-paper/ai-disaster-response/runs/52zhd1ja</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-1aad7eb4c9f1>:45: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler()\n",
            "Epoch 0: 100%|██████████| 536/536 [1:05:12<00:00,  7.30s/it]\n",
            "Epoch 1: 100%|██████████| 536/536 [12:10<00:00,  1.36s/it]\n",
            "Epoch 2: 100%|██████████| 536/536 [12:12<00:00,  1.37s/it]\n",
            "Epoch 3: 100%|██████████| 536/536 [12:10<00:00,  1.36s/it]\n",
            "Epoch 4: 100%|██████████| 536/536 [12:10<00:00,  1.36s/it]\n",
            "Epoch 5: 100%|██████████| 536/536 [12:10<00:00,  1.36s/it]\n",
            "Epoch 6: 100%|██████████| 536/536 [12:12<00:00,  1.37s/it]\n",
            "Epoch 7: 100%|██████████| 536/536 [12:10<00:00,  1.36s/it]\n",
            "Epoch 8: 100%|██████████| 536/536 [12:11<00:00,  1.36s/it]\n",
            "Epoch 9: 100%|██████████| 536/536 [12:10<00:00,  1.36s/it]\n",
            "Epoch 10: 100%|██████████| 536/536 [12:09<00:00,  1.36s/it]\n",
            "Epoch 11: 100%|██████████| 536/536 [12:10<00:00,  1.36s/it]\n",
            "Epoch 12: 100%|██████████| 536/536 [12:11<00:00,  1.37s/it]\n",
            "Epoch 13: 100%|██████████| 536/536 [11:37<00:00,  1.30s/it]\n",
            "Epoch 14: 100%|██████████| 536/536 [12:12<00:00,  1.37s/it]\n",
            "Epoch 15: 100%|██████████| 536/536 [11:36<00:00,  1.30s/it]\n",
            "Epoch 16: 100%|██████████| 536/536 [11:38<00:00,  1.30s/it]\n",
            "Epoch 17: 100%|██████████| 536/536 [11:37<00:00,  1.30s/it]\n",
            "Epoch 18: 100%|██████████| 536/536 [11:37<00:00,  1.30s/it]\n",
            "Epoch 19: 100%|██████████| 536/536 [11:36<00:00,  1.30s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# task_output_sizes = {\n",
        "#     \"task1\": 2,\n",
        "#     \"task2\": 6,\n",
        "#     \"task2_full\": 8,\n",
        "#     \"task3\": 3\n",
        "# }\n",
        "# model = MultiTaskDenseNetElectraModel(\n",
        "#     save_dir=config[\"model_save_path\"],\n",
        "#     num_class=task_output_sizes[config[\"task\"]]\n",
        "# )\n",
        "\n",
        "# # Load the best checkpoint\n",
        "# checkpoint_path = os.path.join(config[\"model_save_path\"], \"best.pt\")\n",
        "# model.load(checkpoint_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8kNowhtNal_",
        "outputId": "99bcd578-6b05-4589-c6a1-9d1db003dda4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.8.0\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet201_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet201_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded model from: /content/drive/MyDrive/AI_Disaster_Management/models/best.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def count_parameters(model):\n",
        "#     total = sum(p.numel() for p in model.parameters())\n",
        "#     trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "#     return total, trainable\n",
        "\n",
        "# total_params, trainable_params = count_parameters(model)\n",
        "# print(f\"Total parameters: {total_params:,}\")\n",
        "# print(f\"Trainable parameters: {trainable_params:,}\")"
      ],
      "metadata": {
        "id": "EQo_-VGcSzxI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# After training is finished\n",
        "print(\"Loading best model for testing...\")\n",
        "best_model_path = os.path.join(config[\"model_save_path\"], \"checkpoint_best.pth\")\n",
        "best_model = MultiTaskDenseNetElectraModel(\n",
        "    save_dir=config[\"model_save_path\"],\n",
        "    num_classes_task1=task_output_sizes[\"task1\"],\n",
        "    num_classes_task2=task_output_sizes[\"task2\"],\n",
        "    num_classes_task3=task_output_sizes[\"task3\"]\n",
        ")\n",
        "best_model = nn.DataParallel(best_model).to(config[\"device\"])\n",
        "load_model(best_model_path, best_model)\n",
        "\n",
        "# Create a new test predict function that uses the best model\n",
        "def predict_with_best_model():\n",
        "    best_model.eval()\n",
        "    task_predictions = {task: [] for task in test_loaders}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for task, loader in test_loaders.items():\n",
        "            for batch in loader:\n",
        "                x = (\n",
        "                    batch['image'].to(config[\"device\"]),\n",
        "                    {\n",
        "                        \"input_ids\": batch[\"input_ids\"].to(config[\"device\"]),\n",
        "                        \"attention_mask\": batch[\"attention_mask\"].to(config[\"device\"]),\n",
        "                        \"token_type_ids\": batch[\"token_type_ids\"].to(config[\"device\"])\n",
        "                    }\n",
        "                )\n",
        "                logits = best_model(x, task=task)\n",
        "                preds = torch.argmax(logits, dim=1)\n",
        "                task_predictions[task].extend(preds.cpu().numpy())\n",
        "\n",
        "    return task_predictions\n",
        "\n",
        "# Get predictions using the BEST model\n",
        "print(\"\\nPredicting on test sets using best model...\")\n",
        "predictions = predict_with_best_model()\n",
        "preds_task1 = predictions[\"task1\"]\n",
        "preds_task2 = predictions[\"task2\"]\n",
        "preds_task3 = predictions[\"task3\"]\n",
        "\n",
        "# extract ground truth and compute metrics\n",
        "y_true_task1 = [sample[\"label\"].item() for sample in test_set_task1]\n",
        "y_true_task2 = [sample[\"label\"].item() for sample in test_set_task2]\n",
        "y_true_task3 = [sample[\"label\"].item() for sample in test_set_task3]\n",
        "\n",
        "# Compute metrics for each task\n",
        "metrics_task1 = compute_metrics(y_true_task1, preds_task1, task_name=\"Task 1 (Informative)\", verbose=True)\n",
        "metrics_task2 = compute_metrics(y_true_task2, preds_task2, task_name=\"Task 2 (Humanitarian)\", verbose=True)\n",
        "metrics_task3 = compute_metrics(y_true_task3, preds_task3, task_name=\"Task 3 (Damage)\", verbose=True)\n",
        "\n",
        "\n",
        "# Prepare accuracy values for MTMS calculation\n",
        "task_accuracies = {\n",
        "    \"task1\": metrics_task1[\"accuracy\"],\n",
        "    \"task2\": metrics_task2[\"accuracy\"],\n",
        "    \"task3\": metrics_task3[\"accuracy\"]\n",
        "}\n",
        "\n",
        "# Define number of classes for each task\n",
        "task_class_counts = {\n",
        "    \"task1\": 2,  # informative vs. not_informative\n",
        "    \"task2\": 6,  # humanitarian categories\n",
        "    \"task3\": 3   # damage severity levels\n",
        "}\n",
        "\n",
        "def compute_mtms(task_metrics, task_class_counts):\n",
        "    \"\"\"\n",
        "    Compute Multi-task Model Strength (MTMS) as defined in the CrisisKAN paper.\n",
        "\n",
        "    Args:\n",
        "        task_metrics: Dictionary mapping task names to their accuracy values\n",
        "        task_class_counts: Dictionary mapping task names to their number of classes\n",
        "\n",
        "    Returns:\n",
        "        MTMS score (float between 0 and 1)\n",
        "    \"\"\"\n",
        "    total_classes = sum(task_class_counts.values())\n",
        "    mtms = 0.0\n",
        "\n",
        "    for task, acc in task_metrics.items():\n",
        "        beta = task_class_counts[task] / total_classes\n",
        "        mtms += beta * acc\n",
        "\n",
        "    print(f\"\\nMulti-task Model Strength (MTMS): {mtms:.4f}\")\n",
        "    return mtms\n",
        "\n",
        "# Compute MTMS\n",
        "mtms = compute_mtms(task_accuracies, task_class_counts)\n",
        "\n",
        "# Log to WandB if enabled\n",
        "if trainer.run:\n",
        "    wandb.log({\n",
        "        \"MTMS\": mtms,\n",
        "        \"task1_accuracy\": metrics_task1[\"accuracy\"],\n",
        "        \"task1_macro_f1\": metrics_task1[\"macro_f1\"],\n",
        "        \"task1_weighted_f1\": metrics_task1[\"weighted_f1\"],\n",
        "        \"task2_accuracy\": metrics_task2[\"accuracy\"],\n",
        "        \"task2_macro_f1\": metrics_task2[\"macro_f1\"],\n",
        "        \"task2_weighted_f1\": metrics_task2[\"weighted_f1\"],\n",
        "        \"task3_accuracy\": metrics_task3[\"accuracy\"],\n",
        "        \"task3_macro_f1\": metrics_task3[\"macro_f1\"],\n",
        "        \"task3_weighted_f1\": metrics_task3[\"weighted_f1\"]\n",
        "    })\n",
        "    trainer.run.finish()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kMQkMawtA7B9",
        "outputId": "f636ba40-ba99-4b1d-f3d2-35f136e872fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading best model for testing...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.8.0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Error(s) in loading state_dict for DataParallel:\n\tMissing key(s) in state_dict: \"module.imageEncoder.features.conv0.weight\", \"module.imageEncoder.features.norm0.weight\", \"module.imageEncoder.features.norm0.bias\", \"module.imageEncoder.features.norm0.running_mean\", \"module.imageEncoder.features.norm0.running_var\", \"module.imageEncoder.features.denseblock1.denselayer1.norm1.weight\", \"module.imageEncoder.features.denseblock1.denselayer1.norm1.bias\", \"module.imageEncoder.features.denseblock1.denselayer1.norm1.running_mean\", \"module.imageEncoder.features.denseblock1.denselayer1.norm1.running_var\", \"module.imageEncoder.features.denseblock1.denselayer1.conv1.weight\", \"module.imageEncoder.features.denseblock1.denselayer1.norm2.weight\", \"module.imageEncoder.features.denseblock1.denselayer1.norm2.bias\", \"module.imageEncoder.features.denseblock1.denselayer1.norm2.running_mean\", \"module.imageEncoder.features.denseblock1.denselayer1.norm2.running_var\", \"module.imageEncoder.features.denseblock1.denselayer1.conv2.weight\", \"module.imageEncoder.features.denseblock1.denselayer2.norm1.weight\", \"module.imageEncoder.features.denseblock1.denselayer2.norm1.bias\", \"module.imageEncoder.features.denseblock1.denselayer2.norm1.running_mean\", \"module.imageEncoder.features.denseblock1.denselayer2.norm1.running_var\", \"module.imageEncoder.features.denseblock1.denselayer2.conv1.weight\", \"module.imageEncoder.features.denseblock1.denselayer2.norm2.weight\", \"module.imageEncoder.features.denseblock1.denselayer2.norm2.bias\", \"module.imageEncoder.features.denseblock1.denselayer2.norm2.running_mean\", \"module.imageEncoder.features.denseblock1.denselayer2.norm2.running_var\", \"module.imageEncoder.features.denseblock1.denselayer2.conv2.weight\", \"module.imageEncoder.features.denseblock1.denselayer3.norm1.weight\", \"module.imageEncoder.features.denseblock1.denselayer3.norm1.bias\", \"module.imageEncoder.features.denseblock1.denselayer3.norm1.running_mean\", \"module.imageEncoder.features.denseblock1.denselayer3.norm1.running_var\", \"module.imageEncoder.features.denseblock1.denselayer3.conv1.weight\", \"module.imageEncoder.features.denseblock1.denselayer3.norm2.weight\", \"module.imageEncoder.features.denseblock1.denselayer3.norm2.bias\", \"module.imageEncoder.features.denseblock1.denselayer3.norm2.running_mean\", \"module.imageEncoder.features.denseblock1.denselayer3.norm2.running_var\", \"module.imageEncoder.features.denseblock1.denselayer3.conv2.weight\", \"module.imageEncoder.features.denseblock1.denselayer4.norm1.weight\", \"module.imageEncoder.features.denseblock1.denselayer4.norm1.bias\", \"module.imageEncoder.features.denseblock1.denselayer4.norm1.running_mean\", \"module.imageEncoder.features.denseblock1.denselayer4.norm1.running_var\", \"module.imageEncoder.features.denseblock1.denselayer4.conv1.weight\", \"module.imageEncoder.features.denseblock1.denselayer4.norm2.weight\", \"module.imageEncoder.features.denseblock1.denselayer4.norm2.bias\", \"module.imageEncoder.features.denseblock1.denselayer4.norm2.running_mean\", \"module.imageEncoder.features.denseblock1.denselayer4.norm2.running_var\", \"module.imageEncoder.features.denseblock1.denselayer4.conv2.weight\", \"module.imageEncoder.features.denseblock1.denselayer5.norm1.weight\", \"module.imageEncoder.features.denseblock1.denselayer5.norm1.bias\", \"module.imageEncoder.features.denseblock1.denselayer5.norm1.running_mean\", \"module.imageEncoder.features.denseblock1.denselayer5.norm1.running_var\", \"module.imageEncoder.features.denseblock1.denselayer5.conv1.weight\", \"module.imageEncoder.features.denseblock1.denselayer5.norm2.weight\", \"module.imageEncoder.features.denseblock1.denselayer5.norm2.bias\", \"module.imageEncoder.features.denseblock1.denselayer5.norm2.running_mean\", \"module.imageEncoder.features.denseblock1.denselayer5.norm2.running_var\", \"module.imageEncoder.features.denseblock1.denselayer5.conv2.weight\", \"module.imageEncoder.features.denseblock1.denselayer6.norm1.weight\", \"module.imageEncoder.features.denseblock1.denselayer6.norm1.bias\", \"module.imageEncoder.features.denseblock1.denselayer6.norm1.running_mean\", \"module.imageEncoder.features.denseblock1.denselayer6.norm1.running_var\", \"module.imageEncoder.features.denseblock1.denselayer6.conv1.weight\", \"module.imageEncoder.features.denseblock1.denselayer6.norm2.weight\", \"module.imageEncoder.features.denseblock1.denselayer6.norm2.bias\", \"module.imageEncoder.features.denseblock1.denselayer6.norm2.running_mean\", \"module.imageEncoder.features.denseblock1.denselayer6.norm2.running_var\", \"module.imageEncoder.features.denseblock1.denselayer6.conv2.weight\", \"module.imageEncoder.features.transition1.norm.weight\", \"module.imageEncoder.features.transition1.norm.bias\", \"module.imageEncoder.features.transition1.norm.running_mean\", \"module.imageEncoder.features.transition1.norm.running_var\", \"module.imageEncoder.features.transition1.conv.weight\", \"module.imageEncoder.features.denseblock2.denselayer1.norm1.weight\", \"module.imageEncoder.features.denseblock2.denselayer1.norm1.bias\", \"module.imageEncoder.features.denseblock2.denselayer1.norm1.running_mean\", \"module.imageEncoder.features.denseblock2.denselayer1.norm1.running_var\", \"module.imageEncoder.features.denseblock2.denselayer1.conv1.weight\", \"module.imageEncoder.features.denseblock2.denselayer1.norm2.weight\", \"module.imageEncoder.features.denseblock2.denselayer1.norm2.bias\", \"module.imageEncoder.features.denseblock2.denselayer1.norm2.running_mean\", \"module.imageEncoder.features.denseblock2.denselayer1.norm2.running_var\", \"module.imageEncoder.features.denseblock2.denselayer1.conv2.weight\", \"module.imageEncoder.features.denseblock2.denselayer2.norm1.weight\", \"module.imageEncoder.features.denseblock2.denselayer2.norm1.bias\", \"module.imageEncoder.features.denseblock2.denselayer2.norm1.running_mean\", \"module.imageEncoder.features.denseblock2.denselayer2.norm1.running_var\", \"module.imageEncoder.features.denseblock2.denselayer2.conv1.weight\", \"module.imageEncoder.features.denseblock2.denselayer2.norm2.weight\", \"module.imageEncoder.features.denseblock2.denselayer2.norm2.bias\", \"module.imageEncoder.features.denseblock2.denselayer2.norm2.running_mean\", \"module.imageEncoder.features.denseblock2.denselayer2.norm2.running_var\", \"module.imageEncoder.features.denseblock2.denselayer2.conv2.weight\", \"module.imageEncoder.features.denseblock2.denselayer3.norm1.weight\", \"module.imageEncoder.features.denseblock2.denselayer3.norm1.bias\", \"module.imageEncoder.features.denseblock2.denselayer3.norm1.running_mean\", \"module.imageEncoder.features.denseblock2.denselayer3.norm1.running_var\", \"module.imageEncoder.features.denseblock2.denselayer3.conv1.weight\", \"module.imageEncoder.features.denseblock2.denselayer3.norm2.weight\", \"module.imageEncoder.features.denseblock2.denselayer3.norm2.bias\", \"module.imageEncoder.features.denseblock2.denselayer3.norm2.running_mean\", \"module.imageEncoder.features.denseblock2.denselayer3.norm2.running_var\", \"module.imageEncoder.features.denseblock2.denselayer3.conv2.weight\", \"module.imageEncoder.features.denseblock2.denselayer4.norm1.weight\", \"module.imageEncoder.features.denseblock2.denselayer4.norm1.bias\", \"module.imageEncoder.features.denseblock2.denselayer4.norm1.running_mean\", \"module.imageEncoder.features.denseblock2.denselayer4.norm1.running_var\", \"module.imageEncoder.features.denseblock2.denselayer4.conv1.weight\", \"module.imageEncoder.features.denseblock2.denselayer4.norm2.weight\", \"module.imageEncoder.features.denseblock2.denselayer4.norm2.bias\", \"module.imageEncoder.features.denseblock2.denselayer4.norm2.running_mean\", \"module.imageEncoder.features.denseblock2.denselayer4.norm2.running_var\", \"module.imageEncoder.features.denseblock2.denselayer4.conv2.weight\", \"module.imageEncoder.features.denseblock2.denselayer5.norm1.weight\", \"module.imageEncoder.features.denseblock2.denselayer5.norm1.bias\", \"module.imageEncoder.features.denseblock2.denselayer5.norm1.running_mean\", \"module.imageEncoder.features.denseblock2.denselayer5.norm1.running_var\", \"module.imageEncoder.features.denseblock2.denselayer5.conv1.weight\", \"module.imageEncoder.features.denseblock2.denselayer5.norm2.weight\", \"module.imageEncoder.features.denseblock2.denselayer5.norm2.bias\", \"module.imageEncoder.features.denseblock2.denselayer5.norm2.running_mean\", \"module.imageEncoder.features.denseblock2.denselayer5.norm2.running_var\", \"module.imageEncoder.features.denseblock2.denselayer5.conv2.weight\", \"module.imageEncoder.features.denseblock2.denselayer6.norm1.weight\", \"module.imageEncoder.features.denseblock2.denselayer6.norm1.bias\", \"module.imageEncoder.features.denseblock2.denselayer6.norm1.running_mean\", \"module.imageEncoder.features.denseblock2.denselayer6.norm1.running_var\", \"module.imageEncoder.features.denseblock2.denselayer6.conv1.weight\", \"module.imageEncoder.features.denseblock2.denselayer6.norm2.weight\", \"module.imageEncoder.features.denseblock2.denselayer6.norm2.bias\", \"module.imageEncoder.features.denseblock2.denselayer6.norm2.running_mean\", \"module.imageEncoder.features.denseblock2.denselayer6.norm2.running_var\", \"module.imageEncoder.features.denseblock2.denselayer6.conv2.weight\", \"module.imageEncoder.features.denseblock2.denselayer7.norm1.weight\", \"module.imageEncoder.features.denseblock2.denselayer7.norm1.bias\", \"module.imageEncoder.features.denseblock2.denselayer7.norm1.running_mean\", \"module.imageEncoder.features.denseblock2.denselayer7.norm1.running_var\", \"module.imageEncoder.features.denseblock2.denselayer7.conv1.weight\", \"module.imageEncoder.features.denseblock2.denselayer7.norm2.weight\", \"module.imageEncoder.features.denseblock2.denselayer7.norm2.bias\", \"module.imageEncoder.features.denseblock2.denselayer7.norm2.running_mean\", \"module.imageEncoder.features.denseblock2.denselayer7.norm2.running_var\", \"module.imageEncoder.features.denseblock2.denselayer7.conv2.weight\", \"module.imageEncoder.features.denseblock2.denselayer8.norm1.weight\", \"module.imageEncoder.features.denseblock2.denselayer8.norm1.bias\", \"module.imageEncoder.features.denseblock2.denselayer8.norm1.running_mean\", \"module.imageEncoder.features.denseblock2.denselayer8.norm1.running_var\", \"module.imageEncoder.features.denseblock2.denselayer8.conv1.weight\", \"module.imageEncoder.features.denseblock2.denselayer8.norm2.weight\", \"module.imageEncoder.features.denseblock2.denselayer8.norm2.bias\", \"module.imageEncoder.features.denseblock2.denselayer8.norm2.running_mean\", \"module.imageEncoder.features.denseblock2.denselayer8.norm2.running_var\", \"module.imageEncoder.features.denseblock2.denselayer8.conv2.weight\", \"module.imageEncoder.features.denseblock2.denselayer9.norm1.weight\", \"module.imageEncoder.features.denseblock2.denselayer9.norm1.bias\", \"module.imageEncoder.features.denseblock2.denselayer9.norm1.running_mean\", \"module.imageEncoder.features.denseblock2.denselayer9.norm1.running_var\", \"module.imageEncoder.features.denseblock2.denselayer9.conv1.weight\", \"module.imageEncoder.features.denseblock2.denselayer9.norm2.weight\", \"module.imageEncoder.features.denseblock2.denselayer9.norm2.bias\", \"module.imageEncoder.features.denseblock2.denselayer9.norm2.running_mean\", \"module.imageEncoder.features.denseblock2.denselayer9.norm2.running_var\", \"module.imageEncoder.features.denseblock2.denselayer9.conv2.weight\", \"module.imageEncoder.features.denseblock2.denselayer10.norm1.weight\", \"module.imageEncoder.features.denseblock2.denselayer10.norm1.bias\", \"module.imageEncoder.features.denseblock2.denselayer10.norm1.running_mean\", \"module.imageEncoder.features.denseblock2.denselayer10.norm1.running_var\", \"module.imageEncoder.features.denseblock2.denselayer10.conv1.weight\", \"module.imageEncoder.features.denseblock2.denselayer10.norm2.weight\", \"module.imageEncoder.features.denseblock2.denselayer10.norm2.bias\", \"module.imageEncoder.features.denseblock2.denselayer10.norm2.running_mean\", \"module.imageEncoder.features.denseblock2.denselayer10.norm2.running_var\", \"module.imageEncoder.features.denseblock2.denselayer10.conv2.weight\", \"module.imageEncoder.features.denseblock2.denselayer11.norm1.weight\", \"module.imageEncoder.features.denseblock2.denselayer11.norm1.bias\", \"module.imageEncoder.features.denseblock2.denselayer11.norm1.running_mean\", \"module.imageEncoder.features.denseblock2.denselayer11.norm1.running_var\", \"module.imageEncoder.features.denseblock2.denselayer11.conv1.weight\", \"module.imageEncoder.features.denseblock2.denselayer11.norm2.weight\", \"module.imageEncoder.features.denseblock2.denselayer11.norm2.bias\", \"module.imageEncoder.features.denseblock2.denselayer11.norm2.running_mean\", \"module.imageEncoder.features.denseblock2.denselayer11.norm2.running_var\", \"module.imageEncoder.features.denseblock2.denselayer11.conv2.weight\", \"module.imageEncoder.features.denseblock2.denselayer12.norm1.weight\", \"module.imageEncoder.features.denseblock2.denselayer12.norm1.bias\", \"module.imageEncoder.features.denseblock2.denselayer12.norm1.running_mean\", \"module.imageEncoder.features.denseblock2.denselayer12.norm1.running_var\", \"module.imageEncoder.features.denseblock2.denselayer12.conv1.weight\", \"module.imageEncoder.features.denseblock2.denselayer12.norm2.weight\", \"module.imageEncoder.features.denseblock2.denselayer12.norm2.bias\", \"module.imageEncoder.features.denseblock2.denselayer12.norm2.running_mean\", \"module.imageEncoder.features.denseblock2.denselayer12.norm2.running_var\", \"module.imageEncoder.features.denseblock2.denselayer12.conv2.weight\", \"module.imageEncoder.features.transition2.norm.weight\", \"module.imageEncoder.features.transition2.norm.bias\", \"module.imageEncoder.features.transition2.norm.running_mean\", \"module.imageEncoder.features.transition2.norm.running_var\", \"module.imageEncoder.features.transition2.conv.weight\", \"module.imageEncoder.features.denseblock3.denselayer1.norm1.weight\", \"module.imageEncoder.features.denseblock3.denselayer1.norm1.bias\", \"module.imageEncoder.features.denseblock3.denselayer1.norm1.running_mean\", \"module.imageEncoder.features.denseblock3.denselayer1.norm1.running_var\", \"module.imageEncoder.features.denseblock3.denselayer1.conv1.weight\", \"module.imageEncoder.features.denseblock3.denselayer1.norm2.weight\", \"module.imageEncoder.features.denseblock3.denselayer1.norm2.bias\", \"module.imageEncoder.features.denseblock3.denselayer1.norm2.running_mean\", \"module.imageEncoder.features.denseblock3.denselayer1.norm2.running_var\", \"module.imageEncoder.features.denseblock3.denselayer1.conv2.weight\", \"module.imageEncoder.features.denseblock3.denselayer2.norm1.weight\", \"module.imageEncoder.features.denseblock3.denselayer2.norm1.bias\", \"module.imageEncoder.features.denseblock3.denselayer2.norm1.running_mean\", \"module.imageEncoder.features.denseblock3.denselayer2.norm1.running_var\", \"module.imageEncoder.features.denseblock3.denselayer2.conv1.weight\", \"module.imageEncoder.features.denseblock3.denselayer2.norm2.weight\", \"module.imageEncoder.features.denseblock3.denselayer2.norm2.bias\", \"module.imageEncoder.features.denseblock3.denselayer2.norm2.running_mean\", \"module.imageEncoder.features.denseblock3.denselayer2.norm2.running_var\", \"module.imageEncoder.features.denseblock3.denselayer2.conv2.weight\", \"module.imageEncoder.features.denseblock3.denselayer3.norm1.weight\", \"module.imageEncoder.features.denseblock3.denselayer3.norm1.bias\", \"module.imageEncoder.features.denseblock3.denselayer3.norm1.running_mean\", \"module.imageEncoder.features.denseblock3.denselayer3.norm1.running_var\", \"module.imageEncoder.features.denseblock3.denselayer3.conv1.weight\", \"module.imageEncoder.features.denseblock3.denselayer3.norm2.weight\", \"module.imageEncoder.features.denseblock3.denselayer3.norm2.bias\", \"module.imageEncoder.features.denseblock3.denselayer3.norm2.running_mean\", \"module.imageEncoder.features.denseblock3.denselayer3.norm2.running_var\", \"module.imageEncoder.features.denseblock3.denselayer3.conv2.weight\", \"module.imageEncoder.features.denseblock3.denselayer4.norm1.weight\", \"module.imageEncoder.features.denseblock3.denselayer4.norm1.bias\", \"module.imageEncoder.features.denseblock3.denselayer4.norm1.running_mean\", \"module.imageEncoder.features.denseblock3.denselayer4.norm1.running_var\", \"module.imageEncoder.features.denseblock3.denselayer4.conv1.weight\", \"module.imageEncoder.features.denseblock3.denselayer4.norm2.weight\", \"module.imageEncoder.features.denseblock3.denselayer4.norm2.bias\", \"module.imageEncoder.features.denseblock3.denselayer4.norm2.running_mean\", \"module.imageEncoder.features.denseblock3.denselayer4.norm2.running_var\", \"module.imageEncoder.features.denseblock3.denselayer4.conv2.weight\", \"module.imageEncoder.features.denseblock3.denselayer5.norm1.weight\", \"module.imageEncoder.features.denseblock3.denselayer5.norm1.bias\", \"module.imageEncoder.features.denseblock3.denselayer5.norm1.running_mean\", \"module.imageEncoder.features.denseblock3.denselayer5.norm1.running_var\", \"module.imageEncoder.features.denseblock3.denselayer5.conv1.weight\", \"module.imageEncoder.features.denseblock3.denselayer5.norm2.weight\", \"module.imageEncoder.features.denseblock3.denselayer5.norm2.bias\", \"module.imageEncoder.features.denseblock3.denselayer5.norm2.running_mean\", \"module.imageEncoder.features.denseblock3.denselayer5.norm2.running_var\", \"module.imageEncoder.features.denseblock3.denselayer5.conv2.weight\", \"module.imageEncoder.features.denseblock3.denselayer6.norm1.weight\", \"module.imageEncoder.features.denseblock3.denselayer6.norm1.bias\", \"module.imageEncoder.features.denseblock3.denselayer6.norm1.running_mean\", \"module.imageEncoder.features.denseblock3.denselayer6.norm1.running_var\", \"module.imageEncoder.features.denseblock3.denselayer6.conv1.weight\", \"module.imageEncoder.features.denseblock3.denselayer6.norm2.weight\", \"module.imageEncoder.features.denseblock3.denselayer6.norm2.bias\", \"module.imageEncoder.features.denseblock3.denselayer6.norm2.running_mean\", \"module.imageEncoder.features.denseblock3.denselayer6.norm2.running_var\", \"module.imageEncoder.features.denseblock3.denselayer6.conv2.weight\", \"module.imageEncoder.features.denseblock3.denselayer7.norm1.weight\", \"module.imageEncoder.features.denseblock3.denselayer7.norm1.bias\", \"module.imageEncoder.features.denseblock3.denselayer7.norm1.running_mean\", \"module.imageEncoder.features.denseblock3.denselayer7.norm1.running_var\", \"module.imageEncoder.features.denseblock3.denselayer7.conv1.weight\", \"module.imageEncoder.features.denseblock3.denselayer7.norm2.weight\", \"module.imageEncoder.features.denseblock3.denselayer7.norm2.bias\", \"module.imageEncoder.features.denseblock3.denselayer7.norm2.running_mean\", \"module.imageEncoder.features.denseblock3.denselayer7.norm2.running_var\", \"module.imageEncoder.features.denseblock3.denselayer7.conv2.weight\", \"module.imageEncoder.features.denseblock3.denselayer8.norm1.weight\", \"module.imageEncoder.features.denseblock3.denselayer8.norm1.bias\", \"module.imageEncoder.features.denseblock3.denselayer8.norm1.running_mean\", \"module.imageEncoder.features.denseblock3.denselayer8.norm1.running_var\", \"module.imageEncoder.features.denseblock3.denselayer8.conv1.weight\", \"module.imageEncoder.features.denseblock3.denselayer8.norm2.weight\", \"module.imageEncoder.features.denseblock3.denselayer8.norm2.bias\", \"module.imageEncoder.features.denseblock3.denselayer8.norm2.running_mean\", \"module.imageEncoder.features.denseblock3.denselayer8.norm2.running_var\", \"module.imageEncoder.features.denseblock3.denselayer8.conv2.weight\", \"module.imageEncoder.features.denseblock3.denselayer9.norm1.weight\", \"module.imageEncoder.features.denseblock3.denselayer9.norm1.bias\", \"module.imageEncoder.features.denseblock3.denselayer9.norm1.running_mean\", \"module.imageEncoder.features.denseblock3.denselayer9.norm1.running_var\", \"module.imageEncoder.features.denseblock3.denselayer9.conv1.weight\", \"module.imageEncoder.features.denseblock3.denselayer9.norm2.weight\", \"module.imageEncoder.features.denseblock3.denselayer9.norm2.bias\", \"module.imageEncoder.features.denseblock3.denselayer9.norm2.running_mean\", \"module.imageEncoder.features.denseblock3.denselayer9.norm2.running_var\", \"module.imageEncoder.features.denseblock3.denselayer9.conv2.weight\", \"module.imageEncoder.features.denseblock3.denselayer10.norm1.weight\", \"module.imageEncoder.features.denseblock3.denselayer10.norm1.bias\", \"module.imageEncoder.features.denseblock3.denselayer10.norm1.running_mean\", \"module.imageEncoder.features.denseblock3.denselayer10.norm1.running_var\", \"module.imageEncoder.features.denseblock3.denselayer10.conv1.weight\", \"module.imageEncoder.features.denseblock3.denselayer10.norm2.weight\", \"module.imageEncoder.features.denseblock3.denselayer10.norm2.bias\", \"module.imageEncoder.features.denseblock3.denselayer10.norm2.running_mean\", \"module.imageEncoder.features.denseblock3.denselayer10.norm2.running_var\", \"module.imageEncoder.features.denseblock3.denselayer10.conv2.weight\", \"module.imageEncoder.features.denseblock3.denselayer11.norm1.weight\", \"module.imageEncoder.features.denseblock3.denselayer11.norm1.bias\", \"module.imageEncoder.features.denseblock3.denselayer11.norm1.running_mean\", \"module.imageEncoder.features.denseblock3.denselayer11.norm1.running_var\", \"module.imageEncoder.features.denseblock3.denselayer11.conv1.weight\", \"module.imageEncoder.features.denseblock3.denselayer11.norm2.weight\", \"module.imageEncoder.features.denseblock3.denselayer11.norm2.bias\", \"module.imageEncoder.features.denseblock3.denselayer11.norm2.running_mean\", \"module.imageEncoder.features.denseblock3.denselayer11.norm2.running_var\", \"module.imageEncoder.features.denseblock3.denselayer11.conv2.weight\", \"module.imageEncoder.features.denseblock3.denselayer12.norm1.weight\", \"module.imageEncoder.features.denseblock3.denselayer12.norm1.bias\", \"module.imageEncoder.features.denseblock3.denselayer12.norm1.running_mean\", \"module.imageEncoder.features.denseblock3.denselayer12.norm1.running_var\", \"module.imageEncoder.features.denseblock3.denselayer12.conv1.weight\", \"module.imageEncoder.features.denseblock3.denselayer12.norm2.weight\", \"module.imageEncoder.features.denseblock3.denselayer12.norm2.bias\", \"module.imageEncoder.features.denseblock3.denselayer12.norm2.running_mean\", \"module.imageEncoder.features.denseblock3.denselayer12.norm2.running_var\", \"module.imageEncoder.features.denseblock3.denselayer12.conv2.weight\", \"module.imageEncoder.features.denseblock3.denselayer13.norm1.weight\", \"module.imageEncoder.features.denseblock3.denselayer13.norm1.bias\", \"module.imageEncoder.features.denseblock3.denselayer13.norm1.running_mean\", \"module.imageEncoder.features.denseblock3.denselayer13.norm1.running_var\", \"module.imageEncoder.features.denseblock3.denselayer13.conv1.weight\", \"module.imageEncoder.features.denseblock3.denselayer13.norm2.weight\", \"module.imageEncoder.features.denseblock3.denselayer13.norm2.bias\", \"module.imageEncoder.features.denseblock3.denselayer13.norm2.running_mean\", \"module.imageEncoder.features.denseblock3.denselayer13.norm2.running_var\", \"module.imageEncoder.features.denseblock3.denselayer13.conv2.weight\", \"module.imageEncoder.features.denseblock3.denselayer14.norm1.weight\", \"module.imageEncoder.features.denseblock3.denselayer14.norm1.bias\", \"module.imageEncoder.features.denseblock3.denselayer14.norm1.running_mean\", \"module.imageEncoder.features.denseblock3.denselayer14.norm1.running_var\", \"module.imageEncoder.features.denseblock3.denselayer14.conv1.weight\", \"module.imageEncoder.features.denseblock3.denselayer14.norm2.weight\", \"module.imageEncoder.features.denseblock3.denselayer14.norm2.bias\", \"module.imageEncoder.features.denseblock3.denselayer14.norm2.running_mean\", \"module.imageEncoder.features.denseblock3.denselayer14.norm2.running_var\", \"module.imageEncoder.features.denseblock3.denselayer14.conv2.weight\", \"module.imageEncoder.features.denseblock3.denselayer15.norm1.weight\", \"module.imageEncoder.features.denseblock3.denselayer15.norm1.bias\", \"module.imageEncoder.features.denseblock3.denselayer15.norm1.running_mean\", \"module.imageEncoder.features.denseblock3.denselayer15.norm1.running_var\", \"module.imageEncoder.features.denseblock3.denselayer15.conv1.weight\", \"module.imageEncoder.features.denseblock3.denselayer15.norm2.weight\", \"module.imageEncoder.features.denseblock3.denselayer15.norm2.bias\", \"module.imageEncoder.features.denseblock3.denselayer15.norm2.running_mean\", \"module.imageEncoder.features.denseblock3.denselayer15.norm2.running_var\", \"module.imageEncoder.features.denseblock3.denselayer15.conv2.weight\", \"module.imageEncoder.features.denseblock3.denselayer16.norm1.weight\", \"module.imageEncoder.features.denseblock3.denselayer16.norm1.bias\", \"module.imageEncoder.features.denseblock3.denselayer16.norm1.running_mean\", \"module.imageEncoder.features.denseblock3.denselayer16.norm1.running_var\", \"module.imageEncoder.features.denseblock3.denselayer16.conv1.weight\", \"module.imageEncoder.features.denseblock3.denselayer16.norm2.weight\", \"module.imageEncoder.features.denseblock3.denselayer16.norm2.bias\", \"module.imageEncoder.features.denseblock3.denselayer16.norm2.running_mean\", \"module.imageEncoder.features.denseblock3.denselayer16.norm2.running_var\", \"module.imageEncoder.features.denseblock3.denselayer16.conv2.weight\", \"module.imageEncoder.features.denseblock3.denselayer17.norm1.weight\", \"module.imageEncoder.features.denseblock3.denselayer17.norm1.bias\", \"module.imageEncoder.features.denseblock3.denselayer17.norm1.running_mean\", \"module.imageEncoder.features.denseblock3.denselayer17.norm1.running_var\", \"module.imageEncoder.features.denseblock3.denselayer17.conv1.weight\", \"module.imageEncoder.features.denseblock3.denselayer17.norm2.weight\", \"module.imageEncoder.features.denseblock3.denselayer17.norm2.bias\", \"module.imageEncoder.features.denseblock3.denselayer17.norm2.running_mean\", \"module.imageEncoder.features.denseblock3.denselayer17.norm2.running_var\", \"module.imageEncoder.features.denseblock3.denselayer17.conv2.weight\", \"module.imageEncoder.features.denseblock3.denselayer18.norm1.weight\", \"module.imageEncoder.features.denseblock3.denselayer18.norm1.bias\", \"module.imageEncoder.features.denseblock3.denselayer18.norm1.running_mean\", \"module.imageEncoder.features.denseblock3.denselayer18.norm1.running_var\", \"module.imageEncoder.features.denseblock3.denselayer18.conv1.weight\", \"module.imageEncoder.features.denseblock3.denselayer18.norm2.weight\", \"module.imageEncoder.features.denseblock3.denselayer18.norm2.bias\", \"module.imageEncoder.features.denseblock3.denselayer18.norm2.running_mean\", \"module.imageEncoder.features.denseblock3.denselayer18.norm2.running_var\", \"module.imageEncoder.features.denseblock3.denselayer18.conv2.weight\", \"module.imageEncoder.features.denseblock3.denselayer19.norm1.weight\", \"module.imageEncoder.features.denseblock3.denselayer19.norm1.bias\", \"module.imageEncoder.features.denseblock3.denselayer19.norm1.running_mean\", \"module.imageEncoder.features.denseblock3.denselayer19.norm1.running_var\", \"module.imageEncoder.features.denseblock3.denselayer19.conv1.weight\", \"module.imageEncoder.features.denseblock3.denselayer19.norm2.weight\", \"module.imageEncoder.features.denseblock3.denselayer19.norm2.bias\", \"module.imageEncoder.features.denseblock3.denselayer19.norm2.running_mean\", \"module.imageEncoder.features.denseblock3.denselayer19.norm2.running_var\", \"module.imageEncoder.features.denseblock3.denselayer19.conv2.weight\", \"module.imageEncoder.features.denseblock3.denselayer20.norm1.weight\", \"module.imageEncoder.features.denseblock3.denselayer20.norm1.bias\", \"module.imageEncoder.features.denseblock3.denselayer20.norm1.running_mean\", \"module.imageEncoder.features.denseblock3.denselayer20.norm1.running_var\", \"module.imageEncoder.features.denseblock3.denselayer20.conv1.weight\", \"module.imageEncoder.features.denseblock3.denselayer20.norm2.weight\", \"module.imageEncoder.features.denseblock3.denselayer20.norm2.bias\", \"module.imageEncoder.features.denseblock3.denselayer20.norm2.running_mean\", \"module.imageEncoder.features.denseblock3.denselayer20.norm2.running_var\", \"module.imageEncoder.features.denseblock3.denselayer20.conv2.weight\", \"module.imageEncoder.features.denseblock3.denselayer21.norm1.weight\", \"module.imageEncoder.features.denseblock3.denselayer21.norm1.bias\", \"module.imageEncoder.features.denseblock3.denselayer21.norm1.running_mean\", \"module.imageEncoder.features.denseblock3.denselayer21.norm1.running_var\", \"module.imageEncoder.features.denseblock3.denselayer21.conv1.weight\", \"module.imageEncoder.features.denseblock3.denselayer21.norm2.weight\", \"module.imageEncoder.features.denseblock3.denselayer21.norm2.bias\", \"module.imageEncoder.features.denseblock3.denselayer21.norm2.running_mean\", \"module.imageEncoder.features.denseblock3.denselayer21.norm2.running_var\", \"module.imageEncoder.features.denseblock3.denselayer21.conv2.weight\", \"module.imageEncoder.features.denseblock3.denselayer22.norm1.weight\", \"module.imageEncoder.features.denseblock3.denselayer22.norm1.bias\", \"module.imageEncoder.features.denseblock3.denselayer22.norm1.running_mean\", \"module.imageEncoder.features.denseblock3.denselayer22.norm1.running_var\", \"module.imageEncoder.features.denseblock3.denselayer22.conv1.weight\", \"module.imageEncoder.features.denseblock3.denselayer22.norm2.weight\", \"module.imageEncoder.features.denseblock3.denselayer22.norm2.bias\", \"module.imageEncoder.features.denseblock3.denselayer22.norm2.running_mean\", \"module.imageEncoder.features.denseblock3.denselayer22.norm2.running_var\", \"module.imageEncoder.features.denseblock3.denselayer22.conv2.weight\", \"module.imageEncoder.features.denseblock3.denselayer23.norm1.weight\", \"module.imageEncoder.features.denseblock3.denselayer23.norm1.bias\", \"module.imageEncoder.features.denseblock3.denselayer23.norm1.running_mean\", \"module.imageEncoder.features.denseblock3.denselayer23.norm1.running_var\", \"module.imageEncoder.features.denseblock3.denselayer23.conv1.weight\", \"module.imageEncoder.features.denseblock3.denselayer23.norm2.weight\", \"module.imageEncoder.features.denseblock3.denselayer23.norm2.bias\", \"module.imageEncoder.features.denseblock3.denselayer23.norm2.running_mean\", \"module.imageEncoder.features.denseblock3.denselayer23.norm2.running_var\", \"module.imageEncoder.features.denseblock3.denselayer23.conv2.weight\", \"module.imageEncoder.features.denseblock3.denselayer24.norm1.weight\", \"module.imageEncoder.features.denseblock3.denselayer24.norm1.bias\", \"module.imageEncoder.features.denseblock3.denselayer24.norm1.running_mean\", \"module.imageEncoder.features.denseblock3.denselayer24.norm1.running_var\", \"module.imageEncoder.features.denseblock3.denselayer24.conv1.weight\", \"module.imageEncoder.features.denseblock3.denselayer24.norm2.weight\", \"module.imageEncoder.features.denseblock3.denselayer24.norm2.bias\", \"module.imageEncoder.features.denseblock3.denselayer24.norm2.running_mean\", \"module.imageEncoder.features.denseblock3.denselayer24.norm2.running_var\", \"module.imageEncoder.features.denseblock3.denselayer24.conv2.weight\", \"module.imageEncoder.features.denseblock3.denselayer25.norm1.weight\", \"module.imageEncoder.features.denseblock3.denselayer25.norm1.bias\", \"module.imageEncoder.features.denseblock3.denselayer25.norm1.running_mean\", \"module.imageEncoder.features.denseblock3.denselayer25.norm1.running_var\", \"module.imageEncoder.features.denseblock3.denselayer25.conv1.weight\", \"module.imageEncoder.features.denseblock3.denselayer25.norm2.weight\", \"module.imageEncoder.features.denseblock3.denselayer25.norm2.bias\", \"module.imageEncoder.features.denseblock3.denselayer25.norm2.running_mean\", \"module.imageEncoder.features.denseblock3.denselayer25.norm2.running_var\", \"module.imageEncoder.features.denseblock3.denselayer25.conv2.weight\", \"module.imageEncoder.features.denseblock3.denselayer26.norm1.weight\", \"module.imageEncoder.features.denseblock3.denselayer26.norm1.bias\", \"module.imageEncoder.features.denseblock3.denselayer26.norm1.running_mean\", \"module.imageEncoder.features.denseblock3.denselayer26.norm1.running_var\", \"module.imageEncoder.features.denseblock3.denselayer26.conv1.weight\", \"module.imageEncoder.features.denseblock3.denselayer26.norm2.weight\", \"module.imageEncoder.features.denseblock3.denselayer26.norm2.bias\", \"module.imageEncoder.features.denseblock3.denselayer26.norm2.running_mean\", \"module.imageEncoder.features.denseblock3.denselayer26.norm2.running_var\", \"module.imageEncoder.features.denseblock3.denselayer26.conv2.weight\", \"module.imageEncoder.features.denseblock3.denselayer27.norm1.weight\", \"module.imageEncoder.features.denseblock3.denselayer27.norm1.bias\", \"module.imageEncoder.features.denseblock3.denselayer27.norm1.running_mean\", \"module.imageEncoder.features.denseblock3.denselayer27.norm1.running_var\", \"module.imageEncoder.features.denseblock3.denselayer27.conv1.weight\", \"module.imageEncoder.features.denseblock3.denselayer27.norm2.weight\", \"module.imageEncoder.features.denseblock3.denselayer27.norm2.bias\", \"module.imageEncoder.features.denseblock3.denselayer27.norm2.running_mean\", \"module.imageEncoder.features.denseblock3.denselayer27.norm2.running_var\", \"module.imageEncoder.features.denseblock3.denselayer27.conv2.weight\", \"module.imageEncoder.features.denseblock3.denselayer28.norm1.weight\", \"module.imageEncoder.features.denseblock3.denselayer28.norm1.bias\", \"module.imageEncoder.features.denseblock3.denselayer28.norm1.running_mean\", \"module.imageEncoder.features.denseblock3.denselayer28.norm1.running_var\", \"module.imageEncoder.features.denseblock3.denselayer28.conv1.weight\", \"module.imageEncoder.features.denseblock3.denselayer28.norm2.weight\", \"module.imageEncoder.features.denseblock3.denselayer28.norm2.bias\", \"module.imageEncoder.features.denseblock3.denselayer28.norm2.running_mean\", \"module.imageEncoder.features.denseblock3.denselayer28.norm2.running_var\", \"module.imageEncoder.features.denseblock3.denselayer28.conv2.weight\", \"module.imageEncoder.features.denseblock3.denselayer29.norm1.weight\", \"module.imageEncoder.features.denseblock3.denselayer29.norm1.bias\", \"module.imageEncoder.features.denseblock3.denselayer29.norm1.running_mean\", \"module.imageEncoder.features.denseblock3.denselayer29.norm1.running_var\", \"module.imageEncoder.features.denseblock3.denselayer29.conv1.weight\", \"module.imageEncoder.features.denseblock3.denselayer29.norm2.weight\", \"module.imageEncoder.features.denseblock3.denselayer29.norm2.bias\", \"module.imageEncoder.features.denseblock3.denselayer29.norm2.running_mean\", \"module.imageEncoder.features.denseblock3.denselayer29.norm2.running_var\", \"module.imageEncoder.features.denseblock3.denselayer29.conv2.weight\", \"module.imageEncoder.features.denseblock3.denselayer30.norm1.weight\", \"module.imageEncoder.features.denseblock3.denselayer30.norm1.bias\", \"module.imageEncoder.features.denseblock3.denselayer30.norm1.running_mean\", \"module.imageEncoder.features.denseblock3.denselayer30.norm1.running_var\", \"module.imageEncoder.features.denseblock3.denselayer30.conv1.weight\", \"module.imageEncoder.features.denseblock3.denselayer30.norm2.weight\", \"module.imageEncoder.features.denseblock3.denselayer30.norm2.bias\", \"module.imageEncoder.features.denseblock3.denselayer30.norm2.running_mean\", \"module.imageEncoder.features.denseblock3.denselayer30.norm2.running_var\", \"module.imageEncoder.features.denseblock3.denselayer30.conv2.weight\", \"module.imageEncoder.features.denseblock3.denselayer31.norm1.weight\", \"module.imageEncoder.features.denseblock3.denselayer31.norm1.bias\", \"module.imageEncoder.features.denseblock3.denselayer31.norm1.running_mean\", \"module.imageEncoder.features.denseblock3.denselayer31.norm1.running_var\", \"module.imageEncoder.features.denseblock3.denselayer31.conv1.weight\", \"module.imageEncoder.features.denseblock3.denselayer31.norm2.weight\", \"module.imageEncoder.features.denseblock3.denselayer31.norm2.bias\", \"module.imageEncoder.features.denseblock3.denselayer31.norm2.running_mean\", \"module.imageEncoder.features.denseblock3.denselayer31.norm2.running_var\", \"module.imageEncoder.features.denseblock3.denselayer31.conv2.weight\", \"module.imageEncoder.features.denseblock3.denselayer32.norm1.weight\", \"module.imageEncoder.features.denseblock3.denselayer32.norm1.bias\", \"module.imageEncoder.features.denseblock3.denselayer32.norm1.running_mean\", \"module.imageEncoder.features.denseblock3.denselayer32.norm1.running_var\", \"module.imageEncoder.features.denseblock3.denselayer32.conv1.weight\", \"module.imageEncoder.features.denseblock3.denselayer32.norm2.weight\", \"module.imageEncoder.features.denseblock3.denselayer32.norm2.bias\", \"module.imageEncoder.features.denseblock3.denselayer32.norm2.running_mean\", \"module.imageEncoder.features.denseblock3.denselayer32.norm2.running_var\", \"module.imageEncoder.features.denseblock3.denselayer32.conv2.weight\", \"module.imageEncoder.features.denseblock3.denselayer33.norm1.weight\", \"module.imageEncoder.features.denseblock3.denselayer33.norm1.bias\", \"module.imageEncoder.features.denseblock3.denselayer33.norm1.running_mean\", \"module.imageEncoder.features.denseblock3.denselayer33.norm1.running_var\", \"module.imageEncoder.features.denseblock3.denselayer33.conv1.weight\", \"module.imageEncoder.features.denseblock3.denselayer33.norm2.weight\", \"module.imageEncoder.features.denseblock3.denselayer33.norm2.bias\", \"module.imageEncoder.features.denseblock3.denselayer33.norm2.running_mean\", \"module.imageEncoder.features.denseblock3.denselayer33.norm2.running_var\", \"module.imageEncoder.features.denseblock3.denselayer33.conv2.weight\", \"module.imageEncoder.features.denseblock3.denselayer34.norm1.weight\", \"module.imageEncoder.features.denseblock3.denselayer34.norm1.bias\", \"module.imageEncoder.features.denseblock3.denselayer34.norm1.running_mean\", \"module.imageEncoder.features.denseblock3.denselayer34.norm1.running_var\", \"module.imageEncoder.features.denseblock3.denselayer34.conv1.weight\", \"module.imageEncoder.features.denseblock3.denselayer34.norm2.weight\", \"module.imageEncoder.features.denseblock3.denselayer34.norm2.bias\", \"module.imageEncoder.features.denseblock3.denselayer34.norm2.running_mean\", \"module.imageEncoder.features.denseblock3.denselayer34.norm2.running_var\", \"module.imageEncoder.features.denseblock3.denselayer34.conv2.weight\", \"module.imageEncoder.features.denseblock3.denselayer35.norm1.weight\", \"module.imageEncoder.features.denseblock3.denselayer35.norm1.bias\", \"module.imageEncoder.features.denseblock3.denselayer35.norm1.running_mean\", \"module.imageEncoder.features.denseblock3.denselayer35.norm1.running_var\", \"module.imageEncoder.features.denseblock3.denselayer35.conv1.weight\", \"module.imageEncoder.features.denseblock3.denselayer35.norm2.weight\", \"module.imageEncoder.features.denseblock3.denselayer35.norm2.bias\", \"module.imageEncoder.features.denseblock3.denselayer35.norm2.running_mean\", \"module.imageEncoder.features.denseblock3.denselayer35.norm2.running_var\", \"module.imageEncoder.features.denseblock3.denselayer35.conv2.weight\", \"module.imageEncoder.features.denseblock3.denselayer36.norm1.weight\", \"module.imageEncoder.features.denseblock3.denselayer36.norm1.bias\", \"module.imageEncoder.features.denseblock3.denselayer36.norm1.running_mean\", \"module.imageEncoder.features.denseblock3.denselayer36.norm1.running_var\", \"module.imageEncoder.features.denseblock3.denselayer36.conv1.weight\", \"module.imageEncoder.features.denseblock3.denselayer36.norm2.weight\", \"module.imageEncoder.features.denseblock3.denselayer36.norm2.bias\", \"module.imageEncoder.features.denseblock3.denselayer36.norm2.running_mean\", \"module.imageEncoder.features.denseblock3.denselayer36.norm2.running_var\", \"module.imageEncoder.features.denseblock3.denselayer36.conv2.weight\", \"module.imageEncoder.features.denseblock3.denselayer37.norm1.weight\", \"module.imageEncoder.features.denseblock3.denselayer37.norm1.bias\", \"module.imageEncoder.features.denseblock3.denselayer37.norm1.running_mean\", \"module.imageEncoder.features.denseblock3.denselayer37.norm1.running_var\", \"module.imageEncoder.features.denseblock3.denselayer37.conv1.weight\", \"module.imageEncoder.features.denseblock3.denselayer37.norm2.weight\", \"module.imageEncoder.features.denseblock3.denselayer37.norm2.bias\", \"module.imageEncoder.features.denseblock3.denselayer37.norm2.running_mean\", \"module.imageEncoder.features.denseblock3.denselayer37.norm2.running_var\", \"module.imageEncoder.features.denseblock3.denselayer37.conv2.weight\", \"module.imageEncoder.features.denseblock3.denselayer38.norm1.weight\", \"module.imageEncoder.features.denseblock3.denselayer38.norm1.bias\", \"module.imageEncoder.features.denseblock3.denselayer38.norm1.running_mean\", \"module.imageEncoder.features.denseblock3.denselayer38.norm1.running_var\", \"module.imageEncoder.features.denseblock3.denselayer38.conv1.weight\", \"module.imageEncoder.features.denseblock3.denselayer38.norm2.weight\", \"module.imageEncoder.features.denseblock3.denselayer38.norm2.bias\", \"module.imageEncoder.features.denseblock3.denselayer38.norm2.running_mean\", \"module.imageEncoder.features.denseblock3.denselayer38.norm2.running_var\", \"module.imageEncoder.features.denseblock3.denselayer38.conv2.weight\", \"module.imageEncoder.features.denseblock3.denselayer39.norm1.weight\", \"module.imageEncoder.features.denseblock3.denselayer39.norm1.bias\", \"module.imageEncoder.features.denseblock3.denselayer39.norm1.running_mean\", \"module.imageEncoder.features.denseblock3.denselayer39.norm1.running_var\", \"module.imageEncoder.features.denseblock3.denselayer39.conv1.weight\", \"module.imageEncoder.features.denseblock3.denselayer39.norm2.weight\", \"module.imageEncoder.features.denseblock3.denselayer39.norm2.bias\", \"module.imageEncoder.features.denseblock3.denselayer39.norm2.running_mean\", \"module.imageEncoder.features.denseblock3.denselayer39.norm2.running_var\", \"module.imageEncoder.features.denseblock3.denselayer39.conv2.weight\", \"module.imageEncoder.features.denseblock3.denselayer40.norm1.weight\", \"module.imageEncoder.features.denseblock3.denselayer40.norm1.bias\", \"module.imageEncoder.features.denseblock3.denselayer40.norm1.running_mean\", \"module.imageEncoder.features.denseblock3.denselayer40.norm1.running_var\", \"module.imageEncoder.features.denseblock3.denselayer40.conv1.weight\", \"module.imageEncoder.features.denseblock3.denselayer40.norm2.weight\", \"module.imageEncoder.features.denseblock3.denselayer40.norm2.bias\", \"module.imageEncoder.features.denseblock3.denselayer40.norm2.running_mean\", \"module.imageEncoder.features.denseblock3.denselayer40.norm2.running_var\", \"module.imageEncoder.features.denseblock3.denselayer40.conv2.weight\", \"module.imageEncoder.features.denseblock3.denselayer41.norm1.weight\", \"module.imageEncoder.features.denseblock3.denselayer41.norm1.bias\", \"module.imageEncoder.features.denseblock3.denselayer41.norm1.running_mean\", \"module.imageEncoder.features.denseblock3.denselayer41.norm1.running_var\", \"module.imageEncoder.features.denseblock3.denselayer41.conv1.weight\", \"module.imageEncoder.features.denseblock3.denselayer41.norm2.weight\", \"module.imageEncoder.features.denseblock3.denselayer41.norm2.bias\", \"module.imageEncoder.features.denseblock3.denselayer41.norm2.running_mean\", \"module.imageEncoder.features.denseblock3.denselayer41.norm2.running_var\", \"module.imageEncoder.features.denseblock3.denselayer41.conv2.weight\", \"module.imageEncoder.features.denseblock3.denselayer42.norm1.weight\", \"module.imageEncoder.features.denseblock3.denselayer42.norm1.bias\", \"module.imageEncoder.features.denseblock3.denselayer42.norm1.running_mean\", \"module.imageEncoder.features.denseblock3.denselayer42.norm1.running_var\", \"module.imageEncoder.features.denseblock3.denselayer42.conv1.weight\", \"module.imageEncoder.features.denseblock3.denselayer42.norm2.weight\", \"module.imageEncoder.features.denseblock3.denselayer42.norm2.bias\", \"module.imageEncoder.features.denseblock3.denselayer42.norm2.running_mean\", \"module.imageEncoder.features.denseblock3.denselayer42.norm2.running_var\", \"module.imageEncoder.features.denseblock3.denselayer42.conv2.weight\", \"module.imageEncoder.features.denseblock3.denselayer43.norm1.weight\", \"module.imageEncoder.features.denseblock3.denselayer43.norm1.bias\", \"module.imageEncoder.features.denseblock3.denselayer43.norm1.running_mean\", \"module.imageEncoder.features.denseblock3.denselayer43.norm1.running_var\", \"module.imageEncoder.features.denseblock3.denselayer43.conv1.weight\", \"module.imageEncoder.features.denseblock3.denselayer43.norm2.weight\", \"module.imageEncoder.features.denseblock3.denselayer43.norm2.bias\", \"module.imageEncoder.features.denseblock3.denselayer43.norm2.running_mean\", \"module.imageEncoder.features.denseblock3.denselayer43.norm2.running_var\", \"module.imageEncoder.features.denseblock3.denselayer43.conv2.weight\", \"module.imageEncoder.features.denseblock3.denselayer44.norm1.weight\", \"module.imageEncoder.features.denseblock3.denselayer44.norm1.bias\", \"module.imageEncoder.features.denseblock3.denselayer44.norm1.running_mean\", \"module.imageEncoder.features.denseblock3.denselayer44.norm1.running_var\", \"module.imageEncoder.features.denseblock3.denselayer44.conv1.weight\", \"module.imageEncoder.features.denseblock3.denselayer44.norm2.weight\", \"module.imageEncoder.features.denseblock3.denselayer44.norm2.bias\", \"module.imageEncoder.features.denseblock3.denselayer44.norm2.running_mean\", \"module.imageEncoder.features.denseblock3.denselayer44.norm2.running_var\", \"module.imageEncoder.features.denseblock3.denselayer44.conv2.weight\", \"module.imageEncoder.features.denseblock3.denselayer45.norm1.weight\", \"module.imageEncoder.features.denseblock3.denselayer45.norm1.bias\", \"module.imageEncoder.features.denseblock3.denselayer45.norm1.running_mean\", \"module.imageEncoder.features.denseblock3.denselayer45.norm1.running_var\", \"module.imageEncoder.features.denseblock3.denselayer45.conv1.weight\", \"module.imageEncoder.features.denseblock3.denselayer45.norm2.weight\", \"module.imageEncoder.features.denseblock3.denselayer45.norm2.bias\", \"module.imageEncoder.features.denseblock3.denselayer45.norm2.running_mean\", \"module.imageEncoder.features.denseblock3.denselayer45.norm2.running_var\", \"module.imageEncoder.features.denseblock3.denselayer45.conv2.weight\", \"module.imageEncoder.features.denseblock3.denselayer46.norm1.weight\", \"module.imageEncoder.features.denseblock3.denselayer46.norm1.bias\", \"module.imageEncoder.features.denseblock3.denselayer46.norm1.running_mean\", \"module.imageEncoder.features.denseblock3.denselayer46.norm1.running_var\", \"module.imageEncoder.features.denseblock3.denselayer46.conv1.weight\", \"module.imageEncoder.features.denseblock3.denselayer46.norm2.weight\", \"module.imageEncoder.features.denseblock3.denselayer46.norm2.bias\", \"module.imageEncoder.features.denseblock3.denselayer46.norm2.running_mean\", \"module.imageEncoder.features.denseblock3.denselayer46.norm2.running_var\", \"module.imageEncoder.features.denseblock3.denselayer46.conv2.weight\", \"module.imageEncoder.features.denseblock3.denselayer47.norm1.weight\", \"module.imageEncoder.features.denseblock3.denselayer47.norm1.bias\", \"module.imageEncoder.features.denseblock3.denselayer47.norm1.running_mean\", \"module.imageEncoder.features.denseblock3.denselayer47.norm1.running_var\", \"module.imageEncoder.features.denseblock3.denselayer47.conv1.weight\", \"module.imageEncoder.features.denseblock3.denselayer47.norm2.weight\", \"module.imageEncoder.features.denseblock3.denselayer47.norm2.bias\", \"module.imageEncoder.features.denseblock3.denselayer47.norm2.running_mean\", \"module.imageEncoder.features.denseblock3.denselayer47.norm2.running_var\", \"module.imageEncoder.features.denseblock3.denselayer47.conv2.weight\", \"module.imageEncoder.features.denseblock3.denselayer48.norm1.weight\", \"module.imageEncoder.features.denseblock3.denselayer48.norm1.bias\", \"module.imageEncoder.features.denseblock3.denselayer48.norm1.running_mean\", \"module.imageEncoder.features.denseblock3.denselayer48.norm1.running_var\", \"module.imageEncoder.features.denseblock3.denselayer48.conv1.weight\", \"module.imageEncoder.features.denseblock3.denselayer48.norm2.weight\", \"module.imageEncoder.features.denseblock3.denselayer48.norm2.bias\", \"module.imageEncoder.features.denseblock3.denselayer48.norm2.running_mean\", \"module.imageEncoder.features.denseblock3.denselayer48.norm2.running_var\", \"module.imageEncoder.features.denseblock3.denselayer48.conv2.weight\", \"module.imageEncoder.features.transition3.norm.weight\", \"module.imageEncoder.features.transition3.norm.bias\", \"module.imageEncoder.features.transition3.norm.running_mean\", \"module.imageEncoder.features.transition3.norm.running_var\", \"module.imageEncoder.features.transition3.conv.weight\", \"module.imageEncoder.features.denseblock4.denselayer1.norm1.weight\", \"module.imageEncoder.features.denseblock4.denselayer1.norm1.bias\", \"module.imageEncoder.features.denseblock4.denselayer1.norm1.running_mean\", \"module.imageEncoder.features.denseblock4.denselayer1.norm1.running_var\", \"module.imageEncoder.features.denseblock4.denselayer1.conv1.weight\", \"module.imageEncoder.features.denseblock4.denselayer1.norm2.weight\", \"module.imageEncoder.features.denseblock4.denselayer1.norm2.bias\", \"module.imageEncoder.features.denseblock4.denselayer1.norm2.running_mean\", \"module.imageEncoder.features.denseblock4.denselayer1.norm2.running_var\", \"module.imageEncoder.features.denseblock4.denselayer1.conv2.weight\", \"module.imageEncoder.features.denseblock4.denselayer2.norm1.weight\", \"module.imageEncoder.features.denseblock4.denselayer2.norm1.bias\", \"module.imageEncoder.features.denseblock4.denselayer2.norm1.running_mean\", \"module.imageEncoder.features.denseblock4.denselayer2.norm1.running_var\", \"module.imageEncoder.features.denseblock4.denselayer2.conv1.weight\", \"module.imageEncoder.features.denseblock4.denselayer2.norm2.weight\", \"module.imageEncoder.features.denseblock4.denselayer2.norm2.bias\", \"module.imageEncoder.features.denseblock4.denselayer2.norm2.running_mean\", \"module.imageEncoder.features.denseblock4.denselayer2.norm2.running_var\", \"module.imageEncoder.features.denseblock4.denselayer2.conv2.weight\", \"module.imageEncoder.features.denseblock4.denselayer3.norm1.weight\", \"module.imageEncoder.features.denseblock4.denselayer3.norm1.bias\", \"module.imageEncoder.features.denseblock4.denselayer3.norm1.running_mean\", \"module.imageEncoder.features.denseblock4.denselayer3.norm1.running_var\", \"module.imageEncoder.features.denseblock4.denselayer3.conv1.weight\", \"module.imageEncoder.features.denseblock4.denselayer3.norm2.weight\", \"module.imageEncoder.features.denseblock4.denselayer3.norm2.bias\", \"module.imageEncoder.features.denseblock4.denselayer3.norm2.running_mean\", \"module.imageEncoder.features.denseblock4.denselayer3.norm2.running_var\", \"module.imageEncoder.features.denseblock4.denselayer3.conv2.weight\", \"module.imageEncoder.features.denseblock4.denselayer4.norm1.weight\", \"module.imageEncoder.features.denseblock4.denselayer4.norm1.bias\", \"module.imageEncoder.features.denseblock4.denselayer4.norm1.running_mean\", \"module.imageEncoder.features.denseblock4.denselayer4.norm1.running_var\", \"module.imageEncoder.features.denseblock4.denselayer4.conv1.weight\", \"module.imageEncoder.features.denseblock4.denselayer4.norm2.weight\", \"module.imageEncoder.features.denseblock4.denselayer4.norm2.bias\", \"module.imageEncoder.features.denseblock4.denselayer4.norm2.running_mean\", \"module.imageEncoder.features.denseblock4.denselayer4.norm2.running_var\", \"module.imageEncoder.features.denseblock4.denselayer4.conv2.weight\", \"module.imageEncoder.features.denseblock4.denselayer5.norm1.weight\", \"module.imageEncoder.features.denseblock4.denselayer5.norm1.bias\", \"module.imageEncoder.features.denseblock4.denselayer5.norm1.running_mean\", \"module.imageEncoder.features.denseblock4.denselayer5.norm1.running_var\", \"module.imageEncoder.features.denseblock4.denselayer5.conv1.weight\", \"module.imageEncoder.features.denseblock4.denselayer5.norm2.weight\", \"module.imageEncoder.features.denseblock4.denselayer5.norm2.bias\", \"module.imageEncoder.features.denseblock4.denselayer5.norm2.running_mean\", \"module.imageEncoder.features.denseblock4.denselayer5.norm2.running_var\", \"module.imageEncoder.features.denseblock4.denselayer5.conv2.weight\", \"module.imageEncoder.features.denseblock4.denselayer6.norm1.weight\", \"module.imageEncoder.features.denseblock4.denselayer6.norm1.bias\", \"module.imageEncoder.features.denseblock4.denselayer6.norm1.running_mean\", \"module.imageEncoder.features.denseblock4.denselayer6.norm1.running_var\", \"module.imageEncoder.features.denseblock4.denselayer6.conv1.weight\", \"module.imageEncoder.features.denseblock4.denselayer6.norm2.weight\", \"module.imageEncoder.features.denseblock4.denselayer6.norm2.bias\", \"module.imageEncoder.features.denseblock4.denselayer6.norm2.running_mean\", \"module.imageEncoder.features.denseblock4.denselayer6.norm2.running_var\", \"module.imageEncoder.features.denseblock4.denselayer6.conv2.weight\", \"module.imageEncoder.features.denseblock4.denselayer7.norm1.weight\", \"module.imageEncoder.features.denseblock4.denselayer7.norm1.bias\", \"module.imageEncoder.features.denseblock4.denselayer7.norm1.running_mean\", \"module.imageEncoder.features.denseblock4.denselayer7.norm1.running_var\", \"module.imageEncoder.features.denseblock4.denselayer7.conv1.weight\", \"module.imageEncoder.features.denseblock4.denselayer7.norm2.weight\", \"module.imageEncoder.features.denseblock4.denselayer7.norm2.bias\", \"module.imageEncoder.features.denseblock4.denselayer7.norm2.running_mean\", \"module.imageEncoder.features.denseblock4.denselayer7.norm2.running_var\", \"module.imageEncoder.features.denseblock4.denselayer7.conv2.weight\", \"module.imageEncoder.features.denseblock4.denselayer8.norm1.weight\", \"module.imageEncoder.features.denseblock4.denselayer8.norm1.bias\", \"module.imageEncoder.features.denseblock4.denselayer8.norm1.running_mean\", \"module.imageEncoder.features.denseblock4.denselayer8.norm1.running_var\", \"module.imageEncoder.features.denseblock4.denselayer8.conv1.weight\", \"module.imageEncoder.features.denseblock4.denselayer8.norm2.weight\", \"module.imageEncoder.features.denseblock4.denselayer8.norm2.bias\", \"module.imageEncoder.features.denseblock4.denselayer8.norm2.running_mean\", \"module.imageEncoder.features.denseblock4.denselayer8.norm2.running_var\", \"module.imageEncoder.features.denseblock4.denselayer8.conv2.weight\", \"module.imageEncoder.features.denseblock4.denselayer9.norm1.weight\", \"module.imageEncoder.features.denseblock4.denselayer9.norm1.bias\", \"module.imageEncoder.features.denseblock4.denselayer9.norm1.running_mean\", \"module.imageEncoder.features.denseblock4.denselayer9.norm1.running_var\", \"module.imageEncoder.features.denseblock4.denselayer9.conv1.weight\", \"module.imageEncoder.features.denseblock4.denselayer9.norm2.weight\", \"module.imageEncoder.features.denseblock4.denselayer9.norm2.bias\", \"module.imageEncoder.features.denseblock4.denselayer9.norm2.running_mean\", \"module.imageEncoder.features.denseblock4.denselayer9.norm2.running_var\", \"module.imageEncoder.features.denseblock4.denselayer9.conv2.weight\", \"module.imageEncoder.features.denseblock4.denselayer10.norm1.weight\", \"module.imageEncoder.features.denseblock4.denselayer10.norm1.bias\", \"module.imageEncoder.features.denseblock4.denselayer10.norm1.running_mean\", \"module.imageEncoder.features.denseblock4.denselayer10.norm1.running_var\", \"module.imageEncoder.features.denseblock4.denselayer10.conv1.weight\", \"module.imageEncoder.features.denseblock4.denselayer10.norm2.weight\", \"module.imageEncoder.features.denseblock4.denselayer10.norm2.bias\", \"module.imageEncoder.features.denseblock4.denselayer10.norm2.running_mean\", \"module.imageEncoder.features.denseblock4.denselayer10.norm2.running_var\", \"module.imageEncoder.features.denseblock4.denselayer10.conv2.weight\", \"module.imageEncoder.features.denseblock4.denselayer11.norm1.weight\", \"module.imageEncoder.features.denseblock4.denselayer11.norm1.bias\", \"module.imageEncoder.features.denseblock4.denselayer11.norm1.running_mean\", \"module.imageEncoder.features.denseblock4.denselayer11.norm1.running_var\", \"module.imageEncoder.features.denseblock4.denselayer11.conv1.weight\", \"module.imageEncoder.features.denseblock4.denselayer11.norm2.weight\", \"module.imageEncoder.features.denseblock4.denselayer11.norm2.bias\", \"module.imageEncoder.features.denseblock4.denselayer11.norm2.running_mean\", \"module.imageEncoder.features.denseblock4.denselayer11.norm2.running_var\", \"module.imageEncoder.features.denseblock4.denselayer11.conv2.weight\", \"module.imageEncoder.features.denseblock4.denselayer12.norm1.weight\", \"module.imageEncoder.features.denseblock4.denselayer12.norm1.bias\", \"module.imageEncoder.features.denseblock4.denselayer12.norm1.running_mean\", \"module.imageEncoder.features.denseblock4.denselayer12.norm1.running_var\", \"module.imageEncoder.features.denseblock4.denselayer12.conv1.weight\", \"module.imageEncoder.features.denseblock4.denselayer12.norm2.weight\", \"module.imageEncoder.features.denseblock4.denselayer12.norm2.bias\", \"module.imageEncoder.features.denseblock4.denselayer12.norm2.running_mean\", \"module.imageEncoder.features.denseblock4.denselayer12.norm2.running_var\", \"module.imageEncoder.features.denseblock4.denselayer12.conv2.weight\", \"module.imageEncoder.features.denseblock4.denselayer13.norm1.weight\", \"module.imageEncoder.features.denseblock4.denselayer13.norm1.bias\", \"module.imageEncoder.features.denseblock4.denselayer13.norm1.running_mean\", \"module.imageEncoder.features.denseblock4.denselayer13.norm1.running_var\", \"module.imageEncoder.features.denseblock4.denselayer13.conv1.weight\", \"module.imageEncoder.features.denseblock4.denselayer13.norm2.weight\", \"module.imageEncoder.features.denseblock4.denselayer13.norm2.bias\", \"module.imageEncoder.features.denseblock4.denselayer13.norm2.running_mean\", \"module.imageEncoder.features.denseblock4.denselayer13.norm2.running_var\", \"module.imageEncoder.features.denseblock4.denselayer13.conv2.weight\", \"module.imageEncoder.features.denseblock4.denselayer14.norm1.weight\", \"module.imageEncoder.features.denseblock4.denselayer14.norm1.bias\", \"module.imageEncoder.features.denseblock4.denselayer14.norm1.running_mean\", \"module.imageEncoder.features.denseblock4.denselayer14.norm1.running_var\", \"module.imageEncoder.features.denseblock4.denselayer14.conv1.weight\", \"module.imageEncoder.features.denseblock4.denselayer14.norm2.weight\", \"module.imageEncoder.features.denseblock4.denselayer14.norm2.bias\", \"module.imageEncoder.features.denseblock4.denselayer14.norm2.running_mean\", \"module.imageEncoder.features.denseblock4.denselayer14.norm2.running_var\", \"module.imageEncoder.features.denseblock4.denselayer14.conv2.weight\", \"module.imageEncoder.features.denseblock4.denselayer15.norm1.weight\", \"module.imageEncoder.features.denseblock4.denselayer15.norm1.bias\", \"module.imageEncoder.features.denseblock4.denselayer15.norm1.running_mean\", \"module.imageEncoder.features.denseblock4.denselayer15.norm1.running_var\", \"module.imageEncoder.features.denseblock4.denselayer15.conv1.weight\", \"module.imageEncoder.features.denseblock4.denselayer15.norm2.weight\", \"module.imageEncoder.features.denseblock4.denselayer15.norm2.bias\", \"module.imageEncoder.features.denseblock4.denselayer15.norm2.running_mean\", \"module.imageEncoder.features.denseblock4.denselayer15.norm2.running_var\", \"module.imageEncoder.features.denseblock4.denselayer15.conv2.weight\", \"module.imageEncoder.features.denseblock4.denselayer16.norm1.weight\", \"module.imageEncoder.features.denseblock4.denselayer16.norm1.bias\", \"module.imageEncoder.features.denseblock4.denselayer16.norm1.running_mean\", \"module.imageEncoder.features.denseblock4.denselayer16.norm1.running_var\", \"module.imageEncoder.features.denseblock4.denselayer16.conv1.weight\", \"module.imageEncoder.features.denseblock4.denselayer16.norm2.weight\", \"module.imageEncoder.features.denseblock4.denselayer16.norm2.bias\", \"module.imageEncoder.features.denseblock4.denselayer16.norm2.running_mean\", \"module.imageEncoder.features.denseblock4.denselayer16.norm2.running_var\", \"module.imageEncoder.features.denseblock4.denselayer16.conv2.weight\", \"module.imageEncoder.features.denseblock4.denselayer17.norm1.weight\", \"module.imageEncoder.features.denseblock4.denselayer17.norm1.bias\", \"module.imageEncoder.features.denseblock4.denselayer17.norm1.running_mean\", \"module.imageEncoder.features.denseblock4.denselayer17.norm1.running_var\", \"module.imageEncoder.features.denseblock4.denselayer17.conv1.weight\", \"module.imageEncoder.features.denseblock4.denselayer17.norm2.weight\", \"module.imageEncoder.features.denseblock4.denselayer17.norm2.bias\", \"module.imageEncoder.features.denseblock4.denselayer17.norm2.running_mean\", \"module.imageEncoder.features.denseblock4.denselayer17.norm2.running_var\", \"module.imageEncoder.features.denseblock4.denselayer17.conv2.weight\", \"module.imageEncoder.features.denseblock4.denselayer18.norm1.weight\", \"module.imageEncoder.features.denseblock4.denselayer18.norm1.bias\", \"module.imageEncoder.features.denseblock4.denselayer18.norm1.running_mean\", \"module.imageEncoder.features.denseblock4.denselayer18.norm1.running_var\", \"module.imageEncoder.features.denseblock4.denselayer18.conv1.weight\", \"module.imageEncoder.features.denseblock4.denselayer18.norm2.weight\", \"module.imageEncoder.features.denseblock4.denselayer18.norm2.bias\", \"module.imageEncoder.features.denseblock4.denselayer18.norm2.running_mean\", \"module.imageEncoder.features.denseblock4.denselayer18.norm2.running_var\", \"module.imageEncoder.features.denseblock4.denselayer18.conv2.weight\", \"module.imageEncoder.features.denseblock4.denselayer19.norm1.weight\", \"module.imageEncoder.features.denseblock4.denselayer19.norm1.bias\", \"module.imageEncoder.features.denseblock4.denselayer19.norm1.running_mean\", \"module.imageEncoder.features.denseblock4.denselayer19.norm1.running_var\", \"module.imageEncoder.features.denseblock4.denselayer19.conv1.weight\", \"module.imageEncoder.features.denseblock4.denselayer19.norm2.weight\", \"module.imageEncoder.features.denseblock4.denselayer19.norm2.bias\", \"module.imageEncoder.features.denseblock4.denselayer19.norm2.running_mean\", \"module.imageEncoder.features.denseblock4.denselayer19.norm2.running_var\", \"module.imageEncoder.features.denseblock4.denselayer19.conv2.weight\", \"module.imageEncoder.features.denseblock4.denselayer20.norm1.weight\", \"module.imageEncoder.features.denseblock4.denselayer20.norm1.bias\", \"module.imageEncoder.features.denseblock4.denselayer20.norm1.running_mean\", \"module.imageEncoder.features.denseblock4.denselayer20.norm1.running_var\", \"module.imageEncoder.features.denseblock4.denselayer20.conv1.weight\", \"module.imageEncoder.features.denseblock4.denselayer20.norm2.weight\", \"module.imageEncoder.features.denseblock4.denselayer20.norm2.bias\", \"module.imageEncoder.features.denseblock4.denselayer20.norm2.running_mean\", \"module.imageEncoder.features.denseblock4.denselayer20.norm2.running_var\", \"module.imageEncoder.features.denseblock4.denselayer20.conv2.weight\", \"module.imageEncoder.features.denseblock4.denselayer21.norm1.weight\", \"module.imageEncoder.features.denseblock4.denselayer21.norm1.bias\", \"module.imageEncoder.features.denseblock4.denselayer21.norm1.running_mean\", \"module.imageEncoder.features.denseblock4.denselayer21.norm1.running_var\", \"module.imageEncoder.features.denseblock4.denselayer21.conv1.weight\", \"module.imageEncoder.features.denseblock4.denselayer21.norm2.weight\", \"module.imageEncoder.features.denseblock4.denselayer21.norm2.bias\", \"module.imageEncoder.features.denseblock4.denselayer21.norm2.running_mean\", \"module.imageEncoder.features.denseblock4.denselayer21.norm2.running_var\", \"module.imageEncoder.features.denseblock4.denselayer21.conv2.weight\", \"module.imageEncoder.features.denseblock4.denselayer22.norm1.weight\", \"module.imageEncoder.features.denseblock4.denselayer22.norm1.bias\", \"module.imageEncoder.features.denseblock4.denselayer22.norm1.running_mean\", \"module.imageEncoder.features.denseblock4.denselayer22.norm1.running_var\", \"module.imageEncoder.features.denseblock4.denselayer22.conv1.weight\", \"module.imageEncoder.features.denseblock4.denselayer22.norm2.weight\", \"module.imageEncoder.features.denseblock4.denselayer22.norm2.bias\", \"module.imageEncoder.features.denseblock4.denselayer22.norm2.running_mean\", \"module.imageEncoder.features.denseblock4.denselayer22.norm2.running_var\", \"module.imageEncoder.features.denseblock4.denselayer22.conv2.weight\", \"module.imageEncoder.features.denseblock4.denselayer23.norm1.weight\", \"module.imageEncoder.features.denseblock4.denselayer23.norm1.bias\", \"module.imageEncoder.features.denseblock4.denselayer23.norm1.running_mean\", \"module.imageEncoder.features.denseblock4.denselayer23.norm1.running_var\", \"module.imageEncoder.features.denseblock4.denselayer23.conv1.weight\", \"module.imageEncoder.features.denseblock4.denselayer23.norm2.weight\", \"module.imageEncoder.features.denseblock4.denselayer23.norm2.bias\", \"module.imageEncoder.features.denseblock4.denselayer23.norm2.running_mean\", \"module.imageEncoder.features.denseblock4.denselayer23.norm2.running_var\", \"module.imageEncoder.features.denseblock4.denselayer23.conv2.weight\", \"module.imageEncoder.features.denseblock4.denselayer24.norm1.weight\", \"module.imageEncoder.features.denseblock4.denselayer24.norm1.bias\", \"module.imageEncoder.features.denseblock4.denselayer24.norm1.running_mean\", \"module.imageEncoder.features.denseblock4.denselayer24.norm1.running_var\", \"module.imageEncoder.features.denseblock4.denselayer24.conv1.weight\", \"module.imageEncoder.features.denseblock4.denselayer24.norm2.weight\", \"module.imageEncoder.features.denseblock4.denselayer24.norm2.bias\", \"module.imageEncoder.features.denseblock4.denselayer24.norm2.running_mean\", \"module.imageEncoder.features.denseblock4.denselayer24.norm2.running_var\", \"module.imageEncoder.features.denseblock4.denselayer24.conv2.weight\", \"module.imageEncoder.features.denseblock4.denselayer25.norm1.weight\", \"module.imageEncoder.features.denseblock4.denselayer25.norm1.bias\", \"module.imageEncoder.features.denseblock4.denselayer25.norm1.running_mean\", \"module.imageEncoder.features.denseblock4.denselayer25.norm1.running_var\", \"module.imageEncoder.features.denseblock4.denselayer25.conv1.weight\", \"module.imageEncoder.features.denseblock4.denselayer25.norm2.weight\", \"module.imageEncoder.features.denseblock4.denselayer25.norm2.bias\", \"module.imageEncoder.features.denseblock4.denselayer25.norm2.running_mean\", \"module.imageEncoder.features.denseblock4.denselayer25.norm2.running_var\", \"module.imageEncoder.features.denseblock4.denselayer25.conv2.weight\", \"module.imageEncoder.features.denseblock4.denselayer26.norm1.weight\", \"module.imageEncoder.features.denseblock4.denselayer26.norm1.bias\", \"module.imageEncoder.features.denseblock4.denselayer26.norm1.running_mean\", \"module.imageEncoder.features.denseblock4.denselayer26.norm1.running_var\", \"module.imageEncoder.features.denseblock4.denselayer26.conv1.weight\", \"module.imageEncoder.features.denseblock4.denselayer26.norm2.weight\", \"module.imageEncoder.features.denseblock4.denselayer26.norm2.bias\", \"module.imageEncoder.features.denseblock4.denselayer26.norm2.running_mean\", \"module.imageEncoder.features.denseblock4.denselayer26.norm2.running_var\", \"module.imageEncoder.features.denseblock4.denselayer26.conv2.weight\", \"module.imageEncoder.features.denseblock4.denselayer27.norm1.weight\", \"module.imageEncoder.features.denseblock4.denselayer27.norm1.bias\", \"module.imageEncoder.features.denseblock4.denselayer27.norm1.running_mean\", \"module.imageEncoder.features.denseblock4.denselayer27.norm1.running_var\", \"module.imageEncoder.features.denseblock4.denselayer27.conv1.weight\", \"module.imageEncoder.features.denseblock4.denselayer27.norm2.weight\", \"module.imageEncoder.features.denseblock4.denselayer27.norm2.bias\", \"module.imageEncoder.features.denseblock4.denselayer27.norm2.running_mean\", \"module.imageEncoder.features.denseblock4.denselayer27.norm2.running_var\", \"module.imageEncoder.features.denseblock4.denselayer27.conv2.weight\", \"module.imageEncoder.features.denseblock4.denselayer28.norm1.weight\", \"module.imageEncoder.features.denseblock4.denselayer28.norm1.bias\", \"module.imageEncoder.features.denseblock4.denselayer28.norm1.running_mean\", \"module.imageEncoder.features.denseblock4.denselayer28.norm1.running_var\", \"module.imageEncoder.features.denseblock4.denselayer28.conv1.weight\", \"module.imageEncoder.features.denseblock4.denselayer28.norm2.weight\", \"module.imageEncoder.features.denseblock4.denselayer28.norm2.bias\", \"module.imageEncoder.features.denseblock4.denselayer28.norm2.running_mean\", \"module.imageEncoder.features.denseblock4.denselayer28.norm2.running_var\", \"module.imageEncoder.features.denseblock4.denselayer28.conv2.weight\", \"module.imageEncoder.features.denseblock4.denselayer29.norm1.weight\", \"module.imageEncoder.features.denseblock4.denselayer29.norm1.bias\", \"module.imageEncoder.features.denseblock4.denselayer29.norm1.running_mean\", \"module.imageEncoder.features.denseblock4.denselayer29.norm1.running_var\", \"module.imageEncoder.features.denseblock4.denselayer29.conv1.weight\", \"module.imageEncoder.features.denseblock4.denselayer29.norm2.weight\", \"module.imageEncoder.features.denseblock4.denselayer29.norm2.bias\", \"module.imageEncoder.features.denseblock4.denselayer29.norm2.running_mean\", \"module.imageEncoder.features.denseblock4.denselayer29.norm2.running_var\", \"module.imageEncoder.features.denseblock4.denselayer29.conv2.weight\", \"module.imageEncoder.features.denseblock4.denselayer30.norm1.weight\", \"module.imageEncoder.features.denseblock4.denselayer30.norm1.bias\", \"module.imageEncoder.features.denseblock4.denselayer30.norm1.running_mean\", \"module.imageEncoder.features.denseblock4.denselayer30.norm1.running_var\", \"module.imageEncoder.features.denseblock4.denselayer30.conv1.weight\", \"module.imageEncoder.features.denseblock4.denselayer30.norm2.weight\", \"module.imageEncoder.features.denseblock4.denselayer30.norm2.bias\", \"module.imageEncoder.features.denseblock4.denselayer30.norm2.running_mean\", \"module.imageEncoder.features.denseblock4.denselayer30.norm2.running_var\", \"module.imageEncoder.features.denseblock4.denselayer30.conv2.weight\", \"module.imageEncoder.features.denseblock4.denselayer31.norm1.weight\", \"module.imageEncoder.features.denseblock4.denselayer31.norm1.bias\", \"module.imageEncoder.features.denseblock4.denselayer31.norm1.running_mean\", \"module.imageEncoder.features.denseblock4.denselayer31.norm1.running_var\", \"module.imageEncoder.features.denseblock4.denselayer31.conv1.weight\", \"module.imageEncoder.features.denseblock4.denselayer31.norm2.weight\", \"module.imageEncoder.features.denseblock4.denselayer31.norm2.bias\", \"module.imageEncoder.features.denseblock4.denselayer31.norm2.running_mean\", \"module.imageEncoder.features.denseblock4.denselayer31.norm2.running_var\", \"module.imageEncoder.features.denseblock4.denselayer31.conv2.weight\", \"module.imageEncoder.features.denseblock4.denselayer32.norm1.weight\", \"module.imageEncoder.features.denseblock4.denselayer32.norm1.bias\", \"module.imageEncoder.features.denseblock4.denselayer32.norm1.running_mean\", \"module.imageEncoder.features.denseblock4.denselayer32.norm1.running_var\", \"module.imageEncoder.features.denseblock4.denselayer32.conv1.weight\", \"module.imageEncoder.features.denseblock4.denselayer32.norm2.weight\", \"module.imageEncoder.features.denseblock4.denselayer32.norm2.bias\", \"module.imageEncoder.features.denseblock4.denselayer32.norm2.running_mean\", \"module.imageEncoder.features.denseblock4.denselayer32.norm2.running_var\", \"module.imageEncoder.features.denseblock4.denselayer32.conv2.weight\", \"module.imageEncoder.features.norm5.weight\", \"module.imageEncoder.features.norm5.bias\", \"module.imageEncoder.features.norm5.running_mean\", \"module.imageEncoder.features.norm5.running_var\", \"module.imageEncoder.classifier.weight\", \"module.imageEncoder.classifier.bias\", \"module.textEncoder.embeddings.word_embeddings.weight\", \"module.textEncoder.embeddings.position_embeddings.weight\", \"module.textEncoder.embeddings.token_type_embeddings.weight\", \"module.textEncoder.embeddings.LayerNorm.weight\", \"module.textEncoder.embeddings.LayerNorm.bias\", \"module.textEncoder.encoder.layer.0.attention.self.query.weight\", \"module.textEncoder.encoder.layer.0.attention.self.query.bias\", \"module.textEncoder.encoder.layer.0.attention.self.key.weight\", \"module.textEncoder.encoder.layer.0.attention.self.key.bias\", \"module.textEncoder.encoder.layer.0.attention.self.value.weight\", \"module.textEncoder.encoder.layer.0.attention.self.value.bias\", \"module.textEncoder.encoder.layer.0.attention.output.dense.weight\", \"module.textEncoder.encoder.layer.0.attention.output.dense.bias\", \"module.textEncoder.encoder.layer.0.attention.output.LayerNorm.weight\", \"module.textEncoder.encoder.layer.0.attention.output.LayerNorm.bias\", \"module.textEncoder.encoder.layer.0.intermediate.dense.weight\", \"module.textEncoder.encoder.layer.0.intermediate.dense.bias\", \"module.textEncoder.encoder.layer.0.output.dense.weight\", \"module.textEncoder.encoder.layer.0.output.dense.bias\", \"module.textEncoder.encoder.layer.0.output.LayerNorm.weight\", \"module.textEncoder.encoder.layer.0.output.LayerNorm.bias\", \"module.textEncoder.encoder.layer.1.attention.self.query.weight\", \"module.textEncoder.encoder.layer.1.attention.self.query.bias\", \"module.textEncoder.encoder.layer.1.attention.self.key.weight\", \"module.textEncoder.encoder.layer.1.attention.self.key.bias\", \"module.textEncoder.encoder.layer.1.attention.self.value.weight\", \"module.textEncoder.encoder.layer.1.attention.self.value.bias\", \"module.textEncoder.encoder.layer.1.attention.output.dense.weight\", \"module.textEncoder.encoder.layer.1.attention.output.dense.bias\", \"module.textEncoder.encoder.layer.1.attention.output.LayerNorm.weight\", \"module.textEncoder.encoder.layer.1.attention.output.LayerNorm.bias\", \"module.textEncoder.encoder.layer.1.intermediate.dense.weight\", \"module.textEncoder.encoder.layer.1.intermediate.dense.bias\", \"module.textEncoder.encoder.layer.1.output.dense.weight\", \"module.textEncoder.encoder.layer.1.output.dense.bias\", \"module.textEncoder.encoder.layer.1.output.LayerNorm.weight\", \"module.textEncoder.encoder.layer.1.output.LayerNorm.bias\", \"module.textEncoder.encoder.layer.2.attention.self.query.weight\", \"module.textEncoder.encoder.layer.2.attention.self.query.bias\", \"module.textEncoder.encoder.layer.2.attention.self.key.weight\", \"module.textEncoder.encoder.layer.2.attention.self.key.bias\", \"module.textEncoder.encoder.layer.2.attention.self.value.weight\", \"module.textEncoder.encoder.layer.2.attention.self.value.bias\", \"module.textEncoder.encoder.layer.2.attention.output.dense.weight\", \"module.textEncoder.encoder.layer.2.attention.output.dense.bias\", \"module.textEncoder.encoder.layer.2.attention.output.LayerNorm.weight\", \"module.textEncoder.encoder.layer.2.attention.output.LayerNorm.bias\", \"module.textEncoder.encoder.layer.2.intermediate.dense.weight\", \"module.textEncoder.encoder.layer.2.intermediate.dense.bias\", \"module.textEncoder.encoder.layer.2.output.dense.weight\", \"module.textEncoder.encoder.layer.2.output.dense.bias\", \"module.textEncoder.encoder.layer.2.output.LayerNorm.weight\", \"module.textEncoder.encoder.layer.2.output.LayerNorm.bias\", \"module.textEncoder.encoder.layer.3.attention.self.query.weight\", \"module.textEncoder.encoder.layer.3.attention.self.query.bias\", \"module.textEncoder.encoder.layer.3.attention.self.key.weight\", \"module.textEncoder.encoder.layer.3.attention.self.key.bias\", \"module.textEncoder.encoder.layer.3.attention.self.value.weight\", \"module.textEncoder.encoder.layer.3.attention.self.value.bias\", \"module.textEncoder.encoder.layer.3.attention.output.dense.weight\", \"module.textEncoder.encoder.layer.3.attention.output.dense.bias\", \"module.textEncoder.encoder.layer.3.attention.output.LayerNorm.weight\", \"module.textEncoder.encoder.layer.3.attention.output.LayerNorm.bias\", \"module.textEncoder.encoder.layer.3.intermediate.dense.weight\", \"module.textEncoder.encoder.layer.3.intermediate.dense.bias\", \"module.textEncoder.encoder.layer.3.output.dense.weight\", \"module.textEncoder.encoder.layer.3.output.dense.bias\", \"module.textEncoder.encoder.layer.3.output.LayerNorm.weight\", \"module.textEncoder.encoder.layer.3.output.LayerNorm.bias\", \"module.textEncoder.encoder.layer.4.attention.self.query.weight\", \"module.textEncoder.encoder.layer.4.attention.self.query.bias\", \"module.textEncoder.encoder.layer.4.attention.self.key.weight\", \"module.textEncoder.encoder.layer.4.attention.self.key.bias\", \"module.textEncoder.encoder.layer.4.attention.self.value.weight\", \"module.textEncoder.encoder.layer.4.attention.self.value.bias\", \"module.textEncoder.encoder.layer.4.attention.output.dense.weight\", \"module.textEncoder.encoder.layer.4.attention.output.dense.bias\", \"module.textEncoder.encoder.layer.4.attention.output.LayerNorm.weight\", \"module.textEncoder.encoder.layer.4.attention.output.LayerNorm.bias\", \"module.textEncoder.encoder.layer.4.intermediate.dense.weight\", \"module.textEncoder.encoder.layer.4.intermediate.dense.bias\", \"module.textEncoder.encoder.layer.4.output.dense.weight\", \"module.textEncoder.encoder.layer.4.output.dense.bias\", \"module.textEncoder.encoder.layer.4.output.LayerNorm.weight\", \"module.textEncoder.encoder.layer.4.output.LayerNorm.bias\", \"module.textEncoder.encoder.layer.5.attention.self.query.weight\", \"module.textEncoder.encoder.layer.5.attention.self.query.bias\", \"module.textEncoder.encoder.layer.5.attention.self.key.weight\", \"module.textEncoder.encoder.layer.5.attention.self.key.bias\", \"module.textEncoder.encoder.layer.5.attention.self.value.weight\", \"module.textEncoder.encoder.layer.5.attention.self.value.bias\", \"module.textEncoder.encoder.layer.5.attention.output.dense.weight\", \"module.textEncoder.encoder.layer.5.attention.output.dense.bias\", \"module.textEncoder.encoder.layer.5.attention.output.LayerNorm.weight\", \"module.textEncoder.encoder.layer.5.attention.output.LayerNorm.bias\", \"module.textEncoder.encoder.layer.5.intermediate.dense.weight\", \"module.textEncoder.encoder.layer.5.intermediate.dense.bias\", \"module.textEncoder.encoder.layer.5.output.dense.weight\", \"module.textEncoder.encoder.layer.5.output.dense.bias\", \"module.textEncoder.encoder.layer.5.output.LayerNorm.weight\", \"module.textEncoder.encoder.layer.5.output.LayerNorm.bias\", \"module.textEncoder.encoder.layer.6.attention.self.query.weight\", \"module.textEncoder.encoder.layer.6.attention.self.query.bias\", \"module.textEncoder.encoder.layer.6.attention.self.key.weight\", \"module.textEncoder.encoder.layer.6.attention.self.key.bias\", \"module.textEncoder.encoder.layer.6.attention.self.value.weight\", \"module.textEncoder.encoder.layer.6.attention.self.value.bias\", \"module.textEncoder.encoder.layer.6.attention.output.dense.weight\", \"module.textEncoder.encoder.layer.6.attention.output.dense.bias\", \"module.textEncoder.encoder.layer.6.attention.output.LayerNorm.weight\", \"module.textEncoder.encoder.layer.6.attention.output.LayerNorm.bias\", \"module.textEncoder.encoder.layer.6.intermediate.dense.weight\", \"module.textEncoder.encoder.layer.6.intermediate.dense.bias\", \"module.textEncoder.encoder.layer.6.output.dense.weight\", \"module.textEncoder.encoder.layer.6.output.dense.bias\", \"module.textEncoder.encoder.layer.6.output.LayerNorm.weight\", \"module.textEncoder.encoder.layer.6.output.LayerNorm.bias\", \"module.textEncoder.encoder.layer.7.attention.self.query.weight\", \"module.textEncoder.encoder.layer.7.attention.self.query.bias\", \"module.textEncoder.encoder.layer.7.attention.self.key.weight\", \"module.textEncoder.encoder.layer.7.attention.self.key.bias\", \"module.textEncoder.encoder.layer.7.attention.self.value.weight\", \"module.textEncoder.encoder.layer.7.attention.self.value.bias\", \"module.textEncoder.encoder.layer.7.attention.output.dense.weight\", \"module.textEncoder.encoder.layer.7.attention.output.dense.bias\", \"module.textEncoder.encoder.layer.7.attention.output.LayerNorm.weight\", \"module.textEncoder.encoder.layer.7.attention.output.LayerNorm.bias\", \"module.textEncoder.encoder.layer.7.intermediate.dense.weight\", \"module.textEncoder.encoder.layer.7.intermediate.dense.bias\", \"module.textEncoder.encoder.layer.7.output.dense.weight\", \"module.textEncoder.encoder.layer.7.output.dense.bias\", \"module.textEncoder.encoder.layer.7.output.LayerNorm.weight\", \"module.textEncoder.encoder.layer.7.output.LayerNorm.bias\", \"module.textEncoder.encoder.layer.8.attention.self.query.weight\", \"module.textEncoder.encoder.layer.8.attention.self.query.bias\", \"module.textEncoder.encoder.layer.8.attention.self.key.weight\", \"module.textEncoder.encoder.layer.8.attention.self.key.bias\", \"module.textEncoder.encoder.layer.8.attention.self.value.weight\", \"module.textEncoder.encoder.layer.8.attention.self.value.bias\", \"module.textEncoder.encoder.layer.8.attention.output.dense.weight\", \"module.textEncoder.encoder.layer.8.attention.output.dense.bias\", \"module.textEncoder.encoder.layer.8.attention.output.LayerNorm.weight\", \"module.textEncoder.encoder.layer.8.attention.output.LayerNorm.bias\", \"module.textEncoder.encoder.layer.8.intermediate.dense.weight\", \"module.textEncoder.encoder.layer.8.intermediate.dense.bias\", \"module.textEncoder.encoder.layer.8.output.dense.weight\", \"module.textEncoder.encoder.layer.8.output.dense.bias\", \"module.textEncoder.encoder.layer.8.output.LayerNorm.weight\", \"module.textEncoder.encoder.layer.8.output.LayerNorm.bias\", \"module.textEncoder.encoder.layer.9.attention.self.query.weight\", \"module.textEncoder.encoder.layer.9.attention.self.query.bias\", \"module.textEncoder.encoder.layer.9.attention.self.key.weight\", \"module.textEncoder.encoder.layer.9.attention.self.key.bias\", \"module.textEncoder.encoder.layer.9.attention.self.value.weight\", \"module.textEncoder.encoder.layer.9.attention.self.value.bias\", \"module.textEncoder.encoder.layer.9.attention.output.dense.weight\", \"module.textEncoder.encoder.layer.9.attention.output.dense.bias\", \"module.textEncoder.encoder.layer.9.attention.output.LayerNorm.weight\", \"module.textEncoder.encoder.layer.9.attention.output.LayerNorm.bias\", \"module.textEncoder.encoder.layer.9.intermediate.dense.weight\", \"module.textEncoder.encoder.layer.9.intermediate.dense.bias\", \"module.textEncoder.encoder.layer.9.output.dense.weight\", \"module.textEncoder.encoder.layer.9.output.dense.bias\", \"module.textEncoder.encoder.layer.9.output.LayerNorm.weight\", \"module.textEncoder.encoder.layer.9.output.LayerNorm.bias\", \"module.textEncoder.encoder.layer.10.attention.self.query.weight\", \"module.textEncoder.encoder.layer.10.attention.self.query.bias\", \"module.textEncoder.encoder.layer.10.attention.self.key.weight\", \"module.textEncoder.encoder.layer.10.attention.self.key.bias\", \"module.textEncoder.encoder.layer.10.attention.self.value.weight\", \"module.textEncoder.encoder.layer.10.attention.self.value.bias\", \"module.textEncoder.encoder.layer.10.attention.output.dense.weight\", \"module.textEncoder.encoder.layer.10.attention.output.dense.bias\", \"module.textEncoder.encoder.layer.10.attention.output.LayerNorm.weight\", \"module.textEncoder.encoder.layer.10.attention.output.LayerNorm.bias\", \"module.textEncoder.encoder.layer.10.intermediate.dense.weight\", \"module.textEncoder.encoder.layer.10.intermediate.dense.bias\", \"module.textEncoder.encoder.layer.10.output.dense.weight\", \"module.textEncoder.encoder.layer.10.output.dense.bias\", \"module.textEncoder.encoder.layer.10.output.LayerNorm.weight\", \"module.textEncoder.encoder.layer.10.output.LayerNorm.bias\", \"module.textEncoder.encoder.layer.11.attention.self.query.weight\", \"module.textEncoder.encoder.layer.11.attention.self.query.bias\", \"module.textEncoder.encoder.layer.11.attention.self.key.weight\", \"module.textEncoder.encoder.layer.11.attention.self.key.bias\", \"module.textEncoder.encoder.layer.11.attention.self.value.weight\", \"module.textEncoder.encoder.layer.11.attention.self.value.bias\", \"module.textEncoder.encoder.layer.11.attention.output.dense.weight\", \"module.textEncoder.encoder.layer.11.attention.output.dense.bias\", \"module.textEncoder.encoder.layer.11.attention.output.LayerNorm.weight\", \"module.textEncoder.encoder.layer.11.attention.output.LayerNorm.bias\", \"module.textEncoder.encoder.layer.11.intermediate.dense.weight\", \"module.textEncoder.encoder.layer.11.intermediate.dense.bias\", \"module.textEncoder.encoder.layer.11.output.dense.weight\", \"module.textEncoder.encoder.layer.11.output.dense.bias\", \"module.textEncoder.encoder.layer.11.output.LayerNorm.weight\", \"module.textEncoder.encoder.layer.11.output.LayerNorm.bias\", \"module.proj_visual.weight\", \"module.proj_visual.bias\", \"module.proj_text.weight\", \"module.proj_text.bias\", \"module.bn_visual.weight\", \"module.bn_visual.bias\", \"module.bn_visual.running_mean\", \"module.bn_visual.running_var\", \"module.bn_text.weight\", \"module.bn_text.bias\", \"module.bn_text.running_mean\", \"module.bn_text.running_var\", \"module.attn_visual.weight\", \"module.attn_visual.bias\", \"module.attn_text.weight\", \"module.attn_text.bias\", \"module.fc_attn.weight\", \"module.fc_attn.bias\", \"module.bn_attn.weight\", \"module.bn_attn.bias\", \"module.bn_attn.running_mean\", \"module.bn_attn.running_var\", \"module.classifier_task1.weight\", \"module.classifier_task1.bias\", \"module.classifier_task2.weight\", \"module.classifier_task2.bias\", \"module.classifier_task3.weight\", \"module.classifier_task3.bias\". \n\tUnexpected key(s) in state_dict: \"imageEncoder.features.conv0.weight\", \"imageEncoder.features.norm0.weight\", \"imageEncoder.features.norm0.bias\", \"imageEncoder.features.norm0.running_mean\", \"imageEncoder.features.norm0.running_var\", \"imageEncoder.features.norm0.num_batches_tracked\", \"imageEncoder.features.denseblock1.denselayer1.norm1.weight\", \"imageEncoder.features.denseblock1.denselayer1.norm1.bias\", \"imageEncoder.features.denseblock1.denselayer1.norm1.running_mean\", \"imageEncoder.features.denseblock1.denselayer1.norm1.running_var\", \"imageEncoder.features.denseblock1.denselayer1.norm1.num_batches_tracked\", \"imageEncoder.features.denseblock1.denselayer1.conv1.weight\", \"imageEncoder.features.denseblock1.denselayer1.norm2.weight\", \"imageEncoder.features.denseblock1.denselayer1.norm2.bias\", \"imageEncoder.features.denseblock1.denselayer1.norm2.running_mean\", \"imageEncoder.features.denseblock1.denselayer1.norm2.running_var\", \"imageEncoder.features.denseblock1.denselayer1.norm2.num_batches_tracked\", \"imageEncoder.features.denseblock1.denselayer1.conv2.weight\", \"imageEncoder.features.denseblock1.denselayer2.norm1.weight\", \"imageEncoder.features.denseblock1.denselayer2.norm1.bias\", \"imageEncoder.features.denseblock1.denselayer2.norm1.running_mean\", \"imageEncoder.features.denseblock1.denselayer2.norm1.running_var\", \"imageEncoder.features.denseblock1.denselayer2.norm1.num_batches_tracked\", \"imageEncoder.features.denseblock1.denselayer2.conv1.weight\", \"imageEncoder.features.denseblock1.denselayer2.norm2.weight\", \"imageEncoder.features.denseblock1.denselayer2.norm2.bias\", \"imageEncoder.features.denseblock1.denselayer2.norm2.running_mean\", \"imageEncoder.features.denseblock1.denselayer2.norm2.running_var\", \"imageEncoder.features.denseblock1.denselayer2.norm2.num_batches_tracked\", \"imageEncoder.features.denseblock1.denselayer2.conv2.weight\", \"imageEncoder.features.denseblock1.denselayer3.norm1.weight\", \"imageEncoder.features.denseblock1.denselayer3.norm1.bias\", \"imageEncoder.features.denseblock1.denselayer3.norm1.running_mean\", \"imageEncoder.features.denseblock1.denselayer3.norm1.running_var\", \"imageEncoder.features.denseblock1.denselayer3.norm1.num_batches_tracked\", \"imageEncoder.features.denseblock1.denselayer3.conv1.weight\", \"imageEncoder.features.denseblock1.denselayer3.norm2.weight\", \"imageEncoder.features.denseblock1.denselayer3.norm2.bias\", \"imageEncoder.features.denseblock1.denselayer3.norm2.running_mean\", \"imageEncoder.features.denseblock1.denselayer3.norm2.running_var\", \"imageEncoder.features.denseblock1.denselayer3.norm2.num_batches_tracked\", \"imageEncoder.features.denseblock1.denselayer3.conv2.weight\", \"imageEncoder.features.denseblock1.denselayer4.norm1.weight\", \"imageEncoder.features.denseblock1.denselayer4.norm1.bias\", \"imageEncoder.features.denseblock1.denselayer4.norm1.running_mean\", \"imageEncoder.features.denseblock1.denselayer4.norm1.running_var\", \"imageEncoder.features.denseblock1.denselayer4.norm1.num_batches_tracked\", \"imageEncoder.features.denseblock1.denselayer4.conv1.weight\", \"imageEncoder.features.denseblock1.denselayer4.norm2.weight\", \"imageEncoder.features.denseblock1.denselayer4.norm2.bias\", \"imageEncoder.features.denseblock1.denselayer4.norm2.running_mean\", \"imageEncoder.features.denseblock1.denselayer4.norm2.running_var\", \"imageEncoder.features.denseblock1.denselayer4.norm2.num_batches_tracked\", \"imageEncoder.features.denseblock1.denselayer4.conv2.weight\", \"imageEncoder.features.denseblock1.denselayer5.norm1.weight\", \"imageEncoder.features.denseblock1.denselayer5.norm1.bias\", \"imageEncoder.features.denseblock1.denselayer5.norm1.running_mean\", \"imageEncoder.features.denseblock1.denselayer5.norm1.running_var\", \"imageEncoder.features.denseblock1.denselayer5.norm1.num_batches_tracked\", \"imageEncoder.features.denseblock1.denselayer5.conv1.weight\", \"imageEncoder.features.denseblock1.denselayer5.norm2.weight\", \"imageEncoder.features.denseblock1.denselayer5.norm2.bias\", \"imageEncoder.features.denseblock1.denselayer5.norm2.running_mean\", \"imageEncoder.features.denseblock1.denselayer5.norm2.running_var\", \"imageEncoder.features.denseblock1.denselayer5.norm2.num_batches_tracked\", \"imageEncoder.features.denseblock1.denselayer5.conv2.weight\", \"imageEncoder.features.denseblock1.denselayer6.norm1.weight\", \"imageEncoder.features.denseblock1.denselayer6.norm1.bias\", \"imageEncoder.features.denseblock1.denselayer6.norm1.running_mean\", \"imageEncoder.features.denseblock1.denselayer6.norm1.running_var\", \"imageEncoder.features.denseblock1.denselayer6.norm1.num_batches_tracked\", \"imageEncoder.features.denseblock1.denselayer6.conv1.weight\", \"imageEncoder.features.denseblock1.denselayer6.norm2.weight\", \"imageEncoder.features.denseblock1.denselayer6.norm2.bias\", \"imageEncoder.features.denseblock1.denselayer6.norm2.running_mean\", \"imageEncoder.features.denseblock1.denselayer6.norm2.running_var\", \"imageEncoder.features.denseblock1.denselayer6.norm2.num_batches_tracked\", \"imageEncoder.features.denseblock1.denselayer6.conv2.weight\", \"imageEncoder.features.transition1.norm.weight\", \"imageEncoder.features.transition1.norm.bias\", \"imageEncoder.features.transition1.norm.running_mean\", \"imageEncoder.features.transition1.norm.running_var\", \"imageEncoder.features.transition1.norm.num_batches_tracked\", \"imageEncoder.features.transition1.conv.weight\", \"imageEncoder.features.denseblock2.denselayer1.norm1.weight\", \"imageEncoder.features.denseblock2.denselayer1.norm1.bias\", \"imageEncoder.features.denseblock2.denselayer1.norm1.running_mean\", \"imageEncoder.features.denseblock2.denselayer1.norm1.running_var\", \"imageEncoder.features.denseblock2.denselayer1.norm1.num_batches_tracked\", \"imageEncoder.features.denseblock2.denselayer1.conv1.weight\", \"imageEncoder.features.denseblock2.denselayer1.norm2.weight\", \"imageEncoder.features.denseblock2.denselayer1.norm2.bias\", \"imageEncoder.features.denseblock2.denselayer1.norm2.running_mean\", \"imageEncoder.features.denseblock2.denselayer1.norm2.running_var\", \"imageEncoder.features.denseblock2.denselayer1.norm2.num_batches_tracked\", \"imageEncoder.features.denseblock2.denselayer1.conv2.weight\", \"imageEncoder.features.denseblock2.denselayer2.norm1.weight\", \"imageEncoder.features.denseblock2.denselayer2.norm1.bias\", \"imageEncoder.features.denseblock2.denselayer2.norm1.running_mean\", \"imageEncoder.features.denseblock2.denselayer2.norm1.running_var\", \"imageEncoder.features.denseblock2.denselayer2.norm1.num_batches_tracked\", \"imageEncoder.features.denseblock2.denselayer2.conv1.weight\", \"imageEncoder.features.denseblock2.denselayer2.norm2.weight\", \"imageEncoder.features.denseblock2.denselayer2.norm2.bias\", \"imageEncoder.features.denseblock2.denselayer2.norm2.running_mean\", \"imageEncoder.features.denseblock2.denselayer2.norm2.running_var\", \"imageEncoder.features.denseblock2.denselayer2.norm2.num_batches_tracked\", \"imageEncoder.features.denseblock2.denselayer2.conv2.weight\", \"imageEncoder.features.denseblock2.denselayer3.norm1.weight\", \"imageEncoder.features.denseblock2.denselayer3.norm1.bias\", \"imageEncoder.features.denseblock2.denselayer3.norm1.running_mean\", \"imageEncoder.features.denseblock2.denselayer3.norm1.running_var\", \"imageEncoder.features.denseblock2.denselayer3.norm1.num_batches_tracked\", \"imageEncoder.features.denseblock2.denselayer3.conv1.weight\", \"imageEncoder.features.denseblock2.denselayer3.norm2.weight\", \"imageEncoder.features.denseblock2.denselayer3.norm2.bias\", \"imageEncoder.features.denseblock2.denselayer3.norm2.running_mean\", \"imageEncoder.features.denseblock2.denselayer3.norm2.running_var\", \"imageEncoder.features.denseblock2.denselayer3.norm2.num_batches_tracked\", \"imageEncoder.features.denseblock2.denselayer3.conv2.weight\", \"imageEncoder.features.denseblock2.denselayer4.norm1.weight\", \"imageEncoder.features.denseblock2.denselayer4.norm1.bias\", \"imageEncoder.features.denseblock2.denselayer4.norm1.running_mean\", \"imageEncoder.features.denseblock2.denselayer4.norm1.running_var\", \"imageEncoder.features.denseblock2.denselayer4.norm1.num_batches_tracked\", \"imageEncoder.features.denseblock2.denselayer4.conv1.weight\", \"imageEncoder.features.denseblock2.denselayer4.norm2.weight\", \"imageEncoder.features.denseblock2.denselayer4.norm2.bias\", \"imageEncoder.features.denseblock2.denselayer4.norm2.running_mean\", \"imageEncoder.features.denseblock2.denselayer4.norm2.running_var\", \"imageEncoder.features.denseblock2.denselayer4.norm2.num_batches_tracked\", \"imageEncoder.features.denseblock2.denselayer4.conv2.weight\", \"imageEncoder.features.denseblock2.denselayer5.norm1.weight\", \"imageEncoder.features.denseblock2.denselayer5.norm1.bias\", \"imageEncoder.features.denseblock2.denselayer5.norm1.running_mean\", \"imageEncoder.features.denseblock2.denselayer5.norm1.running_var\", \"imageEncoder.features.denseblock2.denselayer5.norm1.num_batches_tracked\", \"imageEncoder.features.denseblock2.denselayer5.conv1.weight\", \"imageEncoder.features.denseblock2.denselayer5.norm2.weight\", \"imageEncoder.features.denseblock2.denselayer5.norm2.bias\", \"imageEncoder.features.denseblock2.denselayer5.norm2.running_mean\", \"imageEncoder.features.denseblock2.denselayer5.norm2.running_var\", \"imageEncoder.features.denseblock2.denselayer5.norm2.num_batches_tracked\", \"imageEncoder.features.denseblock2.denselayer5.conv2.weight\", \"imageEncoder.features.denseblock2.denselayer6.norm1.weight\", \"imageEncoder.features.denseblock2.denselayer6.norm1.bias\", \"imageEncoder.features.denseblock2.denselayer6.norm1.running_mean\", \"imageEncoder.features.denseblock2.denselayer6.norm1.running_var\", \"imageEncoder.features.denseblock2.denselayer6.norm1.num_batches_tracked\", \"imageEncoder.features.denseblock2.denselayer6.conv1.weight\", \"imageEncoder.features.denseblock2.denselayer6.norm2.weight\", \"imageEncoder.features.denseblock2.denselayer6.norm2.bias\", \"imageEncoder.features.denseblock2.denselayer6.norm2.running_mean\", \"imageEncoder.features.denseblock2.denselayer6.norm2.running_var\", \"imageEncoder.features.denseblock2.denselayer6.norm2.num_batches_tracked\", \"imageEncoder.features.denseblock2.denselayer6.conv2.weight\", \"imageEncoder.features.denseblock2.denselayer7.norm1.weight\", \"imageEncoder.features.denseblock2.denselayer7.norm1.bias\", \"imageEncoder.features.denseblock2.denselayer7.norm1.running_mean\", \"imageEncoder.features.denseblock2.denselayer7.norm1.running_var\", \"imageEncoder.features.denseblock2.denselayer7.norm1.num_batches_tracked\", \"imageEncoder.features.denseblock2.denselayer7.conv1.weight\", \"imageEncoder.features.denseblock2.denselayer7.norm2.weight\", \"imageEncoder.features.denseblock2.denselayer7.norm2.bias\", \"imageEncoder.features.denseblock2.denselayer7.norm2.running_mean\", \"imageEncoder.features.denseblock2.denselayer7.norm2.running_var\", \"imageEncoder.features.denseblock2.denselayer7.norm2.num_batches_tracked\", \"imageEncoder.features.denseblock2.denselayer7.conv2.weight\", \"imageEncoder.features.denseblock2.denselayer8.norm1.weight\", \"imageEncoder.features.denseblock2.denselayer8.norm1.bias\", \"imageEncoder.features.denseblock2.denselayer8.norm1.running_mean\", \"imageEncoder.features.denseblock2.denselayer8.norm1.running_var\", \"imageEncoder.features.denseblock2.denselayer8.norm1.num_batches_tracked\", \"imageEncoder.features.denseblock2.denselayer8.conv1.weight\", \"imageEncoder.features.denseblock2.denselayer8.norm2.weight\", \"imageEncoder.features.denseblock2.denselayer8.norm2.bias\", \"imageEncoder.features.denseblock2.denselayer8.norm2.running_mean\", \"imageEncoder.features.denseblock2.denselayer8.norm2.running_var\", \"imageEncoder.features.denseblock2.denselayer8.norm2.num_batches_tracked\", \"imageEncoder.features.denseblock2.denselayer8.conv2.weight\", \"imageEncoder.features.denseblock2.denselayer9.norm1.weight\", \"imageEncoder.features.denseblock2.denselayer9.norm1.bias\", \"imageEncoder.features.denseblock2.denselayer9.norm1.running_mean\", \"imageEncoder.features.denseblock2.denselayer9.norm1.running_var\", \"imageEncoder.features.denseblock2.denselayer9.norm1.num_batches_tracked\", \"imageEncoder.features.denseblock2.denselayer9.conv1.weight\", \"imageEncoder.features.denseblock2.denselayer9.norm2.weight\", \"imageEncoder.features.denseblock2.denselayer9.norm2.bias\", \"imageEncoder.features.denseblock2.denselayer9.norm2.running_mean\", \"imageEncoder.features.denseblock2.denselayer9.norm2.running_var\", \"imageEncoder.features.denseblock2.denselayer9.norm2.num_batches_tracked\", \"imageEncoder.features.denseblock2.denselayer9.conv2.weight\", \"imageEncoder.features.denseblock2.denselayer10.norm1.weight\", \"imageEncoder.features.denseblock2.denselayer10.norm1.bias\", \"imageEncoder.features.denseblock2.denselayer10.norm1.running_mean\", \"imageEncoder.features.denseblock2.denselayer10.norm1.running_var\", \"imageEncoder.features.denseblock2.denselayer10.norm1.num_batches_tracked\", \"imageEncoder.features.denseblock2.denselayer10.conv1.weight\", \"imageEncoder.features.denseblock2.denselayer10.norm2.weight\", \"imageEncoder.features.denseblock2.denselayer10.norm2.bias\", \"imageEncoder.features.denseblock2.denselayer10.norm2.running_mean\", \"imageEncoder.features.denseblock2.denselayer10.norm2.running_var\", \"imageEncoder.features.denseblock2.denselayer10.norm2.num_batches_tracked\", \"imageEncoder.features.denseblock2.denselayer10.conv2.weight\", \"imageEncoder.features.denseblock2.denselayer11.norm1.weight\", \"imageEncoder.features.denseblock2.denselayer11.norm1.bias\", \"imageEncoder.features.denseblock2.denselayer11.norm1.running_mean\", \"imageEncoder.features.denseblock2.denselayer11.norm1.running_var\", \"imageEncoder.features.denseblock2.denselayer11.norm1.num_batches_tracked\", \"imageEncoder.features.denseblock2.denselayer11.conv1.weight\", \"imageEncoder.features.denseblock2.denselayer11.norm2.weight\", \"imageEncoder.features.denseblock2.denselayer11.norm2.bias\", \"imageEncoder.features.denseblock2.denselayer11.norm2.running_mean\", \"imageEncoder.features.denseblock2.denselayer11.norm2.running_var\", \"imageEncoder.features.denseblock2.denselayer11.norm2.num_batches_tracked\", \"imageEncoder.features.denseblock2.denselayer11.conv2.weight\", \"imageEncoder.features.denseblock2.denselayer12.norm1.weight\", \"imageEncoder.features.denseblock2.denselayer12.norm1.bias\", \"imageEncoder.features.denseblock2.denselayer12.norm1.running_mean\", \"imageEncoder.features.denseblock2.denselayer12.norm1.running_var\", \"imageEncoder.features.denseblock2.denselayer12.norm1.num_batches_tracked\", \"imageEncoder.features.denseblock2.denselayer12.conv1.weight\", \"imageEncoder.features.denseblock2.denselayer12.norm2.weight\", \"imageEncoder.features.denseblock2.denselayer12.norm2.bias\", \"imageEncoder.features.denseblock2.denselayer12.norm2.running_mean\", \"imageEncoder.features.denseblock2.denselayer12.norm2.running_var\", \"imageEncoder.features.denseblock2.denselayer12.norm2.num_batches_tracked\", \"imageEncoder.features.denseblock2.denselayer12.conv2.weight\", \"imageEncoder.features.transition2.norm.weight\", \"imageEncoder.features.transition2.norm.bias\", \"imageEncoder.features.transition2.norm.running_mean\", \"imageEncoder.features.transition2.norm.running_var\", \"imageEncoder.features.transition2.norm.num_batches_tracked\", \"imageEncoder.features.transition2.conv.weight\", \"imageEncoder.features.denseblock3.denselayer1.norm1.weight\", \"imageEncoder.features.denseblock3.denselayer1.norm1.bias\", \"imageEncoder.features.denseblock3.denselayer1.norm1.running_mean\", \"imageEncoder.features.denseblock3.denselayer1.norm1.running_var\", \"imageEncoder.features.denseblock3.denselayer1.norm1.num_batches_tracked\", \"imageEncoder.features.denseblock3.denselayer1.conv1.weight\", \"imageEncoder.features.denseblock3.denselayer1.norm2.weight\", \"imageEncoder.features.denseblock3.denselayer1.norm2.bias\", \"imageEncoder.features.denseblock3.denselayer1.norm2.running_mean\", \"imageEncoder.features.denseblock3.denselayer1.norm2.running_var\", \"imageEncoder.features.denseblock3.denselayer1.norm2.num_batches_tracked\", \"imageEncoder.features.denseblock3.denselayer1.conv2.weight\", \"imageEncoder.features.denseblock3.denselayer2.norm1.weight\", \"imageEncoder.features.denseblock3.denselayer2.norm1.bias\", \"imageEncoder.features.denseblock3.denselayer2.norm1.running_mean\", \"imageEncoder.features.denseblock3.denselayer2.norm1.running_var\", \"imageEncoder.features.denseblock3.denselayer2.norm1.num_batches_tracked\", \"imageEncoder.features.denseblock3.denselayer2.conv1.weight\", \"imageEncoder.features.denseblock3.denselayer2.norm2.weight\", \"imageEncoder.features.denseblock3.denselayer2.norm2.bias\", \"imageEncoder.features.denseblock3.denselayer2.norm2.running_mean\", \"imageEncoder.features.denseblock3.denselayer2.norm2.running_var\", \"imageEncoder.features.denseblock3.denselayer2.norm2.num_batches_tracked\", \"imageEncoder.features.denseblock3.denselayer2.conv2.weight\", \"imageEncoder.features.denseblock3.denselayer3.norm1.weight\", \"imageEncoder.features.denseblock3.denselayer3.norm1.bias\", \"imageEncoder.features.denseblock3.denselayer3.norm1.running_mean\", \"imageEncoder.features.denseblock3.denselayer3.norm1.running_var\", \"imageEncoder.features.denseblock3.denselayer3.norm1.num_batches_tracked\", \"imageEncoder.features.denseblock3.denselayer3.conv1.weight\", \"imageEncoder.features.denseblock3.denselayer3.norm2.weight\", \"imageEncoder.features.denseblock3.denselayer3.norm2.bias\", \"imageEncoder.features.denseblock3.denselayer3.norm2.running_mean\", \"imageEncoder.features.denseblock3.denselayer3.norm2.running_var\", \"imageEncoder.features.denseblock3.denselayer3.norm2.num_batches_tracked\", \"imageEncoder.features.denseblock3.denselayer3.conv2.weight\", \"imageEncoder.features.denseblock3.denselayer4.norm1.weight\", \"imageEncoder.features.denseblock3.denselayer4.norm1.bias\", \"imageEncoder.features.denseblock3.denselayer4.norm1.running_mean\", \"imageEncoder.features.denseblock3.denselayer4.norm1.running_var\", \"imageEncoder.features.denseblock3.denselayer4.norm1.num_batches_tracked\", \"imageEncoder.features.denseblock3.denselayer4.conv1.weight\", \"imageEncoder.features.denseblock3.denselayer4.norm2.weight\", \"imageEncoder.features.denseblock3.denselayer4.norm2.bias\", \"imageEncoder.features.denseblock3.denselayer4.norm2.running_mean\", \"imageEncoder.features.denseblock3.denselayer4.norm2.running_var\", \"imageEncoder.features.denseblock3.denselayer4.norm2.num_batches_tracked\", \"imageEncoder.features.denseblock3.denselayer4.conv2.weight\", \"imageEncoder.features.denseblock3.denselayer5.norm1.weight\", \"imageEncoder.features.denseblock3.denselayer5.norm1.bias\", \"imageEncoder.features.denseblock3.denselayer5.norm1.running_mean\", \"imageEncoder.features.denseblock3.denselayer5.norm1.running_var\", \"imageEncoder.features.denseblock3.denselayer5.norm1.num_batches_tracked\", \"imageEncoder.features.denseblock3.denselayer5.conv1.weight\", \"imageEncoder.features.denseblock3.denselayer5.norm2.weight\", \"imageEncoder.features.denseblock3.denselayer5.norm2.bias\", \"imageEncoder.features.denseblock3.denselayer5.norm2.running_mean\", \"imageEncoder.features.denseblock3.denselayer5.norm2.running_var\", \"imageEncoder.features.denseblock3.denselayer5.norm2.num_batches_tracked\", \"imageEncoder.features.denseblock3.denselayer5.conv2.weight\", \"imageEncoder.features.denseblock3.denselayer6.norm1.weight\", \"imageEncoder.features.denseblock3.denselayer6.norm1.bias\", \"imageEncoder.features.denseblock3.denselayer6.norm1.running_mean\", \"imageEncoder.features.denseblock3.denselayer6.norm1.running_var\", \"imageEncoder.features.denseblock3.denselayer6.norm1.num_batches_tracked\", \"imageEncoder.features.denseblock3.denselayer6.conv1.weight\", \"imageEncoder.features.denseblock3.denselayer6.norm2.weight\", \"imageEncoder.features.denseblock3.denselayer6.norm2.bias\", \"imageEncoder.features.denseblock3.denselayer6.norm2.running_mean\", \"imageEncoder.features.denseblock3.denselayer6.norm2.running_var\", \"imageEncoder.features.denseblock3.denselayer6.norm2.num_batches_tracked\", \"imageEncoder.features.denseblock3.denselayer6.conv2.weight\", \"imageEncoder.features.denseblock3.denselayer7.norm1.weight\", \"imageEncoder.features.denseblock3.denselayer7.norm1.bias\", \"imageEncoder.features.denseblock3.denselayer7.norm1.running_mean\", \"imageEncoder.features.denseblock3.denselayer7.norm1.running_var\", \"imageEncoder.features.denseblock3.denselayer7.norm1.num_batches_tracked\", \"imageEncoder.features.denseblock3.denselayer7.conv1.weight\", \"imageEncoder.features.denseblock3.denselayer7.norm2.weight\", \"imageEncoder.features.denseblock3.denselayer7.norm2.bias\", \"imageEncoder.features.denseblock3.denselayer7.norm2.running_mean\", \"imageEncoder.features.denseblock3.denselayer7.norm2.running_var\", \"imageEncoder.features.denseblock3.denselayer7.norm2.num_batches_tracked\", \"imageEncoder.features.denseblock3.denselayer7.conv2.weight\", \"imageEncoder.features.denseblock3.denselayer8.norm1.weight\", \"imageEncoder.features.denseblock3.denselayer8.norm1.bias\", \"imageEncoder.features.denseblock3.denselayer8.norm1.running_mean\", \"imageEncoder.features.denseblock3.denselayer8.norm1.running_var\", \"imageEncoder.features.denseblock3.denselayer8.norm1.num_batches_tracked\", \"imageEncoder.features.denseblock3.denselayer8.conv1.weight\", \"imageEncoder.features.denseblock3.denselayer8.norm2.weight\", \"imageEncoder.features.denseblock3.denselayer8.norm2.bias\", \"imageEncoder.features.denseblock3.denselayer8.norm2.running_mean\", \"imageEncoder.features.denseblock3.denselayer8.norm2.running_var\", \"imageEncoder.features.denseblock3.denselayer8.norm2.num_batches_tracked\", \"imageEncoder.features.denseblock3.denselayer8.conv2.weight\", \"imageEncoder.features.denseblock3.denselayer9.norm1.weight\", \"imageEncoder.features.denseblock3.denselayer9.norm1.bias\", \"imageEncoder.features.denseblock3.denselayer9.norm1.running_mean\", \"imageEncoder.features.denseblock3.denselayer9.norm1.running_var\", \"imageEncoder.features.denseblock3.denselayer9.norm1.num_batches_tracked\", \"imageEncoder.features.denseblock3.denselayer9.conv1.weight\", \"imageEncoder.features.denseblock3.denselayer9.norm2.weight\", \"imageEncoder.features.denseblock3.denselayer9.norm2.bias\", \"imageEncoder.features.denseblock3.denselayer9.norm2.running_mean\", \"imageEncoder.features.denseblock3.denselayer9.norm2.running_var\", \"imageEncoder.features.denseblock3.denselayer9.norm2.num_batches_tracked\", \"imageEncoder.features.denseblock3.denselayer9.conv2.weight\", \"imageEncoder.features.denseblock3.denselayer10.norm1.weight\", \"imageEncoder.features.denseblock3.denselayer10.norm1.bias\", \"imageEncoder.features.denseblock3.denselayer10.norm1.running_mean\", \"imageEncoder.features.denseblock3.denselayer10.norm1.running_var\", \"imageEncoder.features.denseblock3.denselayer10.norm1.num_batches_tracked\", \"imageEncoder.features.denseblock3.denselayer10.conv1.weight\", \"imageEncoder.features.denseblock3.denselayer10.norm2.weight\", \"imageEncoder.features.denseblock3.denselayer10.norm2.bias\", \"imageEncoder.features.denseblock3.denselayer10.norm2.running_mean\", \"imageEncoder.features.denseblock3.denselayer10.norm2.running_var\", \"imageEncoder.features.denseblock3.denselayer10.norm2.num_batches_tracked\", \"imageEncoder.features.denseblock3.denselayer10.conv2.weight\", \"imageEncoder.features.denseblock3.denselayer11.norm1.weight\", \"imageEncoder.features.denseblock3.denselayer11.norm1.bias\", \"imageEncoder.features.denseblock3.denselayer11.norm1.running_mean\", \"imageEncoder.features.denseblock3.denselayer11.norm1.running_var\", \"imageEncoder.features.denseblock3.denselayer11.norm1.num_batches_tracked\", \"imageEncoder.features.denseblock3.denselayer11.conv1.weight\", \"imageEncoder.features.denseblock3.denselayer11.norm2.weight\", \"imageEncoder.features.denseblock3.denselayer11.norm2.bias\", \"imageEncoder.features.denseblock3.denselayer11.norm2.running_mean\", \"imageEncoder.features.denseblock3.denselayer11.norm2.running_var\", \"imageEncoder.features.denseblock3.denselayer11.norm2.num_batches_tracked\", \"imageEncoder.features.denseblock3.denselayer11.conv2.weight\", \"imageEncoder.features.denseblock3.denselayer12.norm1.weight\", \"imageEncoder.features.denseblock3.denselayer12.norm1.bias\", \"imageEncoder.features.denseblock3.denselayer12.norm1.running_mean\", \"imageEncoder.features.denseblock3.denselayer12.norm1.running_var\", \"imageEncoder.features.denseblock3.denselayer12.norm1.num_batches_tracked\", \"imageEncoder.features.denseblock3.denselayer12.conv1.weight\", \"imageEncoder.features.denseblock3.denselayer12.norm2.weight\", \"imageEncoder.features.denseblock3.denselayer12.norm2.bias\", \"imageEncoder.features.denseblock3.denselayer12.norm2.running_mean\", \"imageEncoder.features.denseblock3.denselayer12.norm2.running_var\", \"imageEncoder.features.denseblock3.denselayer12.norm2.num_batches_tracked\", \"imageEncoder.features.denseblock3.denselayer12.conv2.weight\", \"imageEncoder.features.denseblock3.denselayer13.norm1.weight\", \"imageEncoder.features.denseblock3.denselayer13.norm1.bias\", \"imageEncoder.features.denseblock3.denselayer13.norm1.running_mean\", \"imageEncoder.features.denseblock3.denselayer13.norm1.running_var\", \"imageEncoder.features.denseblock3.denselayer13.norm1.num_batches_tracked\", \"imageEncoder.features.denseblock3.denselayer13.conv1.weight\", \"imageEncoder.features.denseblock3.denselayer13.norm2.weight\", \"imageEncoder.features.denseblock3.denselayer13.norm2.bias\", \"imageEncoder.features.denseblock3.denselayer13.norm2.running_mean\", \"imageEncoder.features.denseblock3.denselayer13.norm2.running_var\", \"imageEncoder.features.denseblock3.denselayer13.norm2.num_batches_tracked\", \"imageEncoder.features.denseblock3.denselayer13.conv2.weight\", \"imageEncoder.features.denseblock3.denselayer14.norm1.weight\", \"imageEncoder.features.denseblock3.denselayer14.norm1.bias\", \"imageEncoder.features.denseblock3.denselayer14.norm1.running_mean\", \"imageEncoder.features.denseblock3.denselayer14.norm1.running_var\", \"imageEncoder.features.denseblock3.denselayer14.norm1.num_batches_tracked\", \"imageEncoder.features.denseblock3.denselayer14.conv1.weight\", \"imageEncoder.features.denseblock3.denselayer14.norm2.weight\", \"imageEncoder.features.denseblock3.denselayer14.norm2.bias\", \"imageEncoder.features.denseblock3.denselayer14.norm2.running_mean\", \"imageEncoder.features.denseblock3.denselayer14.norm2.running_var\", \"imageEncoder.features.denseblock3.denselayer14.norm2.num_batches_tracked\", \"imageEncoder.features.denseblock3.denselayer14.conv2.weight\", \"imageEncoder.features.denseblock3.denselayer15.norm1.weight\", \"imageEncoder.features.denseblock3.denselayer15.norm1.bias\", \"imageEncoder.features.denseblock3.denselayer15.norm1.running_mean\", \"imageEncoder.features.denseblock3.denselayer15.norm1.running_var\", \"imageEncoder.features.denseblock3.denselayer15.norm1.num_batches_tracked\", \"imageEncoder.features.denseblock3.denselayer15.conv1.weight\", \"imageEncoder.features.denseblock3.denselayer15.norm2.weight\", \"imageEncoder.features.denseblock3.denselayer15.norm2.bias\", \"imageEncoder.features.denseblock3.denselayer15.norm2.running_mean\", \"imageEncoder.features.denseblock3.denselayer15.norm2.running_var\", \"imageEncoder.features.denseblock3.denselayer15.norm2.num_batches_tracked\", \"imageEncoder.features.denseblock3.denselayer15.conv2.weight\", \"imageEncoder.features.denseblock3.denselayer16.norm1.weight\", \"imageEncoder.features.denseblock3.denselayer16.norm1.bias\", \"imageEncoder.features.denseblock3.denselayer16.norm1.running_mean\", \"imageEncoder.features.denseblock3.denselayer16.norm1.running_var\", \"imageEncoder.features.denseblock3.denselayer16.norm1.num_batches_tracked\", \"imageEncoder.features.denseblock3.denselayer16.conv1.weight\", \"imageEncoder.features.denseblock3.denselayer16.norm2.weight\", \"imageEncoder.features.denseblock3.denselayer16.norm2.bias\", \"imageEncoder.features.denseblock3.denselayer16.norm2.running_mean\", \"imageEncoder.features.denseblock3.denselayer16.norm2.running_var\", \"imageEncoder.features.denseblock3.denselayer16.norm2.num_batches_tracked\", \"imageEncoder.features.denseblock3.denselayer16.conv2.weight\", \"imageEncoder.features.denseblock3.denselayer17.norm1.weight\", \"imageEncoder.features.denseblock3.denselayer17.norm1.bias\", \"imageEncoder.features.denseblock3.denselayer17.norm1.running_mean\", \"imageEncoder.features.denseblock3.denselayer17.norm1.running_var\", \"imageEncoder.features.denseblock3.denselayer17.norm1.num_batches_tracked\", \"imageEncoder.features.denseblock3.denselayer17.conv1.weight\", \"imageEncoder.features.denseblock3.denselayer17.norm2.weight\", \"imageEncoder.features.denseblock3.denselayer17.norm2.bias\", \"imageEncoder.features.denseblock3.denselayer17.norm2.running_mean\", \"imageEncoder.features.denseblock3.denselayer17.norm2.running_var\", \"imageEncoder.features.denseblock3.denselayer17.norm2.num_batches_tracked\", \"imageEncoder.features.denseblock3.denselayer17.conv2.weight\", \"imageEncoder.features.denseblock3.denselayer18.norm1.weight\", \"imageEncoder.features.denseblock3.denselayer18.norm1.bias\", \"imageEncoder.features.denseblock3.denselayer18.norm1.running_mean\", \"imageEncoder.features.denseblock3.denselayer18.norm1.running_var\", \"imageEncoder.features.denseblock3.denselayer18.norm1.num_batches_tracked\", \"imageEncoder.features.denseblock3.denselayer18.conv1.weight\", \"imageEncoder.features.denseblock3.denselayer18.norm2.weight\", \"imageEncoder.features.denseblock3.denselayer18.norm2.bias\", \"imageEncoder.features.denseblock3.denselayer18.norm2.running_mean\", \"imageEncoder.features.denseblock3.denselayer18.norm2.running_var\", \"imageEncoder.features.denseblock3.denselayer18.norm2.num_batches_tracked\", \"imageEncoder.features.denseblock3.denselayer18.conv2.weight\", \"imageEncoder.features.denseblock3.denselayer19.norm1.weight\", \"imageEncoder.features.denseblock3.denselayer19.norm1.bias\", \"imageEncoder.features.denseblock3.denselayer19.norm1.running_mean\", \"imageEncoder.features.denseblock3.denselayer19.norm1.running_var\", \"imageEncoder.features.denseblock3.denselayer19.norm1.num_batches_tracked\", \"imageEncoder.features.denseblock3.denselayer19.conv1.weight\", \"imageEncoder.features.denseblock3.denselayer19.norm2.weight\", \"imageEncoder.features.denseblock3.denselayer19.norm2.bias\", \"imageEncoder.features.denseblock3.denselayer19.norm2.running_mean\", \"imageEncoder.features.denseblock3.denselayer19.norm2.running_var\", \"imageEncoder.features.denseblock3.denselayer19.norm2.num_batches_tracked\", \"imageEncoder.features.denseblock3.denselayer19.conv2.weight\", \"imageEncoder.features.denseblock3.denselayer20.norm1.weight\", \"imageEncoder.features.denseblock3.denselayer20.norm1.bias\", \"imageEncoder.features.denseblock3.denselayer20.norm1.running_mean\", \"imageEncoder.features.denseblock3.denselayer20.norm1.running_var\", \"imageEncoder.features.denseblock3.denselayer20.norm1.num_batches_tracked\", \"imageEncoder.features.denseblock3.denselayer20.conv1.weight\", \"imageEncoder.features.denseblock3.denselayer20.norm2.weight\", \"imageEncoder.features.denseblock3.denselayer20.norm2.bias\", \"imageEncoder.features.denseblock3.denselayer20.norm2.running_mean\", \"imageEncoder.features.denseblock3.denselayer20.norm2.running_var\", \"imageEncoder.features.denseblock3.denselayer20.norm2.num_batches_tracked\", \"imageEncoder.features.denseblock3.denselayer20.conv2.weight\", \"imageEncoder.features.denseblock3.denselayer21.norm1.weight\", \"imageEncoder.features.denseblock3.denselayer21.norm1.bias\", \"imageEncoder.features.denseblock3.denselayer21.norm1.running_mean\", \"imageEncoder.features.denseblock3.denselayer21.norm1.running_var\", \"imageEncoder.features.denseblock3.denselayer21.norm1.num_batches_tracked\", \"imageEncoder.features.denseblock3.denselayer21.conv1.weight\", \"imageEncoder.features.denseblock3.denselayer21.norm2.weight\", \"imageEncoder.features.denseblock3.denselayer21.norm2.bias\", \"imageEncoder.features.denseblock3.denselayer21.norm2.running_mean\", \"imageEncoder.features.denseblock3.denselayer21.norm2.running_var\", \"imageEncoder.features.denseblock3.denselayer21.norm2.num_batches_tracked\", \"imageEncoder.features.denseblock3.denselayer21.conv2.weight\", \"imageEncoder.features.denseblock3.denselayer22.norm1.weight\", \"imageEncoder.features.denseblock3.denselayer22.norm1.bias\", \"imageEncoder.features.denseblock3.denselayer22.norm1.running_mean\", \"imageEncoder.features.denseblock3.denselayer22.norm1.running_var\", \"imageEncoder.features.denseblock3.denselayer22.norm1.num_batches_tracked\", \"imageEncoder.features.denseblock3.denselayer22.conv1.weight\", \"imageEncoder.features.denseblock3.denselayer22.norm2.weight\", \"imageEncoder.features.denseblock3.denselayer22.norm2.bias\", \"imageEncoder.features.denseblock3.denselayer22.norm2.running_mean\", \"imageEncoder.features.denseblock3.denselayer22.norm2.running_var\", \"imageEncoder.features.denseblock3.denselayer22.norm2.num_batches_tracked\", \"imageEncoder.features.denseblock3.denselayer22.conv2.weight\", \"imageEncoder.features.denseblock3.denselayer23.norm1.weight\", \"imageEncoder.features.denseblock3.denselayer23.norm1.bias\", \"imageEncoder.features.denseblock3.denselayer23.norm1.running_mean\", \"imageEncoder.features.denseblock3.denselayer23.norm1.running_var\", \"imageEncoder.features.denseblock3.denselayer23.norm1.num_batches_tracked\", \"imageEncoder.features.denseblock3.denselayer23.conv1.weight\", \"imageEncoder.features.denseblock3.denselayer23.norm2.weight\", \"imageEncoder.features.denseblock3.denselayer23.norm2.bias\", \"imageEncoder.features.denseblock3.denselayer23.norm2.running_mean\", \"imageEncoder.features.denseblock3.denselayer23.norm2.running_var\", \"imageEncoder.features.denseblock3.denselayer23.norm2.num_batches_tracked\", \"imageEncoder.features.denseblock3.denselayer23.conv2.weight\", \"imageEncoder.features.denseblock3.denselayer24.norm1.weight\", \"imageEncoder.features.denseblock3.denselayer24.norm1.bias\", \"imageEncoder.features.denseblock3.denselayer24.norm1.running_mean\", \"imageEncoder.features.denseblock3.denselayer24.norm1.running_var\", \"imageEncoder.features.denseblock3.denselayer24.norm1.num_batches_tracked\", \"imageEncoder.features.denseblock3.denselayer24.conv1.weight\", \"imageEncoder.features.denseblock3.denselayer24.norm2.weight\", \"imageEncoder.features.denseblock3.denselayer24.norm2.bias\", \"imageEncoder.features.denseblock3.denselayer24.norm2.running_mean\", \"imageEncoder.features.denseblock3.denselayer24.norm2.running_var\", \"imageEncoder.features.denseblock3.denselayer24.norm2.num_batches_tracked\", \"imageEncoder.features.denseblock3.denselayer24.conv2.weight\", \"imageEncoder.features.denseblock3.denselayer25.norm1.weight\", \"imageEncoder.features.denseblock3.denselayer25.norm1.bias\", \"imageEncoder.features.denseblock3.denselayer25.norm1.running_mean\", \"imageEncoder.features.denseblock3.denselayer25.norm1.running_var\", \"imageEncoder.features.denseblock3.denselayer25.norm1.num_batches_tracked\", \"imageEncoder.features.denseblock3.denselayer25.conv1.weight\", \"imageEncoder.features.denseblock3.denselayer25.norm2.weight\", \"imageEncoder.features.denseblock3.denselayer25.norm2.bias\", \"imageEncoder.features.denseblock3.denselayer25.norm2.running_mean\", \"imageEncoder.features.denseblock3.denselayer25.norm2.running_var\", \"imageEncoder.features.denseblock3.denselayer25.norm2.num_batches_tracked\", \"imageEncoder.features.denseblock3.denselayer25.conv2.weight\", \"imageEncoder.features.denseblock3.denselayer26.norm1.weight\", \"imageEncoder.features.denseblock3.denselayer26.norm1.bias\", \"imageEncoder.features.denseblock3.denselayer26.norm1.running_mean\", \"imageEncoder.features.denseblock3.denselayer26.norm1.running_var\", \"imageEncoder.features.denseblock3.denselayer26.norm1.num_batches_tracked\", \"imageEncoder.features.denseblock3.denselayer26.conv1.weight\", \"imageEncoder.features.denseblock3.denselayer26.norm2.weight\", \"imageEncoder.features.denseblock3.denselayer26.norm2.bias\", \"imageEncoder.features.denseblock3.denselayer26.norm2.running_mean\", \"imageEncoder.features.denseblock3.denselayer26.norm2.running_var\", \"imageEncoder.features.denseblock3.denselayer26.norm2.num_batches_tracked\", \"imageEncoder.features.denseblock3.denselayer26.conv2.weight\", \"imageEncoder.features.denseblock3.denselayer27.norm1.weight\", \"imageEncoder.features.denseblock3.denselayer27.norm1.bias\", \"imageEncoder.features.denseblock3.denselayer27.norm1.running_mean\", \"imageEncoder.features.denseblock3.denselayer27.norm1.running_var\", \"imageEncoder.features.denseblock3.denselayer27.norm1.num_batches_tracked\", \"imageEncoder.features.denseblock3.denselayer27.conv1.weight\", \"imageEncoder.features.denseblock3.denselayer27.norm2.weight\", \"imageEncoder.features.denseblock3.denselayer27.norm2.bias\", \"imageEncoder.features.denseblock3.denselayer27.norm2.running_mean\", \"imageEncoder.features.denseblock3.denselayer27.norm2.running_var\", \"imageEncoder.features.denseblock3.denselayer27.norm2.num_batches_tracked\", \"imageEncoder.features.denseblock3.denselayer27.conv2.weight\", \"imageEncoder.features.denseblock3.denselayer28.norm1.weight\", \"imageEncoder.features.denseblock3.denselayer28.norm1.bias\", \"imageEncoder.features.denseblock3.denselayer28.norm1.running_mean\", \"imageEncoder.features.denseblock3.denselayer28.norm1.running_var\", \"imageEncoder.features.denseblock3.denselayer28.norm1.num_batches_tracked\", \"imageEncoder.features.denseblock3.denselayer28.conv1.weight\", \"imageEncoder.features.denseblock3.denselayer28.norm2.weight\", \"imageEncoder.features.denseblock3.denselayer28.norm2.bias\", \"imageEncoder.features.denseblock3.denselayer28.norm2.running_mean\", \"imageEncoder.features.denseblock3.denselayer28.norm2.running_var\", \"imageEncoder.features.denseblock3.denselayer28.norm2.num_batches_tracked\", \"imageEncoder.features.denseblock3.denselayer28.conv2.weight\", \"imageEncoder.features.denseblock3.denselayer29.norm1.weight\", \"imageEncoder.features.denseblock3.denselayer29.norm1.bias\", \"imageEncoder.features.denseblock3.denselayer29.norm1.running_mean\", \"imageEncoder.features.denseblock3.denselayer29.norm1.running_var\", \"imageEncoder.features.denseblock3.denselayer29.norm1.num_batches_tracked\", \"imageEncoder.features.denseblock3.denselayer29.conv1.weight\", \"imageEncoder.features.denseblock3.denselayer29.norm2.weight\", \"imageEncoder.features.denseblock3.denselayer29.norm2.bias\", \"imageEncoder.features.denseblock3.denselayer29.norm2.running_mean\", \"imageEncoder.features.denseblock3.denselayer29.norm2.running_var\", \"imageEncoder.features.denseblock3.denselayer29.norm2.num_batches_tracked\", \"imageEncoder.features.denseblock3.denselayer29.conv2.weight\", \"imageEncoder.features.denseblock3.denselayer30.norm1.weight\", \"imageEncoder.features.denseblock3.denselayer30.norm1.bias\", \"imageEncoder.features.denseblock3.denselayer30.norm1.running_mean\", \"imageEncoder.features.denseblock3.denselayer30.norm1.running_var\", \"imageEncoder.features.denseblock3.denselayer30.norm1.num_batches_tracked\", \"imageEncoder.features.denseblock3.denselayer30.conv1.weight\", \"imageEncoder.features.denseblock3.denselayer30.norm2.weight\", \"imageEncoder.features.denseblock3.denselayer30.norm2.bias\", \"imageEncoder.features.denseblock3.denselayer30.norm2.running_mean\", \"imageEncoder.features.denseblock3.denselayer30.norm2.running_var\", \"imageEncoder.features.denseblock3.denselayer30.norm2.num_batches_tracked\", \"imageEncoder.features.denseblock3.denselayer30.conv2.weight\", \"imageEncoder.features.denseblock3.denselayer31.norm1.weight\", \"imageEncoder.features.denseblock3.denselayer31.norm1.bias\", \"imageEncoder.features.denseblock3.denselayer31.norm1.running_mean\", \"imageEncoder.features.denseblock3.denselayer31.norm1.running_var\", \"imageEncoder.features.denseblock3.denselayer31.norm1.num_batches_tracked\", \"imageEncoder.features.denseblock3.denselayer31.conv1.weight\", \"imageEncoder.features.denseblock3.denselayer31.norm2.weight\", \"imageEncoder.features.denseblock3.denselayer31.norm2.bias\", \"imageEncoder.features.denseblock3.denselayer31.norm2.running_mean\", \"imageEncoder.features.denseblock3.denselayer31.norm2.running_var\", \"imageEncoder.features.denseblock3.denselayer31.norm2.num_batches_tracked\", \"imageEncoder.features.denseblock3.denselayer31.conv2.weight\", \"imageEncoder.features.denseblock3.denselayer32.norm1.weight\", \"imageEncoder.features.denseblock3.denselayer32.norm1.bias\", \"imageEncoder.features.denseblock3.denselayer32.norm1.running_mean\", \"imageEncoder.features.denseblock3.denselayer32.norm1.running_var\", \"imageEncoder.features.denseblock3.denselayer32.norm1.num_batches_tracked\", \"imageEncoder.features.denseblock3.denselayer32.conv1.weight\", \"imageEncoder.features.denseblock3.denselayer32.norm2.weight\", \"imageEncoder.features.denseblock3.denselayer32.norm2.bias\", \"imageEncoder.features.denseblock3.denselayer32.norm2.running_mean\", \"imageEncoder.features.denseblock3.denselayer32.norm2.running_var\", \"imageEncoder.features.denseblock3.denselayer32.norm2.num_batches_tracked\", \"imageEncoder.features.denseblock3.denselayer32.conv2.weight\", \"imageEncoder.features.denseblock3.denselayer33.norm1.weight\", \"imageEncoder.features.denseblock3.denselayer33.norm1.bias\", \"imageEncoder.features.denseblock3.denselayer33.norm1.running_mean\", \"imageEncoder.features.denseblock3.denselayer33.norm1.running_var\", \"imageEncoder.features.denseblock3.denselayer33.norm1.num_batches_tracked\", \"imageEncoder.features.denseblock3.denselayer33.conv1.weight\", \"imageEncoder.features.denseblock3.denselayer33.norm2.weight\", \"imageEncoder.features.denseblock3.denselayer33.norm2.bias\", \"imageEncoder.features.denseblock3.denselayer33.norm2.running_mean\", \"imageEncoder.features.denseblock3.denselayer33.norm2.running_var\", \"imageEncoder.features.denseblock3.denselayer33.norm2.num_batches_tracked\", \"imageEncoder.features.denseblock3.denselayer33.conv2.weight\", \"imageEncoder.features.denseblock3.denselayer34.norm1.weight\", \"imageEncoder.features.denseblock3.denselayer34.norm1.bias\", \"imageEncoder.features.denseblock3.denselayer34.norm1.running_mean\", \"imageEncoder.features.denseblock3.denselayer34.norm1.running_var\", \"imageEncoder.features.denseblock3.denselayer34.norm1.num_batches_tracked\", \"imageEncoder.features.denseblock3.denselayer34.conv1.weight\", \"imageEncoder.features.denseblock3.denselayer34.norm2.weight\", \"imageEncoder.features.denseblock3.denselayer34.norm2.bias\", \"imageEncoder.features.denseblock3.denselayer34.norm2.running_mean\", \"imageEncoder.features.denseblock3.denselayer34.norm2.running_var\", \"imageEncoder.features.denseblock3.denselayer34.norm2.num_batches_tracked\", \"imageEncoder.features.denseblock3.denselayer34.conv2.weight\", \"imageEncoder.features.denseblock3.denselayer35.norm1.weight\", \"imageEncoder.features.denseblock3.denselayer35.norm1.bias\", \"imageEncoder.features.denseblock3.denselayer35.norm1.running_mean\", \"imageEncoder.features.denseblock3.denselayer35.norm1.running_var\", \"imageEncoder.features.denseblock3.denselayer35.norm1.num_batches_tracked\", \"imageEncoder.features.denseblock3.denselayer35.conv1.weight\", \"imageEncoder.features.denseblock3.denselayer35.norm2.weight\", \"imageEncoder.features.denseblock3.denselayer35.norm2.bias\", \"imageEncoder.features.denseblock3.denselayer35.norm2.running_mean\", \"imageEncoder.features.denseblock3.denselayer35.norm2.running_var\", \"imageEncoder.features.denseblock3.denselayer35.norm2.num_batches_tracked\", \"imageEncoder.features.denseblock3.denselayer35.conv2.weight\", \"imageEncoder.features.denseblock3.denselayer36.norm1.weight\", \"imageEncoder.features.denseblock3.denselayer36.norm1.bias\", \"imageEncoder.features.denseblock3.denselayer36.norm1.running_mean\", \"imageEncoder.features.denseblock3.denselayer36.norm1.running_var\", \"imageEncoder.features.denseblock3.denselayer36.norm1.num_batches_tracked\", \"imageEncoder.features.denseblock3.denselayer36.conv1.weight\", \"imageEncoder.features.denseblock3.denselayer36.norm2.weight\", \"imageEncoder.features.denseblock3.denselayer36.norm2.bias\", \"imageEncoder.features.denseblock3.denselayer36.norm2.running_mean\", \"imageEncoder.features.denseblock3.denselayer36.norm2.running_var\", \"imageEncoder.features.denseblock3.denselayer36.norm2.num_batches_tracked\", \"imageEncoder.features.denseblock3.denselayer36.conv2.weight\", \"imageEncoder.features.denseblock3.denselayer37.norm1.weight\", \"imageEncoder.features.denseblock3.denselayer37.norm1.bias\", \"imageEncoder.features.denseblock3.denselayer37.norm1.running_mean\", \"imageEncoder.features.denseblock3.denselayer37.norm1.running_var\", \"imageEncoder.features.denseblock3.denselayer37.norm1.num_batches_tracked\", \"imageEncoder.features.denseblock3.denselayer37.conv1.weight\", \"imageEncoder.features.denseblock3.denselayer37.norm2.weight\", \"imageEncoder.features.denseblock3.denselayer37.norm2.bias\", \"imageEncoder.features.denseblock3.denselayer37.norm2.running_mean\", \"imageEncoder.features.denseblock3.denselayer37.norm2.running_var\", \"imageEncoder.features.denseblock3.denselayer37.norm2.num_batches_tracked\", \"imageEncoder.features.denseblock3.denselayer37.conv2.weight\", \"imageEncoder.features.denseblock3.denselayer38.norm1.weight\", \"imageEncoder.features.denseblock3.denselayer38.norm1.bias\", \"imageEncoder.features.denseblock3.denselayer38.norm1.running_mean\", \"imageEncoder.features.denseblock3.denselayer38.norm1.running_var\", \"imageEncoder.features.denseblock3.denselayer38.norm1.num_batches_tracked\", \"imageEncoder.features.denseblock3.denselayer38.conv1.weight\", \"imageEncoder.features.denseblock3.denselayer38.norm2.weight\", \"imageEncoder.features.denseblock3.denselayer38.norm2.bias\", \"imageEncoder.features.denseblock3.denselayer38.norm2.running_mean\", \"imageEncoder.features.denseblock3.denselayer38.norm2.running_var\", \"imageEncoder.features.denseblock3.denselayer38.norm2.num_batches_tracked\", \"imageEncoder.features.denseblock3.denselayer38.conv2.weight\", \"imageEncoder.features.denseblock3.denselayer39.norm1.weight\", \"imageEncoder.features.denseblock3.denselayer39.norm1.bias\", \"imageEncoder.features.denseblock3.denselayer39.norm1.running_mean\", \"imageEncoder.features.denseblock3.denselayer39.norm1.running_var\", \"imageEncoder.features.denseblock3.denselayer39.norm1.num_batches_tracked\", \"imageEncoder.features.denseblock3.denselayer39.conv1.weight\", \"imageEncoder.features.denseblock3.denselayer39.norm2.weight\", \"imageEncoder.features.denseblock3.denselayer39.norm2.bias\", \"imageEncoder.features.denseblock3.denselayer39.norm2.running_mean\", \"imageEncoder.features.denseblock3.denselayer39.norm2.running_var\", \"imageEncoder.features.denseblock3.denselayer39.norm2.num_batches_tracked\", \"imageEncoder.features.denseblock3.denselayer39.conv2.weight\", \"imageEncoder.features.denseblock3.denselayer40.norm1.weight\", \"imageEncoder.features.denseblock3.denselayer40.norm1.bias\", \"imageEncoder.features.denseblock3.denselayer40.norm1.running_mean\", \"imageEncoder.features.denseblock3.denselayer40.norm1.running_var\", \"imageEncoder.features.denseblock3.denselayer40.norm1.num_batches_tracked\", \"imageEncoder.features.denseblock3.denselayer40.conv1.weight\", \"imageEncoder.features.denseblock3.denselayer40.norm2.weight\", \"imageEncoder.features.denseblock3.denselayer40.norm2.bias\", \"imageEncoder.features.denseblock3.denselayer40.norm2.running_mean\", \"imageEncoder.features.denseblock3.denselayer40.norm2.running_var\", \"imageEncoder.features.denseblock3.denselayer40.norm2.num_batches_tracked\", \"imageEncoder.features.denseblock3.denselayer40.conv2.weight\", \"imageEncoder.features.denseblock3.denselayer41.norm1.weight\", \"imageEncoder.features.denseblock3.denselayer41.norm1.bias\", \"imageEncoder.features.denseblock3.denselayer41.norm1.running_mean\", \"imageEncoder.features.denseblock3.denselayer41.norm1.running_var\", \"imageEncoder.features.denseblock3.denselayer41.norm1.num_batches_tracked\", \"imageEncoder.features.denseblock3.denselayer41.conv1.weight\", \"imageEncoder.features.denseblock3.denselayer41.norm2.weight\", \"imageEncoder.features.denseblock3.denselayer41.norm2.bias\", \"imageEncoder.features.denseblock3.denselayer41.norm2.running_mean\", \"imageEncoder.features.denseblock3.denselayer41.norm2.running_var\", \"imageEncoder.features.denseblock3.denselayer41.norm2.num_batches_tracked\", \"imageEncoder.features.denseblock3.denselayer41.conv2.weight\", \"imageEncoder.features.denseblock3.denselayer42.norm1.weight\", \"imageEncoder.features.denseblock3.denselayer42.norm1.bias\", \"imageEncoder.features.denseblock3.denselayer42.norm1.running_mean\", \"imageEncoder.features.denseblock3.denselayer42.norm1.running_var\", \"imageEncoder.features.denseblock3.denselayer42.norm1.num_batches_tracked\", \"imageEncoder.features.denseblock3.denselayer42.conv1.weight\", \"imageEncoder.features.denseblock3.denselayer42.norm2.weight\", \"imageEncoder.features.denseblock3.denselayer42.norm2.bias\", \"imageEncoder.features.denseblock3.denselayer42.norm2.running_mean\", \"imageEncoder.features.denseblock3.denselayer42.norm2.running_var\", \"imageEncoder.features.denseblock3.denselayer42.norm2.num_batches_tracked\", \"imageEncoder.features.denseblock3.denselayer42.conv2.weight\", \"imageEncoder.features.denseblock3.denselayer43.norm1.weight\", \"imageEncoder.features.denseblock3.denselayer43.norm1.bias\", \"imageEncoder.features.denseblock3.denselayer43.norm1.running_mean\", \"imageEncoder.features.denseblock3.denselayer43.norm1.running_var\", \"imageEncoder.features.denseblock3.denselayer43.norm1.num_batches_tracked\", \"imageEncoder.features.denseblock3.denselayer43.conv1.weight\", \"imageEncoder.features.denseblock3.denselayer43.norm2.weight\", \"imageEncoder.features.denseblock3.denselayer43.norm2.bias\", \"imageEncoder.features.denseblock3.denselayer43.norm2.running_mean\", \"imageEncoder.features.denseblock3.denselayer43.norm2.running_var\", \"imageEncoder.features.denseblock3.denselayer43.norm2.num_batches_tracked\", \"imageEncoder.features.denseblock3.denselayer43.conv2.weight\", \"imageEncoder.features.denseblock3.denselayer44.norm1.weight\", \"imageEncoder.features.denseblock3.denselayer44.norm1.bias\", \"imageEncoder.features.denseblock3.denselayer44.norm1.running_mean\", \"imageEncoder.features.denseblock3.denselayer44.norm1.running_var\", \"imageEncoder.features.denseblock3.denselayer44.norm1.num_batches_tracked\", \"imageEncoder.features.denseblock3.denselayer44.conv1.weight\", \"imageEncoder.features.denseblock3.denselayer44.norm2.weight\", \"imageEncoder.features.denseblock3.denselayer44.norm2.bias\", \"imageEncoder.features.denseblock3.denselayer44.norm2.running_mean\", \"imageEncoder.features.denseblock3.denselayer44.norm2.running_var\", \"imageEncoder.features.denseblock3.denselayer44.norm2.num_batches_tracked\", \"imageEncoder.features.denseblock3.denselayer44.conv2.weight\", \"imageEncoder.features.denseblock3.denselayer45.norm1.weight\", \"imageEncoder.features.denseblock3.denselayer45.norm1.bias\", \"imageEncoder.features.denseblock3.denselayer45.norm1.running_mean\", \"imageEncoder.features.denseblock3.denselayer45.norm1.running_var\", \"imageEncoder.features.denseblock3.denselayer45.norm1.num_batches_tracked\", \"imageEncoder.features.denseblock3.denselayer45.conv1.weight\", \"imageEncoder.features.denseblock3.denselayer45.norm2.weight\", \"imageEncoder.features.denseblock3.denselayer45.norm2.bias\", \"imageEncoder.features.denseblock3.denselayer45.norm2.running_mean\", \"imageEncoder.features.denseblock3.denselayer45.norm2.running_var\", \"imageEncoder.features.denseblock3.denselayer45.norm2.num_batches_tracked\", \"imageEncoder.features.denseblock3.denselayer45.conv2.weight\", \"imageEncoder.features.denseblock3.denselayer46.norm1.weight\", \"imageEncoder.features.denseblock3.denselayer46.norm1.bias\", \"imageEncoder.features.denseblock3.denselayer46.norm1.running_mean\", \"imageEncoder.features.denseblock3.denselayer46.norm1.running_var\", \"imageEncoder.features.denseblock3.denselayer46.norm1.num_batches_tracked\", \"imageEncoder.features.denseblock3.denselayer46.conv1.weight\", \"imageEncoder.features.denseblock3.denselayer46.norm2.weight\", \"imageEncoder.features.denseblock3.denselayer46.norm2.bias\", \"imageEncoder.features.denseblock3.denselayer46.norm2.running_mean\", \"imageEncoder.features.denseblock3.denselayer46.norm2.running_var\", \"imageEncoder.features.denseblock3.denselayer46.norm2.num_batches_tracked\", \"imageEncoder.features.denseblock3.denselayer46.conv2.weight\", \"imageEncoder.features.denseblock3.denselayer47.norm1.weight\", \"imageEncoder.features.denseblock3.denselayer47.norm1.bias\", \"imageEncoder.features.denseblock3.denselayer47.norm1.running_mean\", \"imageEncoder.features.denseblock3.denselayer47.norm1.running_var\", \"imageEncoder.features.denseblock3.denselayer47.norm1.num_batches_tracked\", \"imageEncoder.features.denseblock3.denselayer47.conv1.weight\", \"imageEncoder.features.denseblock3.denselayer47.norm2.weight\", \"imageEncoder.features.denseblock3.denselayer47.norm2.bias\", \"imageEncoder.features.denseblock3.denselayer47.norm2.running_mean\", \"imageEncoder.features.denseblock3.denselayer47.norm2.running_var\", \"imageEncoder.features.denseblock3.denselayer47.norm2.num_batches_tracked\", \"imageEncoder.features.denseblock3.denselayer47.conv2.weight\", \"imageEncoder.features.denseblock3.denselayer48.norm1.weight\", \"imageEncoder.features.denseblock3.denselayer48.norm1.bias\", \"imageEncoder.features.denseblock3.denselayer48.norm1.running_mean\", \"imageEncoder.features.denseblock3.denselayer48.norm1.running_var\", \"imageEncoder.features.denseblock3.denselayer48.norm1.num_batches_tracked\", \"imageEncoder.features.denseblock3.denselayer48.conv1.weight\", \"imageEncoder.features.denseblock3.denselayer48.norm2.weight\", \"imageEncoder.features.denseblock3.denselayer48.norm2.bias\", \"imageEncoder.features.denseblock3.denselayer48.norm2.running_mean\", \"imageEncoder.features.denseblock3.denselayer48.norm2.running_var\", \"imageEncoder.features.denseblock3.denselayer48.norm2.num_batches_tracked\", \"imageEncoder.features.denseblock3.denselayer48.conv2.weight\", \"imageEncoder.features.transition3.norm.weight\", \"imageEncoder.features.transition3.norm.bias\", \"imageEncoder.features.transition3.norm.running_mean\", \"imageEncoder.features.transition3.norm.running_var\", \"imageEncoder.features.transition3.norm.num_batches_tracked\", \"imageEncoder.features.transition3.conv.weight\", \"imageEncoder.features.denseblock4.denselayer1.norm1.weight\", \"imageEncoder.features.denseblock4.denselayer1.norm1.bias\", \"imageEncoder.features.denseblock4.denselayer1.norm1.running_mean\", \"imageEncoder.features.denseblock4.denselayer1.norm1.running_var\", \"imageEncoder.features.denseblock4.denselayer1.norm1.num_batches_tracked\", \"imageEncoder.features.denseblock4.denselayer1.conv1.weight\", \"imageEncoder.features.denseblock4.denselayer1.norm2.weight\", \"imageEncoder.features.denseblock4.denselayer1.norm2.bias\", \"imageEncoder.features.denseblock4.denselayer1.norm2.running_mean\", \"imageEncoder.features.denseblock4.denselayer1.norm2.running_var\", \"imageEncoder.features.denseblock4.denselayer1.norm2.num_batches_tracked\", \"imageEncoder.features.denseblock4.denselayer1.conv2.weight\", \"imageEncoder.features.denseblock4.denselayer2.norm1.weight\", \"imageEncoder.features.denseblock4.denselayer2.norm1.bias\", \"imageEncoder.features.denseblock4.denselayer2.norm1.running_mean\", \"imageEncoder.features.denseblock4.denselayer2.norm1.running_var\", \"imageEncoder.features.denseblock4.denselayer2.norm1.num_batches_tracked\", \"imageEncoder.features.denseblock4.denselayer2.conv1.weight\", \"imageEncoder.features.denseblock4.denselayer2.norm2.weight\", \"imageEncoder.features.denseblock4.denselayer2.norm2.bias\", \"imageEncoder.features.denseblock4.denselayer2.norm2.running_mean\", \"imageEncoder.features.denseblock4.denselayer2.norm2.running_var\", \"imageEncoder.features.denseblock4.denselayer2.norm2.num_batches_tracked\", \"imageEncoder.features.denseblock4.denselayer2.conv2.weight\", \"imageEncoder.features.denseblock4.denselayer3.norm1.weight\", \"imageEncoder.features.denseblock4.denselayer3.norm1.bias\", \"imageEncoder.features.denseblock4.denselayer3.norm1.running_mean\", \"imageEncoder.features.denseblock4.denselayer3.norm1.running_var\", \"imageEncoder.features.denseblock4.denselayer3.norm1.num_batches_tracked\", \"imageEncoder.features.denseblock4.denselayer3.conv1.weight\", \"imageEncoder.features.denseblock4.denselayer3.norm2.weight\", \"imageEncoder.features.denseblock4.denselayer3.norm2.bias\", \"imageEncoder.features.denseblock4.denselayer3.norm2.running_mean\", \"imageEncoder.features.denseblock4.denselayer3.norm2.running_var\", \"imageEncoder.features.denseblock4.denselayer3.norm2.num_batches_tracked\", \"imageEncoder.features.denseblock4.denselayer3.conv2.weight\", \"imageEncoder.features.denseblock4.denselayer4.norm1.weight\", \"imageEncoder.features.denseblock4.denselayer4.norm1.bias\", \"imageEncoder.features.denseblock4.denselayer4.norm1.running_mean\", \"imageEncoder.features.denseblock4.denselayer4.norm1.running_var\", \"imageEncoder.features.denseblock4.denselayer4.norm1.num_batches_tracked\", \"imageEncoder.features.denseblock4.denselayer4.conv1.weight\", \"imageEncoder.features.denseblock4.denselayer4.norm2.weight\", \"imageEncoder.features.denseblock4.denselayer4.norm2.bias\", \"imageEncoder.features.denseblock4.denselayer4.norm2.running_mean\", \"imageEncoder.features.denseblock4.denselayer4.norm2.running_var\", \"imageEncoder.features.denseblock4.denselayer4.norm2.num_batches_tracked\", \"imageEncoder.features.denseblock4.denselayer4.conv2.weight\", \"imageEncoder.features.denseblock4.denselayer5.norm1.weight\", \"imageEncoder.features.denseblock4.denselayer5.norm1.bias\", \"imageEncoder.features.denseblock4.denselayer5.norm1.running_mean\", \"imageEncoder.features.denseblock4.denselayer5.norm1.running_var\", \"imageEncoder.features.denseblock4.denselayer5.norm1.num_batches_tracked\", \"imageEncoder.features.denseblock4.denselayer5.conv1.weight\", \"imageEncoder.features.denseblock4.denselayer5.norm2.weight\", \"imageEncoder.features.denseblock4.denselayer5.norm2.bias\", \"imageEncoder.features.denseblock4.denselayer5.norm2.running_mean\", \"imageEncoder.features.denseblock4.denselayer5.norm2.running_var\", \"imageEncoder.features.denseblock4.denselayer5.norm2.num_batches_tracked\", \"imageEncoder.features.denseblock4.denselayer5.conv2.weight\", \"imageEncoder.features.denseblock4.denselayer6.norm1.weight\", \"imageEncoder.features.denseblock4.denselayer6.norm1.bias\", \"imageEncoder.features.denseblock4.denselayer6.norm1.running_mean\", \"imageEncoder.features.denseblock4.denselayer6.norm1.running_var\", \"imageEncoder.features.denseblock4.denselayer6.norm1.num_batches_tracked\", \"imageEncoder.features.denseblock4.denselayer6.conv1.weight\", \"imageEncoder.features.denseblock4.denselayer6.norm2.weight\", \"imageEncoder.features.denseblock4.denselayer6.norm2.bias\", \"imageEncoder.features.denseblock4.denselayer6.norm2.running_mean\", \"imageEncoder.features.denseblock4.denselayer6.norm2.running_var\", \"imageEncoder.features.denseblock4.denselayer6.norm2.num_batches_tracked\", \"imageEncoder.features.denseblock4.denselayer6.conv2.weight\", \"imageEncoder.features.denseblock4.denselayer7.norm1.weight\", \"imageEncoder.features.denseblock4.denselayer7.norm1.bias\", \"imageEncoder.features.denseblock4.denselayer7.norm1.running_mean\", \"imageEncoder.features.denseblock4.denselayer7.norm1.running_var\", \"imageEncoder.features.denseblock4.denselayer7.norm1.num_batches_tracked\", \"imageEncoder.features.denseblock4.denselayer7.conv1.weight\", \"imageEncoder.features.denseblock4.denselayer7.norm2.weight\", \"imageEncoder.features.denseblock4.denselayer7.norm2.bias\", \"imageEncoder.features.denseblock4.denselayer7.norm2.running_mean\", \"imageEncoder.features.denseblock4.denselayer7.norm2.running_var\", \"imageEncoder.features.denseblock4.denselayer7.norm2.num_batches_tracked\", \"imageEncoder.features.denseblock4.denselayer7.conv2.weight\", \"imageEncoder.features.denseblock4.denselayer8.norm1.weight\", \"imageEncoder.features.denseblock4.denselayer8.norm1.bias\", \"imageEncoder.features.denseblock4.denselayer8.norm1.running_mean\", \"imageEncoder.features.denseblock4.denselayer8.norm1.running_var\", \"imageEncoder.features.denseblock4.denselayer8.norm1.num_batches_tracked\", \"imageEncoder.features.denseblock4.denselayer8.conv1.weight\", \"imageEncoder.features.denseblock4.denselayer8.norm2.weight\", \"imageEncoder.features.denseblock4.denselayer8.norm2.bias\", \"imageEncoder.features.denseblock4.denselayer8.norm2.running_mean\", \"imageEncoder.features.denseblock4.denselayer8.norm2.running_var\", \"imageEncoder.features.denseblock4.denselayer8.norm2.num_batches_tracked\", \"imageEncoder.features.denseblock4.denselayer8.conv2.weight\", \"imageEncoder.features.denseblock4.denselayer9.norm1.weight\", \"imageEncoder.features.denseblock4.denselayer9.norm1.bias\", \"imageEncoder.features.denseblock4.denselayer9.norm1.running_mean\", \"imageEncoder.features.denseblock4.denselayer9.norm1.running_var\", \"imageEncoder.features.denseblock4.denselayer9.norm1.num_batches_tracked\", \"imageEncoder.features.denseblock4.denselayer9.conv1.weight\", \"imageEncoder.features.denseblock4.denselayer9.norm2.weight\", \"imageEncoder.features.denseblock4.denselayer9.norm2.bias\", \"imageEncoder.features.denseblock4.denselayer9.norm2.running_mean\", \"imageEncoder.features.denseblock4.denselayer9.norm2.running_var\", \"imageEncoder.features.denseblock4.denselayer9.norm2.num_batches_tracked\", \"imageEncoder.features.denseblock4.denselayer9.conv2.weight\", \"imageEncoder.features.denseblock4.denselayer10.norm1.weight\", \"imageEncoder.features.denseblock4.denselayer10.norm1.bias\", \"imageEncoder.features.denseblock4.denselayer10.norm1.running_mean\", \"imageEncoder.features.denseblock4.denselayer10.norm1.running_var\", \"imageEncoder.features.denseblock4.denselayer10.norm1.num_batches_tracked\", \"imageEncoder.features.denseblock4.denselayer10.conv1.weight\", \"imageEncoder.features.denseblock4.denselayer10.norm2.weight\", \"imageEncoder.features.denseblock4.denselayer10.norm2.bias\", \"imageEncoder.features.denseblock4.denselayer10.norm2.running_mean\", \"imageEncoder.features.denseblock4.denselayer10.norm2.running_var\", \"imageEncoder.features.denseblock4.denselayer10.norm2.num_batches_tracked\", \"imageEncoder.features.denseblock4.denselayer10.conv2.weight\", \"imageEncoder.features.denseblock4.denselayer11.norm1.weight\", \"imageEncoder.features.denseblock4.denselayer11.norm1.bias\", \"imageEncoder.features.denseblock4.denselayer11.norm1.running_mean\", \"imageEncoder.features.denseblock4.denselayer11.norm1.running_var\", \"imageEncoder.features.denseblock4.denselayer11.norm1.num_batches_tracked\", \"imageEncoder.features.denseblock4.denselayer11.conv1.weight\", \"imageEncoder.features.denseblock4.denselayer11.norm2.weight\", \"imageEncoder.features.denseblock4.denselayer11.norm2.bias\", \"imageEncoder.features.denseblock4.denselayer11.norm2.running_mean\", \"imageEncoder.features.denseblock4.denselayer11.norm2.running_var\", \"imageEncoder.features.denseblock4.denselayer11.norm2.num_batches_tracked\", \"imageEncoder.features.denseblock4.denselayer11.conv2.weight\", \"imageEncoder.features.denseblock4.denselayer12.norm1.weight\", \"imageEncoder.features.denseblock4.denselayer12.norm1.bias\", \"imageEncoder.features.denseblock4.denselayer12.norm1.running_mean\", \"imageEncoder.features.denseblock4.denselayer12.norm1.running_var\", \"imageEncoder.features.denseblock4.denselayer12.norm1.num_batches_tracked\", \"imageEncoder.features.denseblock4.denselayer12.conv1.weight\", \"imageEncoder.features.denseblock4.denselayer12.norm2.weight\", \"imageEncoder.features.denseblock4.denselayer12.norm2.bias\", \"imageEncoder.features.denseblock4.denselayer12.norm2.running_mean\", \"imageEncoder.features.denseblock4.denselayer12.norm2.running_var\", \"imageEncoder.features.denseblock4.denselayer12.norm2.num_batches_tracked\", \"imageEncoder.features.denseblock4.denselayer12.conv2.weight\", \"imageEncoder.features.denseblock4.denselayer13.norm1.weight\", \"imageEncoder.features.denseblock4.denselayer13.norm1.bias\", \"imageEncoder.features.denseblock4.denselayer13.norm1.running_mean\", \"imageEncoder.features.denseblock4.denselayer13.norm1.running_var\", \"imageEncoder.features.denseblock4.denselayer13.norm1.num_batches_tracked\", \"imageEncoder.features.denseblock4.denselayer13.conv1.weight\", \"imageEncoder.features.denseblock4.denselayer13.norm2.weight\", \"imageEncoder.features.denseblock4.denselayer13.norm2.bias\", \"imageEncoder.features.denseblock4.denselayer13.norm2.running_mean\", \"imageEncoder.features.denseblock4.denselayer13.norm2.running_var\", \"imageEncoder.features.denseblock4.denselayer13.norm2.num_batches_tracked\", \"imageEncoder.features.denseblock4.denselayer13.conv2.weight\", \"imageEncoder.features.denseblock4.denselayer14.norm1.weight\", \"imageEncoder.features.denseblock4.denselayer14.norm1.bias\", \"imageEncoder.features.denseblock4.denselayer14.norm1.running_mean\", \"imageEncoder.features.denseblock4.denselayer14.norm1.running_var\", \"imageEncoder.features.denseblock4.denselayer14.norm1.num_batches_tracked\", \"imageEncoder.features.denseblock4.denselayer14.conv1.weight\", \"imageEncoder.features.denseblock4.denselayer14.norm2.weight\", \"imageEncoder.features.denseblock4.denselayer14.norm2.bias\", \"imageEncoder.features.denseblock4.denselayer14.norm2.running_mean\", \"imageEncoder.features.denseblock4.denselayer14.norm2.running_var\", \"imageEncoder.features.denseblock4.denselayer14.norm2.num_batches_tracked\", \"imageEncoder.features.denseblock4.denselayer14.conv2.weight\", \"imageEncoder.features.denseblock4.denselayer15.norm1.weight\", \"imageEncoder.features.denseblock4.denselayer15.norm1.bias\", \"imageEncoder.features.denseblock4.denselayer15.norm1.running_mean\", \"imageEncoder.features.denseblock4.denselayer15.norm1.running_var\", \"imageEncoder.features.denseblock4.denselayer15.norm1.num_batches_tracked\", \"imageEncoder.features.denseblock4.denselayer15.conv1.weight\", \"imageEncoder.features.denseblock4.denselayer15.norm2.weight\", \"imageEncoder.features.denseblock4.denselayer15.norm2.bias\", \"imageEncoder.features.denseblock4.denselayer15.norm2.running_mean\", \"imageEncoder.features.denseblock4.denselayer15.norm2.running_var\", \"imageEncoder.features.denseblock4.denselayer15.norm2.num_batches_tracked\", \"imageEncoder.features.denseblock4.denselayer15.conv2.weight\", \"imageEncoder.features.denseblock4.denselayer16.norm1.weight\", \"imageEncoder.features.denseblock4.denselayer16.norm1.bias\", \"imageEncoder.features.denseblock4.denselayer16.norm1.running_mean\", \"imageEncoder.features.denseblock4.denselayer16.norm1.running_var\", \"imageEncoder.features.denseblock4.denselayer16.norm1.num_batches_tracked\", \"imageEncoder.features.denseblock4.denselayer16.conv1.weight\", \"imageEncoder.features.denseblock4.denselayer16.norm2.weight\", \"imageEncoder.features.denseblock4.denselayer16.norm2.bias\", \"imageEncoder.features.denseblock4.denselayer16.norm2.running_mean\", \"imageEncoder.features.denseblock4.denselayer16.norm2.running_var\", \"imageEncoder.features.denseblock4.denselayer16.norm2.num_batches_tracked\", \"imageEncoder.features.denseblock4.denselayer16.conv2.weight\", \"imageEncoder.features.denseblock4.denselayer17.norm1.weight\", \"imageEncoder.features.denseblock4.denselayer17.norm1.bias\", \"imageEncoder.features.denseblock4.denselayer17.norm1.running_mean\", \"imageEncoder.features.denseblock4.denselayer17.norm1.running_var\", \"imageEncoder.features.denseblock4.denselayer17.norm1.num_batches_tracked\", \"imageEncoder.features.denseblock4.denselayer17.conv1.weight\", \"imageEncoder.features.denseblock4.denselayer17.norm2.weight\", \"imageEncoder.features.denseblock4.denselayer17.norm2.bias\", \"imageEncoder.features.denseblock4.denselayer17.norm2.running_mean\", \"imageEncoder.features.denseblock4.denselayer17.norm2.running_var\", \"imageEncoder.features.denseblock4.denselayer17.norm2.num_batches_tracked\", \"imageEncoder.features.denseblock4.denselayer17.conv2.weight\", \"imageEncoder.features.denseblock4.denselayer18.norm1.weight\", \"imageEncoder.features.denseblock4.denselayer18.norm1.bias\", \"imageEncoder.features.denseblock4.denselayer18.norm1.running_mean\", \"imageEncoder.features.denseblock4.denselayer18.norm1.running_var\", \"imageEncoder.features.denseblock4.denselayer18.norm1.num_batches_tracked\", \"imageEncoder.features.denseblock4.denselayer18.conv1.weight\", \"imageEncoder.features.denseblock4.denselayer18.norm2.weight\", \"imageEncoder.features.denseblock4.denselayer18.norm2.bias\", \"imageEncoder.features.denseblock4.denselayer18.norm2.running_mean\", \"imageEncoder.features.denseblock4.denselayer18.norm2.running_var\", \"imageEncoder.features.denseblock4.denselayer18.norm2.num_batches_tracked\", \"imageEncoder.features.denseblock4.denselayer18.conv2.weight\", \"imageEncoder.features.denseblock4.denselayer19.norm1.weight\", \"imageEncoder.features.denseblock4.denselayer19.norm1.bias\", \"imageEncoder.features.denseblock4.denselayer19.norm1.running_mean\", \"imageEncoder.features.denseblock4.denselayer19.norm1.running_var\", \"imageEncoder.features.denseblock4.denselayer19.norm1.num_batches_tracked\", \"imageEncoder.features.denseblock4.denselayer19.conv1.weight\", \"imageEncoder.features.denseblock4.denselayer19.norm2.weight\", \"imageEncoder.features.denseblock4.denselayer19.norm2.bias\", \"imageEncoder.features.denseblock4.denselayer19.norm2.running_mean\", \"imageEncoder.features.denseblock4.denselayer19.norm2.running_var\", \"imageEncoder.features.denseblock4.denselayer19.norm2.num_batches_tracked\", \"imageEncoder.features.denseblock4.denselayer19.conv2.weight\", \"imageEncoder.features.denseblock4.denselayer20.norm1.weight\", \"imageEncoder.features.denseblock4.denselayer20.norm1.bias\", \"imageEncoder.features.denseblock4.denselayer20.norm1.running_mean\", \"imageEncoder.features.denseblock4.denselayer20.norm1.running_var\", \"imageEncoder.features.denseblock4.denselayer20.norm1.num_batches_tracked\", \"imageEncoder.features.denseblock4.denselayer20.conv1.weight\", \"imageEncoder.features.denseblock4.denselayer20.norm2.weight\", \"imageEncoder.features.denseblock4.denselayer20.norm2.bias\", \"imageEncoder.features.denseblock4.denselayer20.norm2.running_mean\", \"imageEncoder.features.denseblock4.denselayer20.norm2.running_var\", \"imageEncoder.features.denseblock4.denselayer20.norm2.num_batches_tracked\", \"imageEncoder.features.denseblock4.denselayer20.conv2.weight\", \"imageEncoder.features.denseblock4.denselayer21.norm1.weight\", \"imageEncoder.features.denseblock4.denselayer21.norm1.bias\", \"imageEncoder.features.denseblock4.denselayer21.norm1.running_mean\", \"imageEncoder.features.denseblock4.denselayer21.norm1.running_var\", \"imageEncoder.features.denseblock4.denselayer21.norm1.num_batches_tracked\", \"imageEncoder.features.denseblock4.denselayer21.conv1.weight\", \"imageEncoder.features.denseblock4.denselayer21.norm2.weight\", \"imageEncoder.features.denseblock4.denselayer21.norm2.bias\", \"imageEncoder.features.denseblock4.denselayer21.norm2.running_mean\", \"imageEncoder.features.denseblock4.denselayer21.norm2.running_var\", \"imageEncoder.features.denseblock4.denselayer21.norm2.num_batches_tracked\", \"imageEncoder.features.denseblock4.denselayer21.conv2.weight\", \"imageEncoder.features.denseblock4.denselayer22.norm1.weight\", \"imageEncoder.features.denseblock4.denselayer22.norm1.bias\", \"imageEncoder.features.denseblock4.denselayer22.norm1.running_mean\", \"imageEncoder.features.denseblock4.denselayer22.norm1.running_var\", \"imageEncoder.features.denseblock4.denselayer22.norm1.num_batches_tracked\", \"imageEncoder.features.denseblock4.denselayer22.conv1.weight\", \"imageEncoder.features.denseblock4.denselayer22.norm2.weight\", \"imageEncoder.features.denseblock4.denselayer22.norm2.bias\", \"imageEncoder.features.denseblock4.denselayer22.norm2.running_mean\", \"imageEncoder.features.denseblock4.denselayer22.norm2.running_var\", \"imageEncoder.features.denseblock4.denselayer22.norm2.num_batches_tracked\", \"imageEncoder.features.denseblock4.denselayer22.conv2.weight\", \"imageEncoder.features.denseblock4.denselayer23.norm1.weight\", \"imageEncoder.features.denseblock4.denselayer23.norm1.bias\", \"imageEncoder.features.denseblock4.denselayer23.norm1.running_mean\", \"imageEncoder.features.denseblock4.denselayer23.norm1.running_var\", \"imageEncoder.features.denseblock4.denselayer23.norm1.num_batches_tracked\", \"imageEncoder.features.denseblock4.denselayer23.conv1.weight\", \"imageEncoder.features.denseblock4.denselayer23.norm2.weight\", \"imageEncoder.features.denseblock4.denselayer23.norm2.bias\", \"imageEncoder.features.denseblock4.denselayer23.norm2.running_mean\", \"imageEncoder.features.denseblock4.denselayer23.norm2.running_var\", \"imageEncoder.features.denseblock4.denselayer23.norm2.num_batches_tracked\", \"imageEncoder.features.denseblock4.denselayer23.conv2.weight\", \"imageEncoder.features.denseblock4.denselayer24.norm1.weight\", \"imageEncoder.features.denseblock4.denselayer24.norm1.bias\", \"imageEncoder.features.denseblock4.denselayer24.norm1.running_mean\", \"imageEncoder.features.denseblock4.denselayer24.norm1.running_var\", \"imageEncoder.features.denseblock4.denselayer24.norm1.num_batches_tracked\", \"imageEncoder.features.denseblock4.denselayer24.conv1.weight\", \"imageEncoder.features.denseblock4.denselayer24.norm2.weight\", \"imageEncoder.features.denseblock4.denselayer24.norm2.bias\", \"imageEncoder.features.denseblock4.denselayer24.norm2.running_mean\", \"imageEncoder.features.denseblock4.denselayer24.norm2.running_var\", \"imageEncoder.features.denseblock4.denselayer24.norm2.num_batches_tracked\", \"imageEncoder.features.denseblock4.denselayer24.conv2.weight\", \"imageEncoder.features.denseblock4.denselayer25.norm1.weight\", \"imageEncoder.features.denseblock4.denselayer25.norm1.bias\", \"imageEncoder.features.denseblock4.denselayer25.norm1.running_mean\", \"imageEncoder.features.denseblock4.denselayer25.norm1.running_var\", \"imageEncoder.features.denseblock4.denselayer25.norm1.num_batches_tracked\", \"imageEncoder.features.denseblock4.denselayer25.conv1.weight\", \"imageEncoder.features.denseblock4.denselayer25.norm2.weight\", \"imageEncoder.features.denseblock4.denselayer25.norm2.bias\", \"imageEncoder.features.denseblock4.denselayer25.norm2.running_mean\", \"imageEncoder.features.denseblock4.denselayer25.norm2.running_var\", \"imageEncoder.features.denseblock4.denselayer25.norm2.num_batches_tracked\", \"imageEncoder.features.denseblock4.denselayer25.conv2.weight\", \"imageEncoder.features.denseblock4.denselayer26.norm1.weight\", \"imageEncoder.features.denseblock4.denselayer26.norm1.bias\", \"imageEncoder.features.denseblock4.denselayer26.norm1.running_mean\", \"imageEncoder.features.denseblock4.denselayer26.norm1.running_var\", \"imageEncoder.features.denseblock4.denselayer26.norm1.num_batches_tracked\", \"imageEncoder.features.denseblock4.denselayer26.conv1.weight\", \"imageEncoder.features.denseblock4.denselayer26.norm2.weight\", \"imageEncoder.features.denseblock4.denselayer26.norm2.bias\", \"imageEncoder.features.denseblock4.denselayer26.norm2.running_mean\", \"imageEncoder.features.denseblock4.denselayer26.norm2.running_var\", \"imageEncoder.features.denseblock4.denselayer26.norm2.num_batches_tracked\", \"imageEncoder.features.denseblock4.denselayer26.conv2.weight\", \"imageEncoder.features.denseblock4.denselayer27.norm1.weight\", \"imageEncoder.features.denseblock4.denselayer27.norm1.bias\", \"imageEncoder.features.denseblock4.denselayer27.norm1.running_mean\", \"imageEncoder.features.denseblock4.denselayer27.norm1.running_var\", \"imageEncoder.features.denseblock4.denselayer27.norm1.num_batches_tracked\", \"imageEncoder.features.denseblock4.denselayer27.conv1.weight\", \"imageEncoder.features.denseblock4.denselayer27.norm2.weight\", \"imageEncoder.features.denseblock4.denselayer27.norm2.bias\", \"imageEncoder.features.denseblock4.denselayer27.norm2.running_mean\", \"imageEncoder.features.denseblock4.denselayer27.norm2.running_var\", \"imageEncoder.features.denseblock4.denselayer27.norm2.num_batches_tracked\", \"imageEncoder.features.denseblock4.denselayer27.conv2.weight\", \"imageEncoder.features.denseblock4.denselayer28.norm1.weight\", \"imageEncoder.features.denseblock4.denselayer28.norm1.bias\", \"imageEncoder.features.denseblock4.denselayer28.norm1.running_mean\", \"imageEncoder.features.denseblock4.denselayer28.norm1.running_var\", \"imageEncoder.features.denseblock4.denselayer28.norm1.num_batches_tracked\", \"imageEncoder.features.denseblock4.denselayer28.conv1.weight\", \"imageEncoder.features.denseblock4.denselayer28.norm2.weight\", \"imageEncoder.features.denseblock4.denselayer28.norm2.bias\", \"imageEncoder.features.denseblock4.denselayer28.norm2.running_mean\", \"imageEncoder.features.denseblock4.denselayer28.norm2.running_var\", \"imageEncoder.features.denseblock4.denselayer28.norm2.num_batches_tracked\", \"imageEncoder.features.denseblock4.denselayer28.conv2.weight\", \"imageEncoder.features.denseblock4.denselayer29.norm1.weight\", \"imageEncoder.features.denseblock4.denselayer29.norm1.bias\", \"imageEncoder.features.denseblock4.denselayer29.norm1.running_mean\", \"imageEncoder.features.denseblock4.denselayer29.norm1.running_var\", \"imageEncoder.features.denseblock4.denselayer29.norm1.num_batches_tracked\", \"imageEncoder.features.denseblock4.denselayer29.conv1.weight\", \"imageEncoder.features.denseblock4.denselayer29.norm2.weight\", \"imageEncoder.features.denseblock4.denselayer29.norm2.bias\", \"imageEncoder.features.denseblock4.denselayer29.norm2.running_mean\", \"imageEncoder.features.denseblock4.denselayer29.norm2.running_var\", \"imageEncoder.features.denseblock4.denselayer29.norm2.num_batches_tracked\", \"imageEncoder.features.denseblock4.denselayer29.conv2.weight\", \"imageEncoder.features.denseblock4.denselayer30.norm1.weight\", \"imageEncoder.features.denseblock4.denselayer30.norm1.bias\", \"imageEncoder.features.denseblock4.denselayer30.norm1.running_mean\", \"imageEncoder.features.denseblock4.denselayer30.norm1.running_var\", \"imageEncoder.features.denseblock4.denselayer30.norm1.num_batches_tracked\", \"imageEncoder.features.denseblock4.denselayer30.conv1.weight\", \"imageEncoder.features.denseblock4.denselayer30.norm2.weight\", \"imageEncoder.features.denseblock4.denselayer30.norm2.bias\", \"imageEncoder.features.denseblock4.denselayer30.norm2.running_mean\", \"imageEncoder.features.denseblock4.denselayer30.norm2.running_var\", \"imageEncoder.features.denseblock4.denselayer30.norm2.num_batches_tracked\", \"imageEncoder.features.denseblock4.denselayer30.conv2.weight\", \"imageEncoder.features.denseblock4.denselayer31.norm1.weight\", \"imageEncoder.features.denseblock4.denselayer31.norm1.bias\", \"imageEncoder.features.denseblock4.denselayer31.norm1.running_mean\", \"imageEncoder.features.denseblock4.denselayer31.norm1.running_var\", \"imageEncoder.features.denseblock4.denselayer31.norm1.num_batches_tracked\", \"imageEncoder.features.denseblock4.denselayer31.conv1.weight\", \"imageEncoder.features.denseblock4.denselayer31.norm2.weight\", \"imageEncoder.features.denseblock4.denselayer31.norm2.bias\", \"imageEncoder.features.denseblock4.denselayer31.norm2.running_mean\", \"imageEncoder.features.denseblock4.denselayer31.norm2.running_var\", \"imageEncoder.features.denseblock4.denselayer31.norm2.num_batches_tracked\", \"imageEncoder.features.denseblock4.denselayer31.conv2.weight\", \"imageEncoder.features.denseblock4.denselayer32.norm1.weight\", \"imageEncoder.features.denseblock4.denselayer32.norm1.bias\", \"imageEncoder.features.denseblock4.denselayer32.norm1.running_mean\", \"imageEncoder.features.denseblock4.denselayer32.norm1.running_var\", \"imageEncoder.features.denseblock4.denselayer32.norm1.num_batches_tracked\", \"imageEncoder.features.denseblock4.denselayer32.conv1.weight\", \"imageEncoder.features.denseblock4.denselayer32.norm2.weight\", \"imageEncoder.features.denseblock4.denselayer32.norm2.bias\", \"imageEncoder.features.denseblock4.denselayer32.norm2.running_mean\", \"imageEncoder.features.denseblock4.denselayer32.norm2.running_var\", \"imageEncoder.features.denseblock4.denselayer32.norm2.num_batches_tracked\", \"imageEncoder.features.denseblock4.denselayer32.conv2.weight\", \"imageEncoder.features.norm5.weight\", \"imageEncoder.features.norm5.bias\", \"imageEncoder.features.norm5.running_mean\", \"imageEncoder.features.norm5.running_var\", \"imageEncoder.features.norm5.num_batches_tracked\", \"imageEncoder.classifier.weight\", \"imageEncoder.classifier.bias\", \"textEncoder.embeddings.word_embeddings.weight\", \"textEncoder.embeddings.position_embeddings.weight\", \"textEncoder.embeddings.token_type_embeddings.weight\", \"textEncoder.embeddings.LayerNorm.weight\", \"textEncoder.embeddings.LayerNorm.bias\", \"textEncoder.encoder.layer.0.attention.self.query.weight\", \"textEncoder.encoder.layer.0.attention.self.query.bias\", \"textEncoder.encoder.layer.0.attention.self.key.weight\", \"textEncoder.encoder.layer.0.attention.self.key.bias\", \"textEncoder.encoder.layer.0.attention.self.value.weight\", \"textEncoder.encoder.layer.0.attention.self.value.bias\", \"textEncoder.encoder.layer.0.attention.output.dense.weight\", \"textEncoder.encoder.layer.0.attention.output.dense.bias\", \"textEncoder.encoder.layer.0.attention.output.LayerNorm.weight\", \"textEncoder.encoder.layer.0.attention.output.LayerNorm.bias\", \"textEncoder.encoder.layer.0.intermediate.dense.weight\", \"textEncoder.encoder.layer.0.intermediate.dense.bias\", \"textEncoder.encoder.layer.0.output.dense.weight\", \"textEncoder.encoder.layer.0.output.dense.bias\", \"textEncoder.encoder.layer.0.output.LayerNorm.weight\", \"textEncoder.encoder.layer.0.output.LayerNorm.bias\", \"textEncoder.encoder.layer.1.attention.self.query.weight\", \"textEncoder.encoder.layer.1.attention.self.query.bias\", \"textEncoder.encoder.layer.1.attention.self.key.weight\", \"textEncoder.encoder.layer.1.attention.self.key.bias\", \"textEncoder.encoder.layer.1.attention.self.value.weight\", \"textEncoder.encoder.layer.1.attention.self.value.bias\", \"textEncoder.encoder.layer.1.attention.output.dense.weight\", \"textEncoder.encoder.layer.1.attention.output.dense.bias\", \"textEncoder.encoder.layer.1.attention.output.LayerNorm.weight\", \"textEncoder.encoder.layer.1.attention.output.LayerNorm.bias\", \"textEncoder.encoder.layer.1.intermediate.dense.weight\", \"textEncoder.encoder.layer.1.intermediate.dense.bias\", \"textEncoder.encoder.layer.1.output.dense.weight\", \"textEncoder.encoder.layer.1.output.dense.bias\", \"textEncoder.encoder.layer.1.output.LayerNorm.weight\", \"textEncoder.encoder.layer.1.output.LayerNorm.bias\", \"textEncoder.encoder.layer.2.attention.self.query.weight\", \"textEncoder.encoder.layer.2.attention.self.query.bias\", \"textEncoder.encoder.layer.2.attention.self.key.weight\", \"textEncoder.encoder.layer.2.attention.self.key.bias\", \"textEncoder.encoder.layer.2.attention.self.value.weight\", \"textEncoder.encoder.layer.2.attention.self.value.bias\", \"textEncoder.encoder.layer.2.attention.output.dense.weight\", \"textEncoder.encoder.layer.2.attention.output.dense.bias\", \"textEncoder.encoder.layer.2.attention.output.LayerNorm.weight\", \"textEncoder.encoder.layer.2.attention.output.LayerNorm.bias\", \"textEncoder.encoder.layer.2.intermediate.dense.weight\", \"textEncoder.encoder.layer.2.intermediate.dense.bias\", \"textEncoder.encoder.layer.2.output.dense.weight\", \"textEncoder.encoder.layer.2.output.dense.bias\", \"textEncoder.encoder.layer.2.output.LayerNorm.weight\", \"textEncoder.encoder.layer.2.output.LayerNorm.bias\", \"textEncoder.encoder.layer.3.attention.self.query.weight\", \"textEncoder.encoder.layer.3.attention.self.query.bias\", \"textEncoder.encoder.layer.3.attention.self.key.weight\", \"textEncoder.encoder.layer.3.attention.self.key.bias\", \"textEncoder.encoder.layer.3.attention.self.value.weight\", \"textEncoder.encoder.layer.3.attention.self.value.bias\", \"textEncoder.encoder.layer.3.attention.output.dense.weight\", \"textEncoder.encoder.layer.3.attention.output.dense.bias\", \"textEncoder.encoder.layer.3.attention.output.LayerNorm.weight\", \"textEncoder.encoder.layer.3.attention.output.LayerNorm.bias\", \"textEncoder.encoder.layer.3.intermediate.dense.weight\", \"textEncoder.encoder.layer.3.intermediate.dense.bias\", \"textEncoder.encoder.layer.3.output.dense.weight\", \"textEncoder.encoder.layer.3.output.dense.bias\", \"textEncoder.encoder.layer.3.output.LayerNorm.weight\", \"textEncoder.encoder.layer.3.output.LayerNorm.bias\", \"textEncoder.encoder.layer.4.attention.self.query.weight\", \"textEncoder.encoder.layer.4.attention.self.query.bias\", \"textEncoder.encoder.layer.4.attention.self.key.weight\", \"textEncoder.encoder.layer.4.attention.self.key.bias\", \"textEncoder.encoder.layer.4.attention.self.value.weight\", \"textEncoder.encoder.layer.4.attention.self.value.bias\", \"textEncoder.encoder.layer.4.attention.output.dense.weight\", \"textEncoder.encoder.layer.4.attention.output.dense.bias\", \"textEncoder.encoder.layer.4.attention.output.LayerNorm.weight\", \"textEncoder.encoder.layer.4.attention.output.LayerNorm.bias\", \"textEncoder.encoder.layer.4.intermediate.dense.weight\", \"textEncoder.encoder.layer.4.intermediate.dense.bias\", \"textEncoder.encoder.layer.4.output.dense.weight\", \"textEncoder.encoder.layer.4.output.dense.bias\", \"textEncoder.encoder.layer.4.output.LayerNorm.weight\", \"textEncoder.encoder.layer.4.output.LayerNorm.bias\", \"textEncoder.encoder.layer.5.attention.self.query.weight\", \"textEncoder.encoder.layer.5.attention.self.query.bias\", \"textEncoder.encoder.layer.5.attention.self.key.weight\", \"textEncoder.encoder.layer.5.attention.self.key.bias\", \"textEncoder.encoder.layer.5.attention.self.value.weight\", \"textEncoder.encoder.layer.5.attention.self.value.bias\", \"textEncoder.encoder.layer.5.attention.output.dense.weight\", \"textEncoder.encoder.layer.5.attention.output.dense.bias\", \"textEncoder.encoder.layer.5.attention.output.LayerNorm.weight\", \"textEncoder.encoder.layer.5.attention.output.LayerNorm.bias\", \"textEncoder.encoder.layer.5.intermediate.dense.weight\", \"textEncoder.encoder.layer.5.intermediate.dense.bias\", \"textEncoder.encoder.layer.5.output.dense.weight\", \"textEncoder.encoder.layer.5.output.dense.bias\", \"textEncoder.encoder.layer.5.output.LayerNorm.weight\", \"textEncoder.encoder.layer.5.output.LayerNorm.bias\", \"textEncoder.encoder.layer.6.attention.self.query.weight\", \"textEncoder.encoder.layer.6.attention.self.query.bias\", \"textEncoder.encoder.layer.6.attention.self.key.weight\", \"textEncoder.encoder.layer.6.attention.self.key.bias\", \"textEncoder.encoder.layer.6.attention.self.value.weight\", \"textEncoder.encoder.layer.6.attention.self.value.bias\", \"textEncoder.encoder.layer.6.attention.output.dense.weight\", \"textEncoder.encoder.layer.6.attention.output.dense.bias\", \"textEncoder.encoder.layer.6.attention.output.LayerNorm.weight\", \"textEncoder.encoder.layer.6.attention.output.LayerNorm.bias\", \"textEncoder.encoder.layer.6.intermediate.dense.weight\", \"textEncoder.encoder.layer.6.intermediate.dense.bias\", \"textEncoder.encoder.layer.6.output.dense.weight\", \"textEncoder.encoder.layer.6.output.dense.bias\", \"textEncoder.encoder.layer.6.output.LayerNorm.weight\", \"textEncoder.encoder.layer.6.output.LayerNorm.bias\", \"textEncoder.encoder.layer.7.attention.self.query.weight\", \"textEncoder.encoder.layer.7.attention.self.query.bias\", \"textEncoder.encoder.layer.7.attention.self.key.weight\", \"textEncoder.encoder.layer.7.attention.self.key.bias\", \"textEncoder.encoder.layer.7.attention.self.value.weight\", \"textEncoder.encoder.layer.7.attention.self.value.bias\", \"textEncoder.encoder.layer.7.attention.output.dense.weight\", \"textEncoder.encoder.layer.7.attention.output.dense.bias\", \"textEncoder.encoder.layer.7.attention.output.LayerNorm.weight\", \"textEncoder.encoder.layer.7.attention.output.LayerNorm.bias\", \"textEncoder.encoder.layer.7.intermediate.dense.weight\", \"textEncoder.encoder.layer.7.intermediate.dense.bias\", \"textEncoder.encoder.layer.7.output.dense.weight\", \"textEncoder.encoder.layer.7.output.dense.bias\", \"textEncoder.encoder.layer.7.output.LayerNorm.weight\", \"textEncoder.encoder.layer.7.output.LayerNorm.bias\", \"textEncoder.encoder.layer.8.attention.self.query.weight\", \"textEncoder.encoder.layer.8.attention.self.query.bias\", \"textEncoder.encoder.layer.8.attention.self.key.weight\", \"textEncoder.encoder.layer.8.attention.self.key.bias\", \"textEncoder.encoder.layer.8.attention.self.value.weight\", \"textEncoder.encoder.layer.8.attention.self.value.bias\", \"textEncoder.encoder.layer.8.attention.output.dense.weight\", \"textEncoder.encoder.layer.8.attention.output.dense.bias\", \"textEncoder.encoder.layer.8.attention.output.LayerNorm.weight\", \"textEncoder.encoder.layer.8.attention.output.LayerNorm.bias\", \"textEncoder.encoder.layer.8.intermediate.dense.weight\", \"textEncoder.encoder.layer.8.intermediate.dense.bias\", \"textEncoder.encoder.layer.8.output.dense.weight\", \"textEncoder.encoder.layer.8.output.dense.bias\", \"textEncoder.encoder.layer.8.output.LayerNorm.weight\", \"textEncoder.encoder.layer.8.output.LayerNorm.bias\", \"textEncoder.encoder.layer.9.attention.self.query.weight\", \"textEncoder.encoder.layer.9.attention.self.query.bias\", \"textEncoder.encoder.layer.9.attention.self.key.weight\", \"textEncoder.encoder.layer.9.attention.self.key.bias\", \"textEncoder.encoder.layer.9.attention.self.value.weight\", \"textEncoder.encoder.layer.9.attention.self.value.bias\", \"textEncoder.encoder.layer.9.attention.output.dense.weight\", \"textEncoder.encoder.layer.9.attention.output.dense.bias\", \"textEncoder.encoder.layer.9.attention.output.LayerNorm.weight\", \"textEncoder.encoder.layer.9.attention.output.LayerNorm.bias\", \"textEncoder.encoder.layer.9.intermediate.dense.weight\", \"textEncoder.encoder.layer.9.intermediate.dense.bias\", \"textEncoder.encoder.layer.9.output.dense.weight\", \"textEncoder.encoder.layer.9.output.dense.bias\", \"textEncoder.encoder.layer.9.output.LayerNorm.weight\", \"textEncoder.encoder.layer.9.output.LayerNorm.bias\", \"textEncoder.encoder.layer.10.attention.self.query.weight\", \"textEncoder.encoder.layer.10.attention.self.query.bias\", \"textEncoder.encoder.layer.10.attention.self.key.weight\", \"textEncoder.encoder.layer.10.attention.self.key.bias\", \"textEncoder.encoder.layer.10.attention.self.value.weight\", \"textEncoder.encoder.layer.10.attention.self.value.bias\", \"textEncoder.encoder.layer.10.attention.output.dense.weight\", \"textEncoder.encoder.layer.10.attention.output.dense.bias\", \"textEncoder.encoder.layer.10.attention.output.LayerNorm.weight\", \"textEncoder.encoder.layer.10.attention.output.LayerNorm.bias\", \"textEncoder.encoder.layer.10.intermediate.dense.weight\", \"textEncoder.encoder.layer.10.intermediate.dense.bias\", \"textEncoder.encoder.layer.10.output.dense.weight\", \"textEncoder.encoder.layer.10.output.dense.bias\", \"textEncoder.encoder.layer.10.output.LayerNorm.weight\", \"textEncoder.encoder.layer.10.output.LayerNorm.bias\", \"textEncoder.encoder.layer.11.attention.self.query.weight\", \"textEncoder.encoder.layer.11.attention.self.query.bias\", \"textEncoder.encoder.layer.11.attention.self.key.weight\", \"textEncoder.encoder.layer.11.attention.self.key.bias\", \"textEncoder.encoder.layer.11.attention.self.value.weight\", \"textEncoder.encoder.layer.11.attention.self.value.bias\", \"textEncoder.encoder.layer.11.attention.output.dense.weight\", \"textEncoder.encoder.layer.11.attention.output.dense.bias\", \"textEncoder.encoder.layer.11.attention.output.LayerNorm.weight\", \"textEncoder.encoder.layer.11.attention.output.LayerNorm.bias\", \"textEncoder.encoder.layer.11.intermediate.dense.weight\", \"textEncoder.encoder.layer.11.intermediate.dense.bias\", \"textEncoder.encoder.layer.11.output.dense.weight\", \"textEncoder.encoder.layer.11.output.dense.bias\", \"textEncoder.encoder.layer.11.output.LayerNorm.weight\", \"textEncoder.encoder.layer.11.output.LayerNorm.bias\", \"proj_visual.weight\", \"proj_visual.bias\", \"proj_text.weight\", \"proj_text.bias\", \"bn_visual.weight\", \"bn_visual.bias\", \"bn_visual.running_mean\", \"bn_visual.running_var\", \"bn_visual.num_batches_tracked\", \"bn_text.weight\", \"bn_text.bias\", \"bn_text.running_mean\", \"bn_text.running_var\", \"bn_text.num_batches_tracked\", \"attn_visual.weight\", \"attn_visual.bias\", \"attn_text.weight\", \"attn_text.bias\", \"fc_attn.weight\", \"fc_attn.bias\", \"bn_attn.weight\", \"bn_attn.bias\", \"bn_attn.running_mean\", \"bn_attn.running_var\", \"bn_attn.num_batches_tracked\", \"classifier_task1.weight\", \"classifier_task1.bias\", \"classifier_task2.weight\", \"classifier_task2.bias\", \"classifier_task3.weight\", \"classifier_task3.bias\". ",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-8f54f5e45cc6>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     10\u001b[0m \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_model_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Create a new test predict function that uses the best model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-6f4e02861c32>\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(path, model, metric, optimizer, scheduler)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2580\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2581\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m   2582\u001b[0m                 \"Error(s) in loading state_dict for {}:\\n\\t{}\".format(\n\u001b[1;32m   2583\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\n\\t\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for DataParallel:\n\tMissing key(s) in state_dict: \"module.imageEncoder.features.conv0.weight\", \"module.imageEncoder.features.norm0.weight\", \"module.imageEncoder.features.norm0.bias\", \"module.imageEncoder.features.norm0.running_mean\", \"module.imageEncoder.features.norm0.running_var\", \"module.imageEncoder.features.denseblock1.denselayer1.norm1.weight\", \"module.imageEncoder.features.denseblock1.denselayer1.norm1.bias\", \"module.imageEncoder.features.denseblock1.denselayer1.norm1.running_mean\", \"module.imageEncoder.features.denseblock1.denselayer1.norm1.running_var\", \"module.imageEncoder.features.denseblock1.denselayer1.conv1.weight\", \"module.imageEncoder.features.denseblock1.denselayer1.norm2.weight\", \"module.imageEncoder.features.denseblock1.denselayer1.norm2.bias\", \"module.imageEncoder.features.denseblock1.denselayer1.norm2.running_mean\", \"module.imageEncoder.features.denseblock1.denselayer1.norm2.running_var\", \"module.imageEncoder.features.denseblock1.denselayer1.conv2.weight\", \"module.imageEncoder.features.denseblock1.denselayer2.norm1.weight\", \"module.imageEncoder.features.denseblock1.denselayer2.norm1.bias\", \"module.imageEncoder.features.denseblock1.denselayer2.norm1.running_mean\", \"module.imageEncoder.features.denseblock1.denselayer2.norm1.running_var\", \"module.imageEncoder.features.denseblock1.denselayer2.conv1.weight\", \"module.imageEncoder.features.denseblock1.denselayer2.norm2.weight\", \"module.imageEncoder.features.denseblock1.denselayer2.norm2.bias\", \"module.imageEncoder.features.dens...\n\tUnexpected key(s) in state_dict: \"imageEncoder.features.conv0.weight\", \"imageEncoder.features.norm0.weight\", \"imageEncoder.features.norm0.bias\", \"imageEncoder.features.norm0.running_mean\", \"imageEncoder.features.norm0.running_var\", \"imageEncoder.features.norm0.num_batches_tracked\", \"imageEncoder.features.denseblock1.denselayer1.norm1.weight\", \"imageEncoder.features.denseblock1.denselayer1.norm1.bias\", \"imageEncoder.features.denseblock1.denselayer1.norm1.running_mean\", \"imageEncoder.features.denseblock1.denselayer1.norm1.running_var\", \"imageEncoder.features.denseblock1.denselayer1.norm1.num_batches_tracked\", \"imageEncoder.features.denseblock1.denselayer1.conv1.weight\", \"imageEncoder.features.denseblock1.denselayer1.norm2.weight\", \"imageEncoder.features.denseblock1.denselayer1.norm2.bias\", \"imageEncoder.features.denseblock1.denselayer1.norm2.running_mean\", \"imageEncoder.features.denseblock1.denselayer1.norm2.running_var\", \"imageEncoder.features.denseblock1.denselayer1.norm2.num_batches_tracked\", \"imageEncoder.features.denseblock1.denselayer1.conv2.weight\", \"imageEncoder.features.denseblock1.denselayer2.norm1.weight\", \"imageEncoder.features.denseblock1.denselayer2.norm1.bias\", \"imageEncoder.features.denseblock1.denselayer2.norm1.running_mean\", \"imageEncoder.features.denseblock1.denselayer2.norm1.running_var\", \"imageEncoder.features.denseblock1.denselayer2.norm1.num_batches_tracked\", \"imageEncoder.features.denseblock1.denselayer2.conv1.weight\", \"imageEncoder.features.denseblo..."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def compute_metrics(y_true, y_pred, task_name=None, verbose=True):\n",
        "#     acc = accuracy_score(y_true, y_pred)\n",
        "#     macro_f1 = f1_score(y_true, y_pred, average='macro')\n",
        "#     weighted_f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "#     report = classification_report(y_true, y_pred)\n",
        "\n",
        "#     if verbose:\n",
        "#         print(f\"\\nEvaluation Report for {task_name or 'Unnamed Task'}\")\n",
        "#         print(\"---------------------------------------\")\n",
        "#         print(f\"Accuracy     : {acc:.4f}\")\n",
        "#         print(f\"Macro F1     : {macro_f1:.4f}\")\n",
        "#         print(f\"Weighted F1  : {weighted_f1:.4f}\")\n",
        "#         print(report)\n",
        "\n",
        "#     return {\n",
        "#         \"accuracy\": acc,\n",
        "#         \"macro_f1\": macro_f1,\n",
        "#         \"weighted_f1\": weighted_f1,\n",
        "#         \"report\": report\n",
        "#     }\n",
        "\n",
        "# def compute_mtms(task_metrics, task_class_counts):\n",
        "#     \"\"\"\n",
        "#     Compute Multi-task Model Strength (MTMS) as defined in the CrisisKAN paper.\n",
        "\n",
        "#     Args:\n",
        "#         task_metrics: Dictionary mapping task names to their accuracy values\n",
        "#         task_class_counts: Dictionary mapping task names to their number of classes\n",
        "\n",
        "#     Returns:\n",
        "#         MTMS score (float between 0 and 1)\n",
        "#     \"\"\"\n",
        "#     total_classes = sum(task_class_counts.values())\n",
        "#     mtms = 0.0\n",
        "\n",
        "#     for task, acc in task_metrics.items():\n",
        "#         beta = task_class_counts[task] / total_classes\n",
        "#         mtms += beta * acc\n",
        "\n",
        "#     print(f\"\\nMulti-task Model Strength (MTMS): {mtms:.4f}\")\n",
        "#     return mtms\n"
      ],
      "metadata": {
        "id": "AEBg5UKXvR1_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Extract ground truth labels for each task\n",
        "# y_true_task1 = [sample[\"label\"].item() for sample in test_set_task1]\n",
        "# y_true_task2 = [sample[\"label\"].item() for sample in test_set_task2]\n",
        "# y_true_task3 = [sample[\"label\"].item() for sample in test_set_task3]\n",
        "\n",
        "# # Compute metrics for each task\n",
        "# metrics_task1 = compute_metrics(y_true_task1, preds_task1, task_name=\"Task 1 (Informative)\", verbose=True)\n",
        "# metrics_task2 = compute_metrics(y_true_task2, preds_task2, task_name=\"Task 2 (Humanitarian)\", verbose=True)\n",
        "# metrics_task3 = compute_metrics(y_true_task3, preds_task3, task_name=\"Task 3 (Damage)\", verbose=True)\n",
        "\n",
        "# # Prepare accuracy values for MTMS calculation\n",
        "# task_accuracies = {\n",
        "#     \"task1\": metrics_task1[\"accuracy\"],\n",
        "#     \"task2\": metrics_task2[\"accuracy\"],\n",
        "#     \"task3\": metrics_task3[\"accuracy\"]\n",
        "# }\n",
        "\n",
        "# # Define number of classes for each task\n",
        "# task_class_counts = {\n",
        "#     \"task1\": 2,  # informative vs. not_informative\n",
        "#     \"task2\": 6,  # humanitarian categories\n",
        "#     \"task3\": 3   # damage severity levels\n",
        "# }\n",
        "\n",
        "# # Compute MTMS\n",
        "# mtms = compute_mtms(task_accuracies, task_class_counts)\n",
        "\n",
        "# # Log to WandB if enabled\n",
        "# if trainer.run:\n",
        "#     wandb.log({\n",
        "#         \"MTMS\": mtms,\n",
        "#         \"task1_accuracy\": metrics_task1[\"accuracy\"],\n",
        "#         \"task1_macro_f1\": metrics_task1[\"macro_f1\"],\n",
        "#         \"task1_weighted_f1\": metrics_task1[\"weighted_f1\"],\n",
        "#         \"task2_accuracy\": metrics_task2[\"accuracy\"],\n",
        "#         \"task2_macro_f1\": metrics_task2[\"macro_f1\"],\n",
        "#         \"task2_weighted_f1\": metrics_task2[\"weighted_f1\"],\n",
        "#         \"task3_accuracy\": metrics_task3[\"accuracy\"],\n",
        "#         \"task3_macro_f1\": metrics_task3[\"macro_f1\"],\n",
        "#         \"task3_weighted_f1\": metrics_task3[\"weighted_f1\"]\n",
        "#     })\n",
        "#     trainer.run.finish()\n",
        "\n",
        "\n",
        "# print(\"\\nTraining and evaluation complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mXti-n0fw6LV",
        "outputId": "7901ab94-4878-4ba9-e1f7-8fb8560d5358"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluation Report for Task 1 (Informative)\n",
            "---------------------------------------\n",
            "Accuracy     : 0.7943\n",
            "Macro F1     : 0.7787\n",
            "Weighted F1  : 0.7940\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.72      0.72       530\n",
            "           1       0.83      0.84      0.84       904\n",
            "\n",
            "    accuracy                           0.79      1434\n",
            "   macro avg       0.78      0.78      0.78      1434\n",
            "weighted avg       0.79      0.79      0.79      1434\n",
            "\n",
            "\n",
            "Evaluation Report for Task 2 (Humanitarian)\n",
            "---------------------------------------\n",
            "Accuracy     : 0.6341\n",
            "Macro F1     : 0.4186\n",
            "Weighted F1  : 0.6178\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.49      0.61      0.54       223\n",
            "           1       0.78      0.78      0.78       536\n",
            "           2       0.63      0.59      0.61       344\n",
            "           3       0.50      0.63      0.56       208\n",
            "           4       0.00      0.00      0.00        14\n",
            "           5       1.00      0.01      0.03        77\n",
            "\n",
            "    accuracy                           0.63      1402\n",
            "   macro avg       0.57      0.44      0.42      1402\n",
            "weighted avg       0.66      0.63      0.62      1402\n",
            "\n",
            "\n",
            "Evaluation Report for Task 3 (Damage)\n",
            "---------------------------------------\n",
            "Accuracy     : 0.6747\n",
            "Macro F1     : 0.3796\n",
            "Weighted F1  : 0.5946\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.40      0.05      0.10        37\n",
            "           1       0.56      0.15      0.24        91\n",
            "           2       0.69      0.96      0.80       244\n",
            "\n",
            "    accuracy                           0.67       372\n",
            "   macro avg       0.55      0.39      0.38       372\n",
            "weighted avg       0.63      0.67      0.59       372\n",
            "\n",
            "\n",
            "Multi-task Model Strength (MTMS): 0.6743\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>MTMS</td><td>▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>task1_acc</td><td>▁▂▃▃▄▄▅▅▆▆▆▇▇▇██████</td></tr><tr><td>task1_accuracy</td><td>▁</td></tr><tr><td>task1_macro_f1</td><td>▁</td></tr><tr><td>task1_weighted_f1</td><td>▁</td></tr><tr><td>task2_acc</td><td>▁▂▂▃▃▄▄▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>task2_accuracy</td><td>▁</td></tr><tr><td>task2_macro_f1</td><td>▁</td></tr><tr><td>task2_weighted_f1</td><td>▁</td></tr><tr><td>task3_acc</td><td>▁▄▅▆▇███████████████</td></tr><tr><td>task3_accuracy</td><td>▁</td></tr><tr><td>task3_macro_f1</td><td>▁</td></tr><tr><td>task3_weighted_f1</td><td>▁</td></tr><tr><td>train_loss</td><td>█▇▅▄▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▇▆▅▄▄▃▃▂▂▁▁▁▁▁▂▂▂▃▃</td></tr><tr><td>val_task1_acc</td><td>▁▃▄▄▅▆▆▇▇▇▇█████████</td></tr><tr><td>val_task2_acc</td><td>▁▂▃▅▅▅▆▆▇█▇█████████</td></tr><tr><td>val_task3_acc</td><td>▁▆▆▆▅▇▆▆▇▇▆▆▇█▇▇▆▇▇▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>MTMS</td><td>0.6743</td></tr><tr><td>epoch</td><td>19</td></tr><tr><td>task1_acc</td><td>0.91057</td></tr><tr><td>task1_accuracy</td><td>0.79428</td></tr><tr><td>task1_macro_f1</td><td>0.77866</td></tr><tr><td>task1_weighted_f1</td><td>0.79399</td></tr><tr><td>task2_acc</td><td>0.78159</td></tr><tr><td>task2_accuracy</td><td>0.63409</td></tr><tr><td>task2_macro_f1</td><td>0.41859</td></tr><tr><td>task2_weighted_f1</td><td>0.61781</td></tr><tr><td>task3_acc</td><td>0.99227</td></tr><tr><td>task3_accuracy</td><td>0.67473</td></tr><tr><td>task3_macro_f1</td><td>0.37956</td></tr><tr><td>task3_weighted_f1</td><td>0.59459</td></tr><tr><td>train_loss</td><td>0.2667</td></tr><tr><td>val_loss</td><td>0.87192</td></tr><tr><td>val_task1_acc</td><td>0.83252</td></tr><tr><td>val_task2_acc</td><td>0.62326</td></tr><tr><td>val_task3_acc</td><td>0.65013</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">multitask_1745433298</strong> at: <a href='https://wandb.ai/principle-paper/ai-disaster-response/runs/52zhd1ja' target=\"_blank\">https://wandb.ai/principle-paper/ai-disaster-response/runs/52zhd1ja</a><br> View project at: <a href='https://wandb.ai/principle-paper/ai-disaster-response' target=\"_blank\">https://wandb.ai/principle-paper/ai-disaster-response</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250423_183458-52zhd1ja/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training and evaluation complete!\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}